# -*- coding: utf-8 -*-
"""
PDF Translator - í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ë‹¤êµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì›¹ì•±
- Flask ê¸°ë°˜ ì›¹ ì¸í„°í˜ì´ìŠ¤
- PaddleOCR + VLM (qwen2.5vl) ì‚¬ìš©
- ì§€ì› ì–¸ì–´: ì˜ì–´, ë² íŠ¸ë‚¨ì–´, ì¤‘êµ­ì–´, ì¸ë„ë„¤ì‹œì•„ì–´, ë²µê³¨ì–´
"""

# ë²„ì „ ì •ë³´
VERSION = "1.8.4"
VERSION_DATE = "2026-01-20"
VERSION_NOTES = """
v1.8.4 (2026-01-20)
- â˜… PDF ë¯¸ë¦¬ë³´ê¸° í™•ëŒ€/ì¶•ì†Œ ê¸°ëŠ¥: +/- ë²„íŠ¼ìœ¼ë¡œ 25% ë‹¨ìœ„ í™•ëŒ€/ì¶•ì†Œ
- Ctrl+ë§ˆìš°ìŠ¤íœ ë¡œ í™•ëŒ€/ì¶•ì†Œ ê°€ëŠ¥
- ì˜¤ë¥¸ìª½ ë²ˆì—­ íŒ¨ë„ í¬ê¸°ëŠ” ìœ ì§€ (ë…ë¦½ì  í™•ëŒ€/ì¶•ì†Œ)

v1.8.3 (2026-01-20)
- â˜… í•œê¸€ í°íŠ¸ ìˆ˜ì •: arial.ttf â†’ malgun.ttf (ë§‘ì€ ê³ ë”•)
- í•œê¸€ í…ìŠ¤íŠ¸ê°€ â–¡â–¡â–¡ë¡œ ê¹¨ì§€ëŠ” ë¬¸ì œ í•´ê²°
- ë‹¤êµ­ì–´(í•œì¤‘ì¼) í…ìŠ¤íŠ¸ ë Œë”ë§ ì§€ì›

v1.8.2 (2026-01-11)
- â˜… Placeholder ë³µì› ê°•í™”: AIê°€ ë³€í˜•í•œ ë‹¤ì–‘í•œ TERM íŒ¨í„´ ì²˜ë¦¬
- TERM_1, TERM 1, <TERM_1>, [TERM_1] ë“± ëª¨ë“  ë³€í˜• ìë™ ë³µì›
- ì •ê·œì‹ ê¸°ë°˜ ìœ ì—°í•œ íŒ¨í„´ ë§¤ì¹­ ì¶”ê°€

v1.8.1 (2026-01-11)
- â˜… ì„±ëŠ¥ ë¡œê·¸ ì¶”ê°€: Batch OCR, Claude API, Gemini Batch, ë³‘ë ¬ ë²ˆì—­ íƒ€ì´ë° ì¶œë ¥
- â˜… í™•ì • ë²„íŠ¼ í´ë¦­ ì‹œ ë¯¸ë¦¬ë³´ê¸° ì¦‰ì‹œ ê°±ì‹  ë³µêµ¬
- ë””ë²„ê¹… ë° ì„±ëŠ¥ ë¶„ì„ìš© ìƒì„¸ ë¡œê·¸

v1.8.0 (2026-01-10)
- â˜… ì‚¬ì „ êµ¬ì¡° í†µí•©: {"í•œê¸€": {"full": "ë²ˆì—­", "abbr": "ì•½ì–´"}} 
- â˜… UI ì•½ì–´ í¸ì§‘: ìš©ì–´ ì‚¬ì „ì—ì„œ ì•½ì–´ ì§ì ‘ ì¶”ê°€/ìˆ˜ì • ê°€ëŠ¥
- í•˜ë“œì½”ë”©ëœ ABBREVIATIONS ì œê±°, ì‚¬ì „ ê¸°ë°˜ ì•½ì–´ ì‹œìŠ¤í…œìœ¼ë¡œ ì „í™˜
- ì¥ê¸°ì  í™•ì¥ì„± ê°œì„  (category, note ë“± í•„ë“œ ì¶”ê°€ ìš©ì´)

v1.7.0 (2026-01-09)
- â˜… ìš©ì–´ ì‚¬ì „ ê´€ë¦¬ ê¸°ëŠ¥: ì˜ë¥˜ ì „ë¬¸ ìš©ì–´ ì¶”ê°€/ìˆ˜ì •/ì‚­ì œ ê°€ëŠ¥
- â˜… ì‚¬ì „ í›„ì²˜ë¦¬: AI ë²ˆì—­ í›„ ì‚¬ì „ ìš©ì–´ë¡œ ìë™ êµì • (ì¼ê´€ì„± í–¥ìƒ)
- ğŸ“– ë²„íŠ¼ í´ë¦­ìœ¼ë¡œ ì‚¬ì „ ê´€ë¦¬ ëª¨ë‹¬ ì˜¤í”ˆ
- ì–¸ì–´ë³„ íƒ­ ì „í™˜, ê²€ìƒ‰ ê¸°ëŠ¥, ì‹¤ì‹œê°„ ì €ì¥
- JSON íŒŒì¼(garment_dict.json)ë¡œ ì‚¬ì „ ë°ì´í„° ë¶„ë¦¬

v1.6.1 (2026-01-09)
- Claude Opus 4.5 ëª¨ë¸ ì¶”ê°€
- ë²ˆì—­ í”„ë¡¬í”„íŠ¸ ê°•í™”: ëª¨ë“  í•­ëª© ë²ˆì—­ í•„ìˆ˜ ê·œì¹™ ì ìš©
- íŒŒì‹± ë¡œì§ ê°œì„ : ë‹¤ì–‘í•œ ë²ˆí˜¸ í˜•ì‹ ì§€ì› (1., 1), **1.**, 1:)

v1.6.0 (2026-01-09)
- â˜… Gemini ë°°ì¹˜ ë²ˆì—­: ëª¨ë“  í˜ì´ì§€ í…ìŠ¤íŠ¸ë¥¼ 1íšŒ API í˜¸ì¶œë¡œ ë²ˆì—­ (Free Tier ìµœì í™”)
- AI ëª¨ë¸ ì„ íƒ: Gemini 2.0 Flash, GPT-4o, GPT-4o-mini ì§€ì›
- API í‚¤ ì…ë ¥ í•„ë“œ ì¶”ê°€

v1.5.0 (2026-01-08)
- â˜… ì„¸ë¡œ í…ìŠ¤íŠ¸ ì§€ì›: ë†’ì´>ë„ˆë¹„Ã—2 â†’ ê¸€ìë¥¼ ì„¸ë¡œë¡œ ë°°ì¹˜
- â˜… ì§„í–‰ ìƒí™© í‘œì‹œ: OCR/ë²ˆì—­ ë‹¨ê³„ë³„ ì‹¤ì‹œê°„ ì§„í–‰ë¥  + ê²½ê³¼ì‹œê°„

v1.4.4 (2026-01-08)
- ì„  ë³´ì¡´: ë§ˆì§„ ìµœì†Œí™” (15% â†’ 1px)ë¡œ í…Œì´ë¸” ì„  ì¹¨ë²” ë°©ì§€

v1.4.2 (2026-01-08)
- í…ìŠ¤íŠ¸ ì™„ì „ ì‚­ì œ: Inpainting ëŒ€ì‹  ë°°ê²½ìƒ‰ìœ¼ë¡œ ì§ì ‘ ë®ì–´ì“°ê¸°
- ì–´ë‘ìš´ ë°°ê²½ ì§€ì›: ë°°ê²½ ë°ê¸° ê°ì§€ â†’ ìë™ìœ¼ë¡œ í°ìƒ‰/ê²€ì • í…ìŠ¤íŠ¸ ì„ íƒ

v1.3.0 (2026-01-08)
- ë°°ê²½ìƒ‰ ìƒ˜í”Œë§ ë°©ì‹ ì ìš©: bbox ì£¼ë³€ ê°€ì¥ìë¦¬ì—ì„œ ë°°ê²½ìƒ‰ ê°ì§€
- ê¸€ì ë†’ì´ì— ë¹„ë¡€í•œ ë™ì  ë§ˆì§„ (ìµœì†Œ 5px, ë†’ì´ì˜ 20%)
- ì¸í˜ì¸íŒ… ëŒ€ì‹  ë°°ê²½ìƒ‰ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì±„ìš°ê¸°

v1.2.1 (2026-01-07)
- í…ìŠ¤íŠ¸ ì§€ìš°ê¸° ë‹¨ìˆœí™”: í°ìƒ‰ìœ¼ë¡œ í™•ì‹¤í•˜ê²Œ ë®ì–´ì“°ê¸° (ì¸í˜ì¸íŒ… ì œê±°)
- ë§ˆì§„ í™•ëŒ€: ê¸€ì ë†’ì´ì˜ 15-20%ë¡œ ì¶©ë¶„íˆ ë®ìŒ
- ì•ˆì •ì„± í–¥ìƒ: ë³µì¡í•œ ì¸í˜ì¸íŒ… ëŒ€ì‹  ë‹¨ìˆœí•œ ë°©ì‹ ì±„íƒ

v1.2.0 (2026-01-07)
- ì¸í˜ì¸íŒ… ê¸°ìˆ  ì‹œë„ (ë¬¸ì œ ë°œìƒìœ¼ë¡œ ë¡¤ë°±)

v1.1.0 (2026-01-06)
- í…ìŠ¤íŠ¸ ì§€ìš°ê¸° ê°œì„ : ê¸€ìì—ì„œ ë–¨ì–´ì§„ ì˜ì—­ì—ì„œ ë°°ê²½ìƒ‰ ìƒ˜í”Œë§
- ë§ˆì§„ í™•ì¥: ê¸€ì ë†’ì´ì— ë¹„ë¡€í•œ ë™ì  ë§ˆì§„ìœ¼ë¡œ ì™„ì „íˆ ì§€ì›€
- ë°°ê²½ìƒ‰ ê°ì§€ ê°œì„ : 5-10í”½ì…€ ë–¨ì–´ì§„ ê³³ì—ì„œ ìƒ˜í”Œë§í•˜ì—¬ ê¸€ì ìƒ‰ìƒ í˜¼ì… ë°©ì§€

v1.0.0 (2026-01-06)
- ë¯¸ë¦¬ë³´ê¸° ê¸°ëŠ¥ ì¶”ê°€: ë²ˆì—­ ê²°ê³¼ë¥¼ ë‚´ë³´ë‚´ê¸° ì „ ë¯¸ë¦¬ë³´ê¸° ê°€ëŠ¥
- í…ìŠ¤íŠ¸ ì˜ì—­ ì§€ìš°ê¸°: í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ë°°ê²½ìƒ‰ìœ¼ë¡œ ì§€ìš°ê³  ë²ˆì—­ í…ìŠ¤íŠ¸ ì‚½ì…
- ë°°ê²½ìƒ‰ ìë™ ê°ì§€: í…Œë‘ë¦¬ í”½ì…€ ìƒ˜í”Œë§ìœ¼ë¡œ í°ìƒ‰ ê³„ì—´ ìš°ì„  ê°ì§€
- ë¯¸ë¦¬ë³´ê¸° ìºì‹œ: í˜ì´ì§€ë³„ ìºì‹œë¡œ ì„±ëŠ¥ ìµœì í™”
"""

import os
import sys
import io
import json
import base64
import tempfile
import re
import requests
import logging
from collections import Counter
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed  # ë³‘ë ¬ ì²˜ë¦¬ìš©
from flask import Flask, render_template_string, request, send_file, jsonify
from PIL import Image, ImageDraw, ImageFont
import numpy as np
from paddleocr import PaddleOCR
import cv2
import fitz  # PyMuPDF
from img2table.document import Image as Img2TableImage  # í…Œì´ë¸” ê°ì§€ìš©

# â˜… ë¡œê¹… ì„¤ì • (ê²¹ì¹¨ ê°ì§€ ë””ë²„ê¹…ìš©)
LOG_FILE = os.path.join(os.path.dirname(__file__), 'overlap_debug.log')

# ì „ìš© ë¡œê±° ìƒì„± (Flask ë¡œê¹…ê³¼ ë¶„ë¦¬)
logger = logging.getLogger('overlap_debug')
logger.setLevel(logging.DEBUG)
logger.handlers = []  # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°

# íŒŒì¼ í•¸ë“¤ëŸ¬
file_handler = logging.FileHandler(LOG_FILE, encoding='utf-8', mode='a')
file_handler.setLevel(logging.DEBUG)
file_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s', '%Y-%m-%d %H:%M:%S'))
logger.addHandler(file_handler)

# ì½˜ì†” í•¸ë“¤ëŸ¬
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.DEBUG)
console_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s', '%Y-%m-%d %H:%M:%S'))
logger.addHandler(console_handler)

logger.propagate = False  # ë¶€ëª¨ ë¡œê±°ë¡œ ì „íŒŒ ë°©ì§€

# UTF-8 ì¶œë ¥ ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

app = Flask(__name__)

# ì„¤ì •
OLLAMA_URL = "http://localhost:11434/api/generate"
CLAUDE_API_URL = "https://api.anthropic.com/v1/messages"
OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"
GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models"

# AI ëª¨ë¸ ì„¤ì •
AI_MODELS = {
    "ollama": {
        "models": ["qwen2.5vl:latest", "llava:latest", "bakllava:latest"],
        "default": "qwen2.5vl:latest"
    },
    "claude": {
        "models": ["claude-opus-4-20250514", "claude-sonnet-4-20250514", "claude-3-5-sonnet-20241022", "claude-3-haiku-20240307"],
        "default": "claude-sonnet-4-20250514"
    },
    "openai": {
        "models": ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo"],
        "default": "gpt-4o"
    },
    "gemini": {
        "models": ["gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro"],
        "default": "gemini-2.0-flash"
    }
}
UPLOAD_FOLDER = tempfile.gettempdir()
OUTPUT_FOLDER = os.path.join(os.path.dirname(__file__), "output")
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

# ì–¸ì–´ë³„ ì„¤ì •
LANGUAGE_CONFIG = {
    "english": {
        "name": "English",
        "code": "en",
        "prompt_lang": "English"
    },
    "vietnamese": {
        "name": "Tiáº¿ng Viá»‡t",
        "code": "vi",
        "prompt_lang": "Vietnamese"
    },
    "chinese": {
        "name": "ä¸­æ–‡",
        "code": "zh",
        "prompt_lang": "Chinese (Simplified)"
    },
    "indonesian": {
        "name": "Bahasa Indonesia",
        "code": "id",
        "prompt_lang": "Indonesian"
    },
    "bengali": {
        "name": "à¦¬à¦¾à¦‚à¦²à¦¾",
        "code": "bn",
        "prompt_lang": "Bengali"
    }
}

# [ë ˆê±°ì‹œ] í•˜ë“œì½”ë”©ëœ ì•½ì–´ - ì´ì œ garment_dict.jsonì˜ abbr í•„ë“œë¡œ ëŒ€ì²´ë¨
# ABBREVIATIONS = {
#     "Garment Matching": "G.M",
#     "G Matching": "G.M",
#     "Accessory Matching": "A.M",
#     "A Matching": "A.M",
#     "Consumption": "Cons.",
#     "NaturalZipper": "Nat.Zip",
#     "Natural Zipper": "Nat.Zip",
#     "FrontZipper": "Fr.Zip",
#     "Front Zipper": "Fr.Zip",
#     "SidePocket": "Side Pkt",
#     "Side Pocket": "Side Pkt",
#     "Factory Handling": "Fact.Hdl",
#     "Hood/Hem": "Hd/Hm",
# }

# ì˜ë¥˜ ì „ë¬¸ ìš©ì–´ ì‚¬ì „ íŒŒì¼ ê²½ë¡œ
GARMENT_DICT_FILE = os.path.join(os.path.dirname(__file__), "garment_dict.json")

def load_garment_dict():
    """JSON íŒŒì¼ì—ì„œ ìš©ì–´ ì‚¬ì „ ë¡œë“œ"""
    try:
        if os.path.exists(GARMENT_DICT_FILE):
            with open(GARMENT_DICT_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        print(f"[Warning] Failed to load garment_dict.json: {e}")
    # ê¸°ë³¸ ì‚¬ì „ ë°˜í™˜ (íŒŒì¼ ì—†ì„ ê²½ìš°)
    return {
        "english": {"ë‚¨ì„±": "Men's", "ì—¬ì„±": "Women's"},
        "vietnamese": {"ë‚¨ì„±": "Nam", "ì—¬ì„±": "Ná»¯"},
        "chinese": {"ë‚¨ì„±": "ç”·å£«", "ì—¬ì„±": "å¥³å£«"},
        "indonesian": {"ë‚¨ì„±": "Pria", "ì—¬ì„±": "Wanita"},
        "bengali": {"ë‚¨ì„±": "à¦ªà§à¦°à§à¦·", "ì—¬ì„±": "à¦®à¦¹à¦¿à¦²à¦¾"}
    }

def save_garment_dict(data):
    """ìš©ì–´ ì‚¬ì „ì„ JSON íŒŒì¼ë¡œ ì €ì¥"""
    try:
        with open(GARMENT_DICT_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"[Error] Failed to save garment_dict.json: {e}")
        return False

# ìš©ì–´ ì‚¬ì „ ë¡œë“œ (ì „ì—­)
GARMENT_DICT = load_garment_dict()

# OCR ì—”ì§„ ì´ˆê¸°í™” (ì‹±ê¸€í†¤)
ocr_engine = None

def get_ocr_engine():
    global ocr_engine
    if ocr_engine is None:
        print("[init] PaddleOCR engine (korean)...")
        # ì „ì²˜ë¦¬ ë¹„í™œì„±í™”: bbox ì¢Œí‘œê°€ ì›ë³¸ ì´ë¯¸ì§€ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ë„ë¡ í•¨
        # ê°ì§€ ì„ê³„ê°’ ë‚®ì¶°ì„œ ë” ë§ì€ í…ìŠ¤íŠ¸ ì¸ì‹ (ì˜ì–´ í¬í•¨)
        ocr_engine = PaddleOCR(
            lang="korean",
            use_doc_orientation_classify=False,  # ë¬¸ì„œ ë°©í–¥ ë¶„ë¥˜ ë„ê¸°
            use_doc_unwarping=False,             # ë¬¸ì„œ ì™œê³¡ ë³´ì • ë„ê¸°
            use_textline_orientation=False,      # í…ìŠ¤íŠ¸ë¼ì¸ ë°©í–¥ ë¶„ë¥˜ ë„ê¸°
            det_db_thresh=0.2,                   # í…ìŠ¤íŠ¸ ê°ì§€ ì„ê³„ê°’ ë‚®ì¶¤ (ê¸°ë³¸ 0.3)
            det_db_box_thresh=0.4                # ë°•ìŠ¤ ì„ê³„ê°’ ë‚®ì¶¤ (ê¸°ë³¸ 0.6)
        )
        print("[init] PaddleOCR engine ready")
    return ocr_engine


def pdf_to_images(pdf_path, zoom=2.0):
    """PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
    doc = fitz.open(pdf_path)
    images = []

    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        mat = fitz.Matrix(zoom, zoom)
        pix = page.get_pixmap(matrix=mat)

        img_path = os.path.join(UPLOAD_FOLDER, f"page_{page_num + 1}.png")
        pix.save(img_path)
        images.append(img_path)

    doc.close()
    return images


def get_ocr_results(image_path):
    """PaddleOCRë¡œ í…ìŠ¤íŠ¸ì™€ ìœ„ì¹˜ ì¶”ì¶œ"""
    ocr = get_ocr_engine()

    # â˜… í•µì‹¬ ìˆ˜ì •: ì´ë¯¸ì§€ë¥¼ RGB numpy ë°°ì—´ë¡œ ë³€í™˜í•˜ì—¬ ì „ë‹¬
    # PaddleOCRì€ RGB í˜•ì‹ì„ ê¸°ëŒ€í•˜ë¯€ë¡œ, íŒŒì¼ ê²½ë¡œ ëŒ€ì‹  RGB ë°°ì—´ ì „ë‹¬
    img_bgr = cv2.imread(image_path)
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    result = ocr.predict(img_rgb)

    texts = []
    if result:
        for item in result:
            rec_texts = []
            rec_scores = []
            dt_polys = []

            # OCRResult ê°ì²´ ì²˜ë¦¬ (ìƒˆ PaddleOCR API)
            if hasattr(item, 'rec_texts'):
                rec_texts = item.rec_texts or []
                rec_scores = item.rec_scores or []
                # dt_polys ì‚¬ìš© (ì›ë³¸ detection ì¢Œí‘œ - ë” ì •í™•í•¨)
                dt_polys = item.dt_polys if hasattr(item, 'dt_polys') and item.dt_polys is not None else []
            elif isinstance(item, dict):
                rec_texts = item.get('rec_text', item.get('rec_texts', []))
                rec_scores = item.get('rec_score', item.get('rec_scores', []))
                dt_polys = item.get('dt_polys', [])

            if isinstance(rec_texts, str):
                rec_texts = [rec_texts]
                rec_scores = [rec_scores]
                dt_polys = [dt_polys]

            for text, score, poly in zip(rec_texts, rec_scores, dt_polys):
                text_str = str(text)
                # ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì˜ì–´ í¬í•¨) - ê²¹ì¹¨ ê°ì§€ì— ì‚¬ìš©
                # has_korean í”Œë˜ê·¸ë¡œ ë²ˆì—­ ëŒ€ìƒ ì—¬ë¶€ êµ¬ë¶„
                has_korean = any('\uac00' <= c <= '\ud7a3' for c in text_str)
                bbox = poly.tolist() if hasattr(poly, 'tolist') else poly
                texts.append({
                    "bbox": bbox,
                    "text": text_str,
                    "confidence": float(score) if score else 1.0,
                    "has_korean": has_korean  # í•œê¸€ í¬í•¨ ì—¬ë¶€ í”Œë˜ê·¸
                })

    return texts


def get_ocr_results_batch(image_paths):
    """ë°°ì¹˜ OCR - ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ í•œë²ˆì— ì²˜ë¦¬ (ì†ë„ í–¥ìƒ)
    
    Args:
        image_paths: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        list: ê° ì´ë¯¸ì§€ë³„ OCR ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    import time
    batch_start = time.time()
    
    ocr = get_ocr_engine()
    
    # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ RGB numpy ë°°ì—´ë¡œ ë³€í™˜
    load_start = time.time()
    images_rgb = []
    for img_path in image_paths:
        img_bgr = cv2.imread(img_path)
        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
        images_rgb.append(img_rgb)
    load_time = time.time() - load_start
    print(f"[Batch OCR] Image loading: {load_time:.2f}s for {len(images_rgb)} images", flush=True)
    
    # ë°°ì¹˜ OCR ì‹¤í–‰
    ocr_start = time.time()
    print(f"[Batch OCR] Running OCR on {len(images_rgb)} images...", flush=True)
    results = ocr.predict(images_rgb)
    ocr_time = time.time() - ocr_start
    print(f"[Batch OCR] OCR inference: {ocr_time:.2f}s", flush=True)
    
    # ê²°ê³¼ íŒŒì‹±
    all_texts = []
    for page_idx, result in enumerate(results if results else []):
        texts = []
        rec_texts = []
        rec_scores = []
        dt_polys = []
        
        # OCRResult ê°ì²´ ì²˜ë¦¬
        if hasattr(result, 'rec_texts'):
            rec_texts = result.rec_texts or []
            rec_scores = result.rec_scores or []
            dt_polys = result.dt_polys if hasattr(result, 'dt_polys') and result.dt_polys is not None else []
        elif isinstance(result, dict):
            rec_texts = result.get('rec_text', result.get('rec_texts', []))
            rec_scores = result.get('rec_score', result.get('rec_scores', []))
            dt_polys = result.get('dt_polys', [])
        
        if isinstance(rec_texts, str):
            rec_texts = [rec_texts]
            rec_scores = [rec_scores]
            dt_polys = [dt_polys]
        
        for text, score, poly in zip(rec_texts, rec_scores, dt_polys):
            text_str = str(text)
            has_korean = any('\uac00' <= c <= '\ud7a3' for c in text_str)
            bbox = poly.tolist() if hasattr(poly, 'tolist') else poly
            texts.append({
                "bbox": bbox,
                "text": text_str,
                "confidence": float(score) if score else 1.0,
                "has_korean": has_korean
            })
        
        all_texts.append(texts)
        print(f"  [Page {page_idx+1}] Found {len(texts)} texts", flush=True)
    
    total_time = time.time() - batch_start
    total_texts = sum(len(t) for t in all_texts)
    print(f"[Batch OCR] TOTAL: {total_time:.2f}s for {len(image_paths)} pages, {total_texts} texts", flush=True)
    
    return all_texts


def translate_with_dict(korean_text, target_lang):
    """ì‚¬ì „ ê¸°ë°˜ ë²ˆì—­ (fallbackìš©)"""
    result = korean_text
    if target_lang in GARMENT_DICT:
        for kor, trans in GARMENT_DICT[target_lang].items():
            # â˜… ìƒˆ dict êµ¬ì¡° ì§€ì›: {"full": "...", "abbr": "..."}
            if isinstance(trans, dict):
                trans_text = trans.get("full", "")
            else:
                trans_text = trans
            if trans_text:
                result = result.replace(kor, trans_text)
    return result


def apply_dict_preprocess(korean_text, target_lang):
    """AI ë²ˆì—­ ì „ ì‚¬ì „ ìš©ì–´ë¥¼ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ëŒ€ì²´ (Placeholder ë°©ì‹)

    Args:
        korean_text: ì›ë³¸ í•œê¸€ í…ìŠ¤íŠ¸
        target_lang: ëŒ€ìƒ ì–¸ì–´ (english, vietnamese ë“±)

    Returns:
        tuple: (í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì ìš©ëœ í…ìŠ¤íŠ¸, í”Œë ˆì´ìŠ¤í™€ë” ë§¤í•‘ ë”•ì…”ë„ˆë¦¬)

    Example:
        "23SS í–‰ê±°ë£¨í”„ ìš”ì²™" â†’ ("23SS í–‰ê±°ë£¨í”„ <<TERM_1>>", {"<<TERM_1>>": "Consumption"})
    """
    if target_lang not in GARMENT_DICT:
        return korean_text, {}

    result = korean_text
    placeholder_map = {}  # {"<<TERM_1>>": "Consumption", ...}
    dict_terms = GARMENT_DICT[target_lang]

    # ê¸´ ìš©ì–´ë¶€í„° ì²˜ë¦¬ (ë³µí•©ì–´ ìš°ì„ : "í›„ë“œíƒˆë¶€ì°©" > "í›„ë“œ")
    sorted_terms = sorted(dict_terms.items(), key=lambda x: len(x[0]), reverse=True)

    term_idx = 1
    for korean_term, term_data in sorted_terms:
        if korean_term in result:
            placeholder = f"<<TERM_{term_idx}>>"
            result = result.replace(korean_term, placeholder)
            # ìƒˆ êµ¬ì¡°: term_data = {"full": "ë²ˆì—­", "abbr": "ì•½ì–´"}
            if isinstance(term_data, dict):
                placeholder_map[placeholder] = term_data.get("full", "")
            else:
                # ë ˆê±°ì‹œ í˜¸í™˜: ë‹¨ìˆœ ë¬¸ìì—´ì¸ ê²½ìš°
                placeholder_map[placeholder] = term_data
            term_idx += 1

    return result, placeholder_map


def detect_table_regions(image_path, max_avg_row_height=50):
    """img2tableì„ ì‚¬ìš©í•˜ì—¬ í…Œì´ë¸” ì˜ì—­ ê°ì§€
    
    Args:
        image_path: ì´ë¯¸ì§€ ê²½ë¡œ
        max_avg_row_height: í…Œì´ë¸”ë¡œ ì¸ì •í•  ìµœëŒ€ í‰ê·  í–‰ ë†’ì´ (ê¸°ë³¸ 50px)
    
    Returns:
        list: í…Œì´ë¸” ì˜ì—­ bbox ë¦¬ìŠ¤íŠ¸ [(x1, y1, x2, y2), ...]
    """
    try:
        img = Img2TableImage(src=image_path)
        tables = img.extract_tables()
        logger.info(f"[Table Detection] Found {len(tables)} raw tables")
        
        table_regions = []
        for idx, table in enumerate(tables):
            # í–‰ ë†’ì´ ê³„ì‚°
            if hasattr(table, 'content') and table.content:
                row_heights = []
                for row in table.content:
                    if row:
                        for cell in row:
                            if cell and hasattr(cell, 'bbox'):
                                cell_bbox = cell.bbox
                                if hasattr(cell_bbox, 'y1') and hasattr(cell_bbox, 'y2'):
                                    row_heights.append(cell_bbox.y2 - cell_bbox.y1)
                                break
                
                if row_heights:
                    avg_row_height = sum(row_heights) / len(row_heights)
                    logger.info(f"[Table Detection] Table #{idx} avg row height: {avg_row_height:.1f}px")
                    if avg_row_height > max_avg_row_height:
                        logger.info(f"[Table Detection] Table #{idx} skipped (height > {max_avg_row_height}px)")
                        continue
            
            # bbox ì¶”ì¶œ
            if hasattr(table, 'bbox'):
                bbox = table.bbox
                if hasattr(bbox, 'x1'):
                    table_regions.append((bbox.x1, bbox.y1, bbox.x2, bbox.y2))
                    logger.info(f"[Table Detection] Table #{idx} added: ({bbox.x1}, {bbox.y1}, {bbox.x2}, {bbox.y2})")
        
        logger.info(f"[Table Detection] Final: {len(table_regions)} valid tables")
        return table_regions
    except Exception as e:
        logger.error(f"[Table Detection] Error: {e}")
        return []


def is_inside_table(bbox, table_regions):
    """í…ìŠ¤íŠ¸ bboxê°€ í…Œì´ë¸” ì˜ì—­ ì•ˆì— ìˆëŠ”ì§€ í™•ì¸"""
    if not table_regions:
        return False
    
    # bbox ì¤‘ì‹¬ì  ê³„ì‚°
    xs = [p[0] for p in bbox]
    ys = [p[1] for p in bbox]
    center_x = (min(xs) + max(xs)) / 2
    center_y = (min(ys) + max(ys)) / 2
    
    for (tx1, ty1, tx2, ty2) in table_regions:
        if tx1 <= center_x <= tx2 and ty1 <= center_y <= ty2:
            return True
    return False


def restore_placeholders(translated_text, placeholder_map):
    """ë²ˆì—­ ê²°ê³¼ì—ì„œ í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì‚¬ì „ ë²ˆì—­ìœ¼ë¡œ ë³µì›

    Args:
        translated_text: AIê°€ ë²ˆì—­í•œ í…ìŠ¤íŠ¸ (í”Œë ˆì´ìŠ¤í™€ë” í¬í•¨)
        placeholder_map: í”Œë ˆì´ìŠ¤í™€ë” â†’ ì‚¬ì „ ë²ˆì—­ ë§¤í•‘

    Returns:
        str: í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì‚¬ì „ ë²ˆì—­ìœ¼ë¡œ ëŒ€ì²´ëœ ìµœì¢… í…ìŠ¤íŠ¸

    Example:
        ("23SS Hanger Loop <<TERM_1>>", {"<<TERM_1>>": "Consumption"})
        â†’ "23SS Hanger Loop Consumption"
    """
    import re
    result = translated_text
    
    for placeholder, translation in placeholder_map.items():
        # ì›ë³¸ placeholder (ì˜ˆ: <<TERM_1>>)
        result = result.replace(placeholder, translation)
        
        # AIê°€ ë³€í˜•í•œ ë‹¤ì–‘í•œ íŒ¨í„´ë„ ì²˜ë¦¬
        # <<TERM_1>> ì—ì„œ ìˆ«ì ì¶”ì¶œ
        match = re.search(r'TERM_(\d+)', placeholder)
        if match:
            term_num = match.group(1)
            # ë‹¤ì–‘í•œ ë³€í˜• íŒ¨í„´ ì²˜ë¦¬ (ì •í™•í•œ ë¬¸ìì—´ ë§¤ì¹­)
            variations = [
                f"TERM_{term_num}",           # TERM_1 (êº¾ì‡  ì œê±°ë¨)
                f"TERM {term_num}",           # TERM 1 (ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°ë¨)
                f"<TERM_{term_num}>",         # <TERM_1> (êº¾ì‡  í•˜ë‚˜ë§Œ)
                f"[TERM_{term_num}]",         # [TERM_1] (ëŒ€ê´„í˜¸ë¡œ ë³€í˜•)
                f"(TERM_{term_num})",         # (TERM_1) (ê´„í˜¸ë¡œ ë³€í˜•)
                f"{{TERM_{term_num}}}",       # {TERM_1} (ì¤‘ê´„í˜¸ë¡œ ë³€í˜•)
                f"TERM{term_num}",            # TERM1 (ì–¸ë”ìŠ¤ì½”ì–´ ì™„ì „ ì œê±°)
                f"Term_{term_num}",           # Term_1 (ëŒ€ì†Œë¬¸ì ë³€í˜•)
                f"term_{term_num}",           # term_1 (ì†Œë¬¸ì ë³€í˜•)
            ]
            for var in variations:
                if var in result:
                    result = result.replace(var, translation)
            
            # ì •ê·œì‹ìœ¼ë¡œ ë” ìœ ì—°í•œ íŒ¨í„´ ë§¤ì¹­ (ê³µë°±, íŠ¹ìˆ˜ë¬¸ì í¬í•¨)
            # ì˜ˆ: "TERM _ 1", "TERM- 1", "TERM_1." ë“±
            flexible_patterns = [
                rf'<<\s*TERM[_\s-]*{term_num}\s*>>',  # << TERM_1 >> ë“±
                rf'<\s*TERM[_\s-]*{term_num}\s*>',    # < TERM_1 > ë“±
                rf'\[\s*TERM[_\s-]*{term_num}\s*\]',  # [ TERM_1 ] ë“±
                rf'\(\s*TERM[_\s-]*{term_num}\s*\)',  # ( TERM_1 ) ë“±
                rf'TERM[_\s-]*{term_num}(?![0-9])',   # TERM_1, TERM 1, TERM-1 (ë’¤ì— ìˆ«ì ì—†ì„ ë•Œë§Œ)
            ]
            for pattern in flexible_patterns:
                result = re.sub(pattern, translation, result, flags=re.IGNORECASE)
    
    return result


def apply_dict_postprocess(translated_text, original_korean, target_lang):
    """AI ë²ˆì—­ ê²°ê³¼ì— ì‚¬ì „ ìš©ì–´ í›„ì²˜ë¦¬ ì ìš© (ë ˆê±°ì‹œ - ë°±ì—…ìš©)

    ì›ë³¸ í•œê¸€ì—ì„œ ì‚¬ì „ ìš©ì–´ê°€ ìˆìœ¼ë©´, ë²ˆì—­ ê²°ê³¼ì—ì„œ í•´ë‹¹ ë¶€ë¶„ì„ ì‚¬ì „ ë²ˆì—­ìœ¼ë¡œ êµì²´
    Note: Placeholder ë°©ì‹(apply_dict_preprocess + restore_placeholders)ì´ ë” ê¶Œì¥ë¨
    """
    if target_lang not in GARMENT_DICT:
        return translated_text

    result = translated_text
    dict_terms = GARMENT_DICT[target_lang]

    # ê¸´ ìš©ì–´ë¶€í„° ì²˜ë¦¬ (ë³µí•©ì–´ ìš°ì„ )
    sorted_terms = sorted(dict_terms.items(), key=lambda x: len(x[0]), reverse=True)

    for korean_term, correct_translation in sorted_terms:
        if korean_term in original_korean:
            # ì›ë³¸ì— í•´ë‹¹ ìš©ì–´ê°€ ìˆìœ¼ë©´, ë²ˆì—­ ê²°ê³¼ì—ì„œ ì˜ëª»ëœ ë²ˆì—­ì„ êµì²´
            # ë‹¨, ì´ë¯¸ ì˜¬ë°”ë¥¸ ë²ˆì—­ì´ ìˆìœ¼ë©´ ê±´ë„ˆëœ€
            if correct_translation not in result:
                # í”í•œ ì˜¤ë²ˆì—­ íŒ¨í„´ë“¤ì„ ì‚¬ì „ ë²ˆì—­ìœ¼ë¡œ êµì²´
                result = result.replace(korean_term, correct_translation)

    return result


def translate_with_claude(image_path, texts, target_lang, api_key, model=None):
    """Claude APIë¡œ ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ë²ˆì—­ (Placeholder ë°©ì‹ ì ìš©)"""
    import time
    api_start = time.time()
    
    print(f"[Claude] translate_with_claude called - texts: {len(texts)}, model: {model}", flush=True)
    if model is None:
        model = AI_MODELS["claude"]["default"]
    print(f"[Claude] Using model: {model}", flush=True)
    lang_config = LANGUAGE_CONFIG.get(target_lang, LANGUAGE_CONFIG["english"])

    # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
    with open(image_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode()

    translations = []

    # í•œê¸€ í…ìŠ¤íŠ¸ë§Œ í•„í„°ë§ (ì¸ë±ìŠ¤ ë³´ì¡´) - ì˜ì–´ë§Œ ìˆëŠ” í…ìŠ¤íŠ¸ëŠ” ë²ˆì—­í•˜ì§€ ì•ŠìŒ
    korean_items = [(i, item) for i, item in enumerate(texts) if item.get("has_korean", True)]
    korean_list = [item["text"] for _, item in korean_items]
    korean_indices = [i for i, _ in korean_items]
    
    print(f"[Claude] Total texts: {len(texts)}, Korean texts to translate: {len(korean_list)}", flush=True)

    # â˜… Placeholder ì „ì²˜ë¦¬: ì‚¬ì „ ìš©ì–´ë¥¼ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ëŒ€ì²´
    preprocessed_list = []
    placeholder_maps = []  # ê° í…ìŠ¤íŠ¸ë³„ í”Œë ˆì´ìŠ¤í™€ë” ë§¤í•‘ ì €ì¥
    for korean_text in korean_list:
        processed_text, pmap = apply_dict_preprocess(korean_text, target_lang)
        preprocessed_list.append(processed_text)
        placeholder_maps.append(pmap)
        if pmap:
            print(f"[Claude] Preprocess: '{korean_text}' â†’ '{processed_text}' (placeholders: {len(pmap)})", flush=True)

    korean_joined = "\n".join([f"{i+1}. {t}" for i, t in enumerate(preprocessed_list)])

    prompt = f"""This is a garment/clothing technical specification image (tech pack).
Translate ALL the following Korean texts to {lang_config['prompt_lang']}. These are garment industry terms.

RULES:
- Translate EVERY item, even if it contains English or numbers
- Use FULL words only, do NOT abbreviate (e.g., "Consumption" not "Cons.", "Management" not "Mgmt.")
- Use format: "1. translation" (number + dot + space + translation)
- Do NOT skip any item
- Do NOT use markdown formatting like **bold**
- CRITICAL: <<TERM_N>> placeholders are pre-translated dictionary terms. Keep them EXACTLY as they are. Do NOT translate, modify, or replace them.

Korean texts:
{korean_joined}

{lang_config['prompt_lang']} translations (translate ALL {len(korean_list)} items):"""

    try:
        headers = {
            "Content-Type": "application/json",
            "x-api-key": api_key,
            "anthropic-version": "2023-06-01"
        }

        payload = {
            "model": model,
            "max_tokens": 4096,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/png",
                                "data": image_data
                            }
                        },
                        {
                            "type": "text",
                            "text": prompt
                        }
                    ]
                }
            ]
        }

        print(f"[Claude] Calling API: {CLAUDE_API_URL}", flush=True)
        request_start = time.time()
        response = requests.post(
            CLAUDE_API_URL,
            headers=headers,
            json=payload,
            timeout=120
        )
        api_time = time.time() - request_start
        print(f"[Claude] API response status: {response.status_code} (took {api_time:.2f}s)", flush=True)

        if response.status_code == 200:
            result = response.json()
            response_text = result.get("content", [{}])[0].get("text", "").strip()
            print(f"[Claude] Raw response:\n{response_text}", flush=True)

            # ì‘ë‹µ íŒŒì‹± (ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
            import re
            lines = response_text.split("\n")
            trans_dict = {}
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                # ë‹¤ì–‘í•œ ë²ˆí˜¸ í˜•ì‹ ì§€ì›: "1. text", "1) text", "**1.** text", "1: text"
                match = re.match(r'^[*]*(\d+)[.*)\]:]+\s*[*]*\s*(.+)', line)
                if match:
                    idx = int(match.group(1)) - 1
                    trans = match.group(2).strip()
                    if idx < len(korean_list):
                        trans_dict[idx] = trans
                        print(f"[Claude] Parsed {idx+1}: {trans[:30]}...", flush=True)

            print(f"[Claude] Parsed {len(trans_dict)}/{len(korean_list)} translations", flush=True)

            # ê²°ê³¼ ë§¤í•‘ + í”Œë ˆì´ìŠ¤í™€ë” ë³µì›
            for i, item in enumerate(texts):
                if not item.get("has_korean", True):
                    # ì˜ì–´ í…ìŠ¤íŠ¸: ì›ë³¸ ìœ ì§€ (ë²ˆì—­í•˜ì§€ ì•ŠìŒ)
                    translations.append({**item, "translated": item["text"]})
                else:
                    # í•œê¸€ í…ìŠ¤íŠ¸: ë²ˆì—­ ê²°ê³¼ ë§¤í•‘
                    korean_idx = korean_indices.index(i)
                    if korean_idx in trans_dict:
                        translated = trans_dict[korean_idx]
                        # â˜… í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì‚¬ì „ ë²ˆì—­ìœ¼ë¡œ ë³µì›
                        if placeholder_maps[korean_idx]:
                            translated = restore_placeholders(translated, placeholder_maps[korean_idx])
                            print(f"[Claude] Restored placeholders for item {i+1}: {translated[:50]}...", flush=True)
                    else:
                        translated = translate_with_dict(item["text"], target_lang)

                    translations.append({
                        **item,
                        "translated": translated
                    })
        else:
            print(f"[Claude] API error: {response.status_code} - {response.text}", flush=True)
            # fallback: ì‚¬ì „ ë²ˆì—­ (í•œê¸€ë§Œ), ì˜ì–´ëŠ” ì›ë³¸ ìœ ì§€
            for item in texts:
                if item.get("has_korean", True):
                    translated = translate_with_dict(item["text"], target_lang)
                else:
                    translated = item["text"]  # ì˜ì–´ ì›ë³¸ ìœ ì§€
                translations.append({**item, "translated": translated})

    except Exception as e:
        print(f"[Claude] Exception: {e}", flush=True)
        for item in texts:
            if item.get("has_korean", True):
                translated = translate_with_dict(item["text"], target_lang)
            else:
                translated = item["text"]  # ì˜ì–´ ì›ë³¸ ìœ ì§€
            translations.append({**item, "translated": translated})

    total_time = time.time() - api_start
    print(f"[Claude] TOTAL: {total_time:.2f}s for {len(texts)} texts ({len(korean_list)} Korean)", flush=True)
    return translations


def translate_with_openai(image_path, texts, target_lang, api_key, model=None):
    """OpenAI GPT-4 Vision APIë¡œ ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ë²ˆì—­ (Placeholder ë°©ì‹ ì ìš©)"""
    if model is None:
        model = AI_MODELS["openai"]["default"]
    lang_config = LANGUAGE_CONFIG.get(target_lang, LANGUAGE_CONFIG["english"])

    # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
    with open(image_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode()

    translations = []

    # í•œê¸€ í…ìŠ¤íŠ¸ë§Œ í•„í„°ë§ (ì¸ë±ìŠ¤ ë³´ì¡´) - ì˜ì–´ë§Œ ìˆëŠ” í…ìŠ¤íŠ¸ëŠ” ë²ˆì—­í•˜ì§€ ì•ŠìŒ
    korean_items = [(i, item) for i, item in enumerate(texts) if item.get("has_korean", True)]
    korean_list = [item["text"] for _, item in korean_items]
    korean_indices = [i for i, _ in korean_items]
    
    print(f"[OpenAI] Total texts: {len(texts)}, Korean texts to translate: {len(korean_list)}", flush=True)

    # â˜… Placeholder ì „ì²˜ë¦¬: ì‚¬ì „ ìš©ì–´ë¥¼ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ëŒ€ì²´
    preprocessed_list = []
    placeholder_maps = []
    for korean_text in korean_list:
        processed_text, pmap = apply_dict_preprocess(korean_text, target_lang)
        preprocessed_list.append(processed_text)
        placeholder_maps.append(pmap)

    korean_joined = "\n".join([f"{i+1}. {t}" for i, t in enumerate(preprocessed_list)])

    prompt = f"""This is a garment/clothing technical specification image (tech pack).
Translate ALL the following Korean texts to {lang_config['prompt_lang']}. These are garment industry terms.

RULES:
- Translate EVERY item, even if it contains English or numbers
- Use FULL words only, do NOT abbreviate (e.g., "Consumption" not "Cons.", "Management" not "Mgmt.")
- Use format: "1. translation" (number + dot + space + translation)
- Do NOT skip any item
- Do NOT use markdown formatting like **bold**
- CRITICAL: <<TERM_N>> placeholders are pre-translated dictionary terms. Keep them EXACTLY as they are. Do NOT translate, modify, or replace them.

Korean texts:
{korean_joined}

{lang_config['prompt_lang']} translations (translate ALL {len(korean_list)} items):"""

    try:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }

        payload = {
            "model": model,
            "max_tokens": 4096,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{image_data}"
                            }
                        },
                        {
                            "type": "text",
                            "text": prompt
                        }
                    ]
                }
            ]
        }

        response = requests.post(
            OPENAI_API_URL,
            headers=headers,
            json=payload,
            timeout=120
        )

        if response.status_code == 200:
            result = response.json()
            response_text = result.get("choices", [{}])[0].get("message", {}).get("content", "").strip()

            # ì‘ë‹µ íŒŒì‹±
            lines = response_text.split("\n")
            trans_dict = {}
            for line in lines:
                line = line.strip()
                if line and line[0].isdigit():
                    parts = line.split(".", 1)
                    if len(parts) == 2:
                        idx = int(parts[0]) - 1
                        trans = parts[1].strip()
                        if idx < len(korean_list):
                            trans_dict[idx] = trans

            # ê²°ê³¼ ë§¤í•‘ + í”Œë ˆì´ìŠ¤í™€ë” ë³µì›
            for i, item in enumerate(texts):
                if not item.get("has_korean", True):
                    # ì˜ì–´ í…ìŠ¤íŠ¸: ì›ë³¸ ìœ ì§€ (ë²ˆì—­í•˜ì§€ ì•ŠìŒ)
                    translations.append({**item, "translated": item["text"]})
                else:
                    # í•œê¸€ í…ìŠ¤íŠ¸: ë²ˆì—­ ê²°ê³¼ ë§¤í•‘
                    korean_idx = korean_indices.index(i)
                    if korean_idx in trans_dict:
                        translated = trans_dict[korean_idx]
                        # â˜… í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì‚¬ì „ ë²ˆì—­ìœ¼ë¡œ ë³µì›
                        if placeholder_maps[korean_idx]:
                            translated = restore_placeholders(translated, placeholder_maps[korean_idx])
                    else:
                        translated = translate_with_dict(item["text"], target_lang)

                    translations.append({
                        **item,
                        "translated": translated
                    })
        else:
            print(f"OpenAI API error: {response.status_code} - {response.text}")
            # fallback: ì‚¬ì „ ë²ˆì—­ (í•œê¸€ë§Œ), ì˜ì–´ëŠ” ì›ë³¸ ìœ ì§€
            for item in texts:
                if item.get("has_korean", True):
                    translated = translate_with_dict(item["text"], target_lang)
                else:
                    translated = item["text"]
                translations.append({**item, "translated": translated})

    except Exception as e:
        print(f"OpenAI API error: {e}")
        for item in texts:
            if item.get("has_korean", True):
                translated = translate_with_dict(item["text"], target_lang)
            else:
                translated = item["text"]
            translations.append({**item, "translated": translated})

    return translations


def translate_batch_with_gemini(all_pages_texts, target_lang, api_key, model=None):
    """Google Gemini APIë¡œ ëª¨ë“  í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ë²ˆì—­ (ë°°ì¹˜ ëª¨ë“œ, Placeholder ë°©ì‹)

    Args:
        all_pages_texts: [{page_idx: int, texts: [{text, bbox}, ...]}, ...]
        target_lang: ë²ˆì—­ ëŒ€ìƒ ì–¸ì–´
        api_key: Gemini API í‚¤
        model: Gemini ëª¨ë¸ëª…

    Returns:
        {page_idx: [translated_texts], ...}
    """
    import time
    batch_start = time.time()
    
    if model is None:
        model = AI_MODELS["gemini"]["default"]
    lang_config = LANGUAGE_CONFIG.get(target_lang, LANGUAGE_CONFIG["english"])
    
    total_pages = len(all_pages_texts)
    total_texts = sum(len(p["texts"]) for p in all_pages_texts)
    print(f"[Gemini Batch] Starting batch translation: {total_pages} pages, {total_texts} texts", flush=True)

    # ëª¨ë“  í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹¨ (í˜ì´ì§€ êµ¬ë¶„ í¬í•¨)
    all_korean = []
    all_placeholder_maps = []  # â˜… ê° í…ìŠ¤íŠ¸ë³„ í”Œë ˆì´ìŠ¤í™€ë” ë§¤í•‘
    page_text_counts = []  # ê° í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ê°œìˆ˜

    for page_data in all_pages_texts:
        page_texts = page_data["texts"]
        page_text_counts.append(len(page_texts))
        for item in page_texts:
            # â˜… Placeholder ì „ì²˜ë¦¬
            processed_text, pmap = apply_dict_preprocess(item["text"], target_lang)
            all_korean.append(processed_text)
            all_placeholder_maps.append(pmap)

    if not all_korean:
        return {page_data["page_idx"]: [] for page_data in all_pages_texts}

    # ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë²ˆí˜¸ë¡œ ì¡°ì¸
    korean_joined = "\n".join([f"{i+1}. {t}" for i, t in enumerate(all_korean)])

    prompt = f"""This is a garment/clothing technical specification document (tech pack).
Translate ALL the following Korean texts to {lang_config['prompt_lang']}. These are garment industry terms.
Keep translations SHORT and professional. Only respond with numbered translations in {lang_config['prompt_lang']}.
There are {len(all_korean)} items total from multiple pages. Translate ALL of them.
IMPORTANT: Keep <<TERM_N>> placeholders exactly as they are (do not translate them).

Korean texts:
{korean_joined}

{lang_config['prompt_lang']} translations (same numbering 1-{len(all_korean)}, SHORT answers only):"""

    try:
        url = f"{GEMINI_API_URL}/{model}:generateContent?key={api_key}"

        headers = {"Content-Type": "application/json"}

        payload = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {"maxOutputTokens": 8192}
        }

        print(f"[Batch Translation] Sending {len(all_korean)} texts to Gemini...", flush=True)

        response = requests.post(url, headers=headers, json=payload, timeout=180)

        if response.status_code == 200:
            result = response.json()
            response_text = result.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "").strip()

            # ë””ë²„ê¹…: ì›ë³¸ ì‘ë‹µ ì¼ë¶€ ì¶œë ¥
            print(f"[Batch Translation] Response preview (first 500 chars):\n{response_text[:500]}", flush=True)

            # ì‘ë‹µ íŒŒì‹± (ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›: 1. 1) **1.** ë“±)
            lines = response_text.split("\n")
            trans_dict = {}
            for line in lines:
                line = line.strip()
                # ë‹¤ì–‘í•œ ë²ˆí˜¸ í˜•ì‹ ì§€ì›: "1.", "1)", "**1.**", "1 .", "1:", "- 1." ë“±
                match = re.match(r'^[\*\-\s]*(\d+)[\.\)\:\*\s]+(.+)', line)
                if match:
                    try:
                        idx = int(match.group(1)) - 1
                        trans = match.group(2).strip().strip('*').strip()
                        if 0 <= idx < len(all_korean) and trans:
                            trans_dict[idx] = trans
                    except ValueError:
                        continue

            print(f"[Batch Translation] Got {len(trans_dict)}/{len(all_korean)} translations", flush=True)

            # í˜ì´ì§€ë³„ë¡œ ê²°ê³¼ ë¶„ë°°
            result_by_page = {}
            current_idx = 0

            for page_data in all_pages_texts:
                page_idx = page_data["page_idx"]
                page_texts = page_data["texts"]
                page_translations = []

                for item in page_texts:
                    if current_idx in trans_dict:
                        translated = trans_dict[current_idx]
                        # â˜… í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì‚¬ì „ ë²ˆì—­ìœ¼ë¡œ ë³µì›
                        if all_placeholder_maps[current_idx]:
                            translated = restore_placeholders(translated, all_placeholder_maps[current_idx])
                    else:
                        translated = translate_with_dict(item["text"], target_lang)

                    page_translations.append({
                        **item,
                        "translated": translated
                    })
                    current_idx += 1

                result_by_page[page_idx] = page_translations

            total_time = time.time() - batch_start
            print(f"[Gemini Batch] TOTAL: {total_time:.2f}s for {total_pages} pages, {total_texts} texts (1 API call)", flush=True)
            return result_by_page
        else:
            print(f"Gemini Batch API error: {response.status_code} - {response.text}", flush=True)
            # fallback: ì‚¬ì „ ë²ˆì—­
            return _fallback_batch_translation(all_pages_texts, target_lang)

    except Exception as e:
        print(f"Gemini Batch API error: {e}", flush=True)
        return _fallback_batch_translation(all_pages_texts, target_lang)


def _fallback_batch_translation(all_pages_texts, target_lang):
    """ë°°ì¹˜ ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì‚¬ì „ ë²ˆì—­ìœ¼ë¡œ fallback"""
    result_by_page = {}
    for page_data in all_pages_texts:
        page_idx = page_data["page_idx"]
        page_translations = []
        for item in page_data["texts"]:
            translated = translate_with_dict(item["text"], target_lang)
            page_translations.append({**item, "translated": translated})
        result_by_page[page_idx] = page_translations
    return result_by_page


def translate_with_gemini(image_path, texts, target_lang, api_key, model=None):
    """Google Gemini APIë¡œ ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ë²ˆì—­ (Placeholder ë°©ì‹ ì ìš©)"""
    if model is None:
        model = AI_MODELS["gemini"]["default"]
    lang_config = LANGUAGE_CONFIG.get(target_lang, LANGUAGE_CONFIG["english"])

    # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
    with open(image_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode()

    translations = []

    # ëª¨ë“  í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ë²ˆì—­ ìš”ì²­
    korean_list = [item["text"] for item in texts]

    # â˜… Placeholder ì „ì²˜ë¦¬: ì‚¬ì „ ìš©ì–´ë¥¼ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ëŒ€ì²´
    preprocessed_list = []
    placeholder_maps = []
    for korean_text in korean_list:
        processed_text, pmap = apply_dict_preprocess(korean_text, target_lang)
        preprocessed_list.append(processed_text)
        placeholder_maps.append(pmap)

    korean_joined = "\n".join([f"{i+1}. {t}" for i, t in enumerate(preprocessed_list)])

    prompt = f"""This is a garment/clothing technical specification image (tech pack).
Translate ALL the following Korean texts to {lang_config['prompt_lang']}. These are garment industry terms.

RULES:
- Translate EVERY item, even if it contains English or numbers
- Use FULL words only, do NOT abbreviate (e.g., "Consumption" not "Cons.", "Management" not "Mgmt.")
- Use format: "1. translation" (number + dot + space + translation)
- Do NOT skip any item
- Do NOT use markdown formatting like **bold**
- CRITICAL: <<TERM_N>> placeholders are pre-translated dictionary terms. Keep them EXACTLY as they are. Do NOT translate, modify, or replace them.

Korean texts:
{korean_joined}

{lang_config['prompt_lang']} translations (translate ALL {len(korean_list)} items):"""

    try:
        # Gemini API URLì— ëª¨ë¸ëª…ê³¼ API í‚¤ ì¶”ê°€
        url = f"{GEMINI_API_URL}/{model}:generateContent?key={api_key}"

        headers = {
            "Content-Type": "application/json"
        }

        payload = {
            "contents": [
                {
                    "parts": [
                        {
                            "inline_data": {
                                "mime_type": "image/png",
                                "data": image_data
                            }
                        },
                        {
                            "text": prompt
                        }
                    ]
                }
            ],
            "generationConfig": {
                "maxOutputTokens": 4096
            }
        }

        response = requests.post(
            url,
            headers=headers,
            json=payload,
            timeout=120
        )

        if response.status_code == 200:
            result = response.json()
            response_text = result.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "").strip()

            # ì‘ë‹µ íŒŒì‹±
            lines = response_text.split("\n")
            trans_dict = {}
            for line in lines:
                line = line.strip()
                if line and line[0].isdigit():
                    parts = line.split(".", 1)
                    if len(parts) == 2:
                        idx = int(parts[0]) - 1
                        trans = parts[1].strip()
                        if idx < len(korean_list):
                            trans_dict[idx] = trans

            # ê²°ê³¼ ë§¤í•‘ + í”Œë ˆì´ìŠ¤í™€ë” ë³µì›
            for i, item in enumerate(texts):
                if i in trans_dict:
                    translated = trans_dict[i]
                    # â˜… í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì‚¬ì „ ë²ˆì—­ìœ¼ë¡œ ë³µì›
                    if placeholder_maps[i]:
                        translated = restore_placeholders(translated, placeholder_maps[i])
                else:
                    translated = translate_with_dict(item["text"], target_lang)

                translations.append({
                    **item,
                    "translated": translated
                })
        else:
            print(f"Gemini API error: {response.status_code} - {response.text}")
            # fallback: ì‚¬ì „ ë²ˆì—­
            for item in texts:
                translated = translate_with_dict(item["text"], target_lang)
                translations.append({**item, "translated": translated})

    except Exception as e:
        print(f"Gemini API error: {e}")
        for item in texts:
            translated = translate_with_dict(item["text"], target_lang)
            translations.append({**item, "translated": translated})

    return translations


def translate_pages_parallel(pages_data, target_lang, ai_engine, api_key, model, max_workers=3):
    """ë³‘ë ¬ ë²ˆì—­ - ì—¬ëŸ¬ í˜ì´ì§€ë¥¼ ë™ì‹œì— ë²ˆì—­ (Claude, OpenAIìš©)
    
    Args:
        pages_data: [{"page_idx": 0, "img_path": "...", "texts": [...]}, ...]
        target_lang: ëŒ€ìƒ ì–¸ì–´
        ai_engine: AI ì—”ì§„ (claude, openai)
        api_key: API í‚¤
        model: ëª¨ë¸ëª…
        max_workers: ë™ì‹œ ì²˜ë¦¬ ìŠ¤ë ˆë“œ ìˆ˜ (ê¸°ë³¸ 3, API rate limit ê³ ë ¤)
        
    Returns:
        dict: {page_idx: translations, ...}
    """
    import time
    parallel_start = time.time()
    results = {}
    page_times = {}  # ê° í˜ì´ì§€ë³„ ì†Œìš” ì‹œê°„
    
    def translate_single_page(page_data):
        """ë‹¨ì¼ í˜ì´ì§€ ë²ˆì—­ (ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)"""
        page_start = time.time()
        page_idx = page_data["page_idx"]
        img_path = page_data["img_path"]
        texts = page_data["texts"]
        
        if not texts:
            return page_idx, [], 0
        
        try:
            translations = translate_with_vlm(img_path, texts, target_lang, ai_engine, api_key, model)
            elapsed = time.time() - page_start
            print(f"  [Parallel] Page {page_idx+1} done - {len(translations)} texts in {elapsed:.2f}s", flush=True)
            return page_idx, translations, elapsed
        except Exception as e:
            elapsed = time.time() - page_start
            print(f"  [Parallel] Page {page_idx+1} ERROR in {elapsed:.2f}s: {e}", flush=True)
            # ì—ëŸ¬ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
            return page_idx, [{"bbox": t["bbox"], "text": t["text"], "translated": t["text"], 
                             "has_korean": t.get("has_korean", True)} for t in texts], elapsed
    
    total_texts = sum(len(p["texts"]) for p in pages_data)
    print(f"[Parallel Translation] Starting {len(pages_data)} pages ({total_texts} texts) with {max_workers} workers...", flush=True)
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # ëª¨ë“  í˜ì´ì§€ ë²ˆì—­ ì‘ì—… ì œì¶œ
        futures = {executor.submit(translate_single_page, pd): pd["page_idx"] for pd in pages_data}
        
        # ì™„ë£Œë˜ëŠ” ìˆœì„œëŒ€ë¡œ ê²°ê³¼ ìˆ˜ì§‘
        for future in as_completed(futures):
            page_idx, translations, elapsed = future.result()
            results[page_idx] = translations
            page_times[page_idx] = elapsed
    
    total_time = time.time() - parallel_start
    avg_time = sum(page_times.values()) / len(page_times) if page_times else 0
    print(f"[Parallel Translation] TOTAL: {total_time:.2f}s (avg per page: {avg_time:.2f}s, workers: {max_workers})", flush=True)
    return results


def translate_with_vlm(image_path, texts, target_lang, ai_engine="ollama", api_key=None, model=None):
    """VLMìœ¼ë¡œ ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ë²ˆì—­ (Ollama, Claude, GPT-4, Gemini)"""

    # Claude API ì„ íƒ ì‹œ
    if ai_engine == "claude" and api_key:
        return translate_with_claude(image_path, texts, target_lang, api_key, model)

    # OpenAI GPT-4 API ì„ íƒ ì‹œ
    if ai_engine == "openai" and api_key:
        return translate_with_openai(image_path, texts, target_lang, api_key, model)

    # Google Gemini API ì„ íƒ ì‹œ
    if ai_engine == "gemini" and api_key:
        return translate_with_gemini(image_path, texts, target_lang, api_key, model)

    # ê¸°ë³¸: Ollama (Placeholder ë°©ì‹ ì ìš©)
    if model is None:
        model = AI_MODELS["ollama"]["default"]
    lang_config = LANGUAGE_CONFIG.get(target_lang, LANGUAGE_CONFIG["english"])

    # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
    with open(image_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode()

    translations = []

    # ëª¨ë“  í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ë²ˆì—­ ìš”ì²­
    korean_list = [item["text"] for item in texts]

    # â˜… Placeholder ì „ì²˜ë¦¬: ì‚¬ì „ ìš©ì–´ë¥¼ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ëŒ€ì²´
    preprocessed_list = []
    placeholder_maps = []
    for korean_text in korean_list:
        processed_text, pmap = apply_dict_preprocess(korean_text, target_lang)
        preprocessed_list.append(processed_text)
        placeholder_maps.append(pmap)

    korean_joined = "\n".join([f"{i+1}. {t}" for i, t in enumerate(preprocessed_list)])

    prompt = f"""This is a garment/clothing technical specification image (tech pack).
Translate ALL the following Korean texts to {lang_config['prompt_lang']}. These are garment industry terms.

RULES:
- Translate EVERY item, even if it contains English or numbers
- Use FULL words only, do NOT abbreviate (e.g., "Consumption" not "Cons.", "Management" not "Mgmt.")
- Use format: "1. translation" (number + dot + space + translation)
- Do NOT skip any item
- Do NOT use markdown formatting like **bold**
- CRITICAL: <<TERM_N>> placeholders are pre-translated dictionary terms. Keep them EXACTLY as they are. Do NOT translate, modify, or replace them.

Korean texts:
{korean_joined}

{lang_config['prompt_lang']} translations (translate ALL {len(korean_list)} items):"""

    try:
        response = requests.post(
            OLLAMA_URL,
            json={
                "model": model,
                "prompt": prompt,
                "images": [image_data],
                "stream": False
            },
            timeout=120
        )

        if response.status_code == 200:
            result = response.json()
            response_text = result.get("response", "").strip()

            # ì‘ë‹µ íŒŒì‹± (ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
            import re
            lines = response_text.split("\n")
            trans_dict = {}
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                # ë‹¤ì–‘í•œ ë²ˆí˜¸ í˜•ì‹ ì§€ì›: "1. text", "1) text", "**1.** text", "1: text"
                match = re.match(r'^[*]*(\d+)[.*)\]:]+\s*[*]*\s*(.+)', line)
                if match:
                    idx = int(match.group(1)) - 1
                    trans = match.group(2).strip()
                    if idx < len(korean_list):
                        trans_dict[idx] = trans

            # ê²°ê³¼ ë§¤í•‘ + í”Œë ˆì´ìŠ¤í™€ë” ë³µì›
            for i, item in enumerate(texts):
                if i in trans_dict:
                    translated = trans_dict[i]
                    # â˜… í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì‚¬ì „ ë²ˆì—­ìœ¼ë¡œ ë³µì›
                    if placeholder_maps[i]:
                        translated = restore_placeholders(translated, placeholder_maps[i])
                else:
                    translated = translate_with_dict(item["text"], target_lang)

                translations.append({
                    **item,
                    "translated": translated
                })
        else:
            # fallback: ì‚¬ì „ ë²ˆì—­
            for item in texts:
                translated = translate_with_dict(item["text"], target_lang)
                translations.append({**item, "translated": translated})

    except Exception as e:
        print(f"VLM error: {e}")
        for item in texts:
            translated = translate_with_dict(item["text"], target_lang)
            translations.append({**item, "translated": translated})

    return translations


def get_background_color(img, bbox, height, width):
    """bbox ì£¼ë³€ì˜ ë°°ê²½ìƒ‰ì„ ìƒ˜í”Œë§ (ê¸€ìì—ì„œ ë–¨ì–´ì§„ ì˜ì—­ì—ì„œ ìƒ˜í”Œë§)"""
    # bbox ê²½ê³„ ê³„ì‚°
    x_min = int(min(p[0] for p in bbox))
    y_min = int(min(p[1] for p in bbox))
    x_max = int(max(p[0] for p in bbox))
    y_max = int(max(p[1] for p in bbox))

    box_height = y_max - y_min
    box_width = x_max - x_min

    # ìƒ˜í”Œë§ ê±°ë¦¬: bboxì—ì„œ 5-10í”½ì…€ ë–¨ì–´ì§„ ê³³ (ê¸€ìê°€ ì—†ëŠ” ì˜ì—­)
    sample_dist = max(5, min(10, box_height // 3))

    border_pixels = []

    # ìƒë‹¨ ë°”ê¹¥ ì˜ì—­ (bbox ìœ„ sample_dist~sample_dist+3 í”½ì…€)
    sample_y = y_min - sample_dist
    if sample_y >= 3:
        for x in range(max(0, x_min), min(width, x_max)):
            for dy in range(3):
                if sample_y - dy >= 0:
                    border_pixels.append(img[sample_y - dy, x])

    # í•˜ë‹¨ ë°”ê¹¥ ì˜ì—­
    sample_y = y_max + sample_dist
    if sample_y < height - 3:
        for x in range(max(0, x_min), min(width, x_max)):
            for dy in range(3):
                if sample_y + dy < height:
                    border_pixels.append(img[sample_y + dy, x])

    # ì¢Œì¸¡ ë°”ê¹¥ ì˜ì—­
    sample_x = x_min - sample_dist
    if sample_x >= 3:
        for y in range(max(0, y_min), min(height, y_max)):
            for dx in range(3):
                if sample_x - dx >= 0:
                    border_pixels.append(img[y, sample_x - dx])

    # ìš°ì¸¡ ë°”ê¹¥ ì˜ì—­
    sample_x = x_max + sample_dist
    if sample_x < width - 3:
        for y in range(max(0, y_min), min(height, y_max)):
            for dx in range(3):
                if sample_x + dx < width:
                    border_pixels.append(img[y, sample_x + dx])

    if border_pixels:
        # í°ìƒ‰/ë°ì€ ê³„ì—´ í”½ì…€ë§Œ í•„í„°ë§ (RGB ê° ì±„ë„ì´ 180 ì´ìƒ)
        bright_pixels = [p for p in border_pixels if all(c >= 180 for c in p)]
        if bright_pixels:
            # ê°€ì¥ ë°ì€ í”½ì…€ë“¤ì˜ í‰ê·  ì‚¬ìš©
            bg_color = np.mean(bright_pixels, axis=0).astype(np.uint8)
        else:
            # ë°ì€ í”½ì…€ì´ ì—†ìœ¼ë©´ ì „ì²´ í‰ê· 
            bg_color = np.mean(border_pixels, axis=0).astype(np.uint8)
    else:
        bg_color = np.array([255, 255, 255], dtype=np.uint8)

    return bg_color


def get_background_color_from_edges(img, bbox, margin=10):
    """bbox ì£¼ë³€ ê°€ì¥ìë¦¬ì—ì„œ ë°°ê²½ìƒ‰ ìƒ˜í”Œë§"""
    from collections import Counter

    height, width = img.shape[:2]
    x_min = int(min(p[0] for p in bbox))
    y_min = int(min(p[1] for p in bbox))
    x_max = int(max(p[0] for p in bbox))
    y_max = int(max(p[1] for p in bbox))

    edge_pixels = []

    # ìƒë‹¨ ê°€ì¥ìë¦¬ (margin í”½ì…€ ìœ„)
    sample_y = max(0, y_min - margin)
    for x in range(max(0, x_min), min(width, x_max)):
        pixel = tuple(img[sample_y, x])
        edge_pixels.append(pixel)

    # í•˜ë‹¨ ê°€ì¥ìë¦¬ (margin í”½ì…€ ì•„ë˜)
    sample_y = min(height - 1, y_max + margin)
    for x in range(max(0, x_min), min(width, x_max)):
        pixel = tuple(img[sample_y, x])
        edge_pixels.append(pixel)

    # ì¢Œì¸¡ ê°€ì¥ìë¦¬ (margin í”½ì…€ ì™¼ìª½)
    sample_x = max(0, x_min - margin)
    for y in range(max(0, y_min), min(height, y_max)):
        pixel = tuple(img[y, sample_x])
        edge_pixels.append(pixel)

    # ìš°ì¸¡ ê°€ì¥ìë¦¬ (margin í”½ì…€ ì˜¤ë¥¸ìª½)
    sample_x = min(width - 1, x_max + margin)
    for y in range(max(0, y_min), min(height, y_max)):
        pixel = tuple(img[y, sample_x])
        edge_pixels.append(pixel)

    if edge_pixels:
        # ê°€ì¥ ë§ì´ ë“±ì¥í•˜ëŠ” ìƒ‰ìƒ ì„ íƒ
        most_common = Counter(edge_pixels).most_common(1)[0][0]
        return most_common

    return (255, 255, 255)  # ê¸°ë³¸ê°’: í°ìƒ‰


def erase_text_region(img, bbox):
    """í…ìŠ¤íŠ¸ ì˜ì—­ë§Œ ì§€ìš°ê¸° (ì„ ì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ) - v1.4.4"""
    height, width = img.shape[:2]

    # bbox ê²½ê³„ ê³„ì‚°
    x_min = int(min(p[0] for p in bbox))
    y_min = int(min(p[1] for p in bbox))
    x_max = int(max(p[0] for p in bbox))
    y_max = int(max(p[1] for p in bbox))

    # â˜… Yì¶•ë§Œ ì¶•ì†Œí•˜ì—¬ ìˆ˜í‰ì„ (ì…€ ê²½ê³„) ë³´í˜¸
    # margin_x = 1: Xì¶•ì€ ê¸°ì¡´ëŒ€ë¡œ ì•½ê°„ í™•ì¥
    # margin_y = -2: Yì¶•ì€ ì•ˆìª½ìœ¼ë¡œ ì¶•ì†Œ (ìœ„ì•„ë˜ 2pxì”© ë³´í˜¸)
    margin_x = 1
    margin_y = -2
    x_min_ext = max(0, x_min - margin_x)
    y_min_ext = max(0, y_min - margin_y)  # y_min + 3 (ì•„ë˜ë¡œ ì¶•ì†Œ)
    x_max_ext = min(width, x_max + margin_x)
    y_max_ext = min(height, y_max + margin_y)  # y_max - 3 (ìœ„ë¡œ ì¶•ì†Œ)

    # ë°°ê²½ìƒ‰ ìƒ˜í”Œë§
    bg_color = sample_background_color(img, bbox, height, width)

    # â˜… bbox ë‚´ë¶€ë§Œ ë°°ê²½ìƒ‰ìœ¼ë¡œ ì±„ìš°ê¸° (ì„ ì€ bbox ë°”ê¹¥ì´ë¯€ë¡œ ì•ˆì „)
    cv2.rectangle(img, (x_min_ext, y_min_ext), (x_max_ext, y_max_ext), bg_color, -1)

    return img, bg_color


def sample_background_color(img, bbox, height, width):
    """bbox ë‚´ë¶€ì—ì„œ ê°€ì¥ ë§ì´ ë“±ì¥í•˜ëŠ” ìƒ‰ìƒì„ ë°°ê²½ìƒ‰ìœ¼ë¡œ íŒë‹¨

    ì›ë¦¬: í…ìŠ¤íŠ¸ë³´ë‹¤ ë°°ê²½ í”½ì…€ì´ ë” ë§ìœ¼ë¯€ë¡œ ìµœë¹ˆê°’ = ë°°ê²½ìƒ‰
    """
    x_min = int(min(p[0] for p in bbox))
    y_min = int(min(p[1] for p in bbox))
    x_max = int(max(p[0] for p in bbox))
    y_max = int(max(p[1] for p in bbox))

    # bbox ë‚´ë¶€ í”½ì…€ ìƒ˜í”Œë§
    samples = []
    for y in range(max(0, y_min), min(height, y_max), 2):
        for x in range(max(0, x_min), min(width, x_max), 2):
            pixel = tuple(img[y, x].tolist())
            samples.append(pixel)

    if samples:
        # ê°€ì¥ ë§ì´ ë“±ì¥í•˜ëŠ” ìƒ‰ìƒ = ë°°ê²½ìƒ‰
        most_common = Counter(samples).most_common(1)[0][0]
        return most_common

    return (255, 255, 255)  # ê¸°ë³¸: í°ìƒ‰


def get_text_color_for_background(bg_color):
    """ë°°ê²½ìƒ‰ì— ë”°ë¼ ì ì ˆí•œ í…ìŠ¤íŠ¸ ìƒ‰ìƒ ë°˜í™˜ (ë°ì€ ë°°ê²½ â†’ ê²€ì •, ì–´ë‘ìš´ ë°°ê²½ â†’ í°ìƒ‰)"""
    # BGR to grayscale luminance
    if isinstance(bg_color, (list, tuple, np.ndarray)):
        # OpenCV BGR ìˆœì„œ
        b, g, r = bg_color[0], bg_color[1], bg_color[2]
        luminance = 0.299 * r + 0.587 * g + 0.114 * b
    else:
        luminance = bg_color

    # ë°ê¸° ì„ê³„ê°’: 128 (ì¤‘ê°„ê°’)
    if luminance < 128:
        return (255, 255, 255)  # ì–´ë‘ìš´ ë°°ê²½ â†’ í°ìƒ‰ í…ìŠ¤íŠ¸
    else:
        return (0, 0, 0)  # ë°ì€ ë°°ê²½ â†’ ê²€ì • í…ìŠ¤íŠ¸


def check_bbox_overlap(bbox1, bbox2):
    """ë‘ bboxê°€ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸

    Args:
        bbox1: (x, y, width, height) í˜•íƒœì˜ íŠœí”Œ
        bbox2: (x, y, width, height) í˜•íƒœì˜ íŠœí”Œ

    Returns:
        bool: ê²¹ì¹˜ë©´ True
    """
    x1, y1, w1, h1 = bbox1
    x2, y2, w2, h2 = bbox2

    # ê²¹ì¹¨ ì—†ìŒ ì¡°ê±´ (í•˜ë‚˜ë¼ë„ ë§Œì¡±í•˜ë©´ ê²¹ì¹˜ì§€ ì•ŠìŒ)
    if x1 + w1 <= x2 or x2 + w2 <= x1:  # ì¢Œìš°ë¡œ ë¶„ë¦¬
        return False
    if y1 + h1 <= y2 or y2 + h2 <= y1:  # ìƒí•˜ë¡œ ë¶„ë¦¬
        return False
    return True


def abbreviate_text(text, used_abbreviations, target_lang="english"):
    """ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì•½ì–´ë¡œ ì¶•ì•½ (ì‚¬ì „ ê¸°ë°˜)

    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
        used_abbreviations: ì‚¬ìš©ëœ ì•½ì–´ ì¶”ì ìš© set (ìˆ˜ì •ë¨)
        target_lang: ëŒ€ìƒ ì–¸ì–´ (ì‚¬ì „ì—ì„œ ì•½ì–´ ì¡°íšŒìš©)

    Returns:
        str: ì¶•ì•½ëœ í…ìŠ¤íŠ¸
    """
    result = text
    
    # ì‚¬ì „ì—ì„œ ì•½ì–´ ì¡°íšŒ
    if target_lang in GARMENT_DICT:
        lang_dict = GARMENT_DICT[target_lang]
        for korean_term, term_data in lang_dict.items():
            if isinstance(term_data, dict):
                full_text = term_data.get("full", "")
                abbr = term_data.get("abbr", "")
                if abbr and full_text in result:
                    result = result.replace(full_text, abbr)
                    used_abbreviations.add((abbr, full_text))  # (ì•½ì–´, ì›ë¬¸) ì €ì¥
    
    return result


def find_bottom_empty_area(image_height, all_bboxes, required_height=25):
    """ì´ë¯¸ì§€ í•˜ë‹¨ì—ì„œ ë¹ˆ ê³µê°„ ì°¾ê¸°

    Args:
        image_height: ì´ë¯¸ì§€ ì „ì²´ ë†’ì´
        all_bboxes: ëª¨ë“  í…ìŠ¤íŠ¸ bbox ë¦¬ìŠ¤íŠ¸ [(x, y, w, h), ...]
        required_height: í•„ìš”í•œ ìµœì†Œ ë†’ì´ (ê¸°ë³¸ 25px)

    Returns:
        int or None: ë²”ë¡€ë¥¼ ë„£ì„ yì¢Œí‘œ, ê³µê°„ ì—†ìœ¼ë©´ None
    """
    if not all_bboxes:
        return image_height - required_height - 5

    # ëª¨ë“  bbox ì¤‘ ê°€ì¥ ì•„ë˜ yì¢Œí‘œ ì°¾ê¸°
    max_y = 0
    for bbox in all_bboxes:
        y = bbox[1] + bbox[3]  # y + height
        if y > max_y:
            max_y = y

    # í•˜ë‹¨ ì—¬ë°±ì´ required_height ì´ìƒì´ë©´ ì‚¬ìš© ê°€ëŠ¥
    if image_height - max_y >= required_height + 10:  # 10px ì¶”ê°€ ë§ˆì§„
        return max_y + 5  # ë§ˆì§€ë§‰ í…ìŠ¤íŠ¸ ì•„ë˜ 5px

    return None  # ê³µê°„ ì—†ìŒ


def render_legend(draw, used_abbreviations, image_width, legend_y, font_size=8):
    """ë²”ë¡€ë¥¼ ì´ë¯¸ì§€ í•˜ë‹¨ ì¤‘ì•™ì— ë Œë”ë§

    Args:
        draw: PIL ImageDraw ê°ì²´
        used_abbreviations: {(ì•½ì–´, ì›ë¬¸), ...} set
        image_width: ì´ë¯¸ì§€ ë„ˆë¹„
        legend_y: ë²”ë¡€ë¥¼ ë„£ì„ yì¢Œí‘œ
        font_size: í°íŠ¸ í¬ê¸° (ê¸°ë³¸ 8)
    """
    if not used_abbreviations:
        return

    # ë²”ë¡€ í…ìŠ¤íŠ¸ ìƒì„±: "* G.M=Garment Matching, A.M=Accessory Matching"
    legend_parts = [f"{abbr}={full}" for abbr, full in sorted(used_abbreviations)]
    legend_text = "* " + ", ".join(legend_parts)

    # í°íŠ¸ ë¡œë“œ
    try:
        font = ImageFont.truetype("malgun.ttf", font_size)
    except:
        try:
            font = ImageFont.truetype("C:/Windows/Fonts/malgun.ttf", font_size)
        except:
            font = ImageFont.load_default()

    # í…ìŠ¤íŠ¸ ë„ˆë¹„ ê³„ì‚°
    text_bbox = draw.textbbox((0, 0), legend_text, font=font)
    text_width = text_bbox[2] - text_bbox[0]

    # ì¤‘ì•™ ì •ë ¬
    x = (image_width - text_width) // 2

    # íšŒìƒ‰ìœ¼ë¡œ ì‘ê²Œ ë Œë”ë§
    draw.text((x, legend_y), legend_text, fill=(128, 128, 128), font=font)


def is_vertical_text(bbox):
    """ì„¸ë¡œ í…ìŠ¤íŠ¸ ì—¬ë¶€ íŒë‹¨ - ë†’ì´ê°€ ë„ˆë¹„ì˜ 2ë°° ì´ìƒì´ë©´ ì„¸ë¡œ"""
    xs = [p[0] for p in bbox]
    ys = [p[1] for p in bbox]
    box_width = max(xs) - min(xs)
    box_height = max(ys) - min(ys)
    return box_height > box_width * 2


def draw_vertical_text(draw, text, x, y, font, fill, box_width, box_height):
    """ì„¸ë¡œ í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° - ê¸€ìë¥¼ í•˜ë‚˜ì”© ì„¸ë¡œë¡œ ë°°ì¹˜"""
    # ê¸€ìë‹¹ ë†’ì´ ê³„ì‚°
    char_height = box_height / max(len(text), 1)
    
    # í°íŠ¸ í¬ê¸° ì¡°ì • (ê¸€ìë‹¹ ê³µê°„ì— ë§ê²Œ)
    font_size = min(int(char_height * 0.9), int(box_width * 0.9))
    font_size = max(font_size, 6)  # ìµœì†Œ 6px
    
    try:
        adjusted_font = ImageFont.truetype("malgun.ttf", font_size)
    except:
        try:
            adjusted_font = ImageFont.truetype("C:/Windows/Fonts/malgun.ttf", font_size)
        except:
            adjusted_font = font
    
    # ê° ê¸€ìë¥¼ ì„¸ë¡œë¡œ ë°°ì¹˜
    current_y = y
    for char in text:
        # ê¸€ì ì¤‘ì•™ ì •ë ¬ (xì¶•)
        char_bbox = draw.textbbox((0, 0), char, font=adjusted_font)
        char_width = char_bbox[2] - char_bbox[0]
        char_x = x + (box_width - char_width) // 2
        
        draw.text((char_x, current_y), char, fill=fill, font=adjusted_font)
        current_y += char_height


def replace_text_in_image(image_path, translations, output_path, target_lang="english"):
    """ì´ë¯¸ì§€ì—ì„œ í•œê¸€ ì˜ì—­ì„ ì§€ìš°ê³  ë²ˆì—­ëœ í…ìŠ¤íŠ¸ë¡œ êµì²´ - v1.8.2 (ì˜ì–´ í…ìŠ¤íŠ¸ ìœ ì§€, ê²¹ì¹¨ ê°ì§€ìš© í¬í•¨)"""
    img = cv2.imread(image_path)
    height, width = img.shape[:2]
    
    # â˜… í…Œì´ë¸” ì˜ì—­ ê°ì§€ (ì¤‘ì•™ ì •ë ¬ ì ìš© ì—¬ë¶€ íŒë‹¨ìš©)
    table_regions = detect_table_regions(image_path)

    # 1ë‹¨ê³„: í•œê¸€ í…ìŠ¤íŠ¸ ì˜ì—­ë§Œ ë°°ê²½ìƒ‰ìœ¼ë¡œ ì§€ìš°ê¸° (ì˜ì–´ëŠ” ì›ë³¸ ìœ ì§€)
    bg_colors = {}
    for i, item in enumerate(translations):
        if item.get("has_korean", True):  # í•œê¸€ í…ìŠ¤íŠ¸ë§Œ erase
            bbox = item["bbox"]
            img, bg_color = erase_text_region(img, bbox)
            bg_colors[i] = bg_color
        else:
            bg_colors[i] = (255, 255, 255)  # ì˜ì–´ í…ìŠ¤íŠ¸ëŠ” erase ì•ˆ í•¨

    # 2ë‹¨ê³„: í…ìŠ¤íŠ¸ ì •ë³´ ì‚¬ì „ ê³„ì‚° (ê²¹ì¹¨ ê°ì§€ìš©)
    font_sizes = [13, 12, 11, 10, 9, 8, 7]  # í°íŠ¸ í¬ê¸° ì•½ê°„ ì¦ê°€
    text_render_info = []

    img_pil_temp = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw_temp = ImageDraw.Draw(img_pil_temp)

    for i, item in enumerate(translations):
        bbox = item["bbox"]
        translated_text = item["translated"]

        xs = [p[0] for p in bbox]
        ys = [p[1] for p in bbox]
        box_width = max(xs) - min(xs)
        box_height = max(ys) - min(ys)

        x = int(min(xs))
        y = int(min(ys))

        font = None
        text_width = 0
        for size in font_sizes:
            try:
                font = ImageFont.truetype("malgun.ttf", size)
            except:
                try:
                    font = ImageFont.truetype("C:/Windows/Fonts/malgun.ttf", size)
                except:
                    font = ImageFont.load_default()
                    break

            text_bbox_size = draw_temp.textbbox((0, 0), translated_text, font=font, anchor="lt")
            text_width = text_bbox_size[2] - text_bbox_size[0]
            selected_text_height = text_bbox_size[3] - text_bbox_size[1]

            if selected_text_height <= box_height:  # ì…€ ë†’ì´ì— ë§ì¶¤ (í´ë¦¬í•‘ìœ¼ë¡œ ê²½ê³„ ì²˜ë¦¬)
                break

        text_bbox_actual = draw_temp.textbbox((0, 0), translated_text, font=font, anchor="lt")
        actual_text_width = text_bbox_actual[2] - text_bbox_actual[0]
        actual_text_height = text_bbox_actual[3] - text_bbox_actual[1]
        text_top_offset = text_bbox_actual[1]  # textbboxì˜ top offset (ê¸€ë¦¬í”„ ìƒë‹¨ê¹Œì§€ ê±°ë¦¬)

        # â˜… ìŠ¤ì¼€ì¼ë§ ë°˜ì˜: í…ìŠ¤íŠ¸ê°€ ì…€ë³´ë‹¤ í¬ë©´ ë¦¬ì‚¬ì´ì¦ˆëœ í­/ë†’ì´ ê³„ì‚°
        if actual_text_height > box_height:
            ratio = box_height / actual_text_height
            text_width = max(1, int(actual_text_width * ratio))  # ìŠ¤ì¼€ì¼ë§ëœ í­
            render_height = box_height
            actual_text_height = box_height # ì •ë³´ ì—…ë°ì´íŠ¸
        else:
            text_width = actual_text_width # ì›ë³¸ í­
            render_height = actual_text_height

        # Yì¶• ì¤‘ì•™ ì •ë ¬: ì…€ ì¤‘ì•™ì— í…ìŠ¤íŠ¸ ì¤‘ì•™ì„ ë§ì¶¤
        cell_top = int(min(ys))
        cell_center = cell_top + box_height // 2
        y_adjusted = cell_center - render_height // 2 - text_top_offset + 1  # +1: í…ìŠ¤íŠ¸ë¥¼ ì•½ê°„ ì•„ë˜ë¡œ

        bg_color = bg_colors.get(i, (255, 255, 255))
        is_vertical = is_vertical_text(bbox)
        # ê²¹ì¹¨ ê°ì§€ìš©: OCR bbox ì‚¬ìš© (ê°™ì€ í–‰ íŒë‹¨ì„ ìœ„í•´ ì›ë³¸ ì¢Œí‘œ ì‚¬ìš©)
        cell_bbox = (x, int(min(ys)), box_width, box_height)
        # â˜… í…Œì´ë¸” ì•ˆì— ìˆëŠ”ì§€ í™•ì¸
        in_table = is_inside_table(bbox, table_regions)

        text_render_info.append({
            'x': x, 'y': y, 'y_adjusted': y_adjusted,
            'text': translated_text, 'font': font,
            'text_width': text_width, 'text_height': actual_text_height,
            'cell_bbox': cell_bbox, 'bg_color': bg_color,
            'is_vertical': is_vertical, 'bbox': bbox,
            'has_korean': item.get("has_korean", True),  # í•œê¸€ í¬í•¨ ì—¬ë¶€ í”Œë˜ê·¸
            'is_in_table': in_table  # â˜… í…Œì´ë¸” ë‚´ ì—¬ë¶€
        })

    # 3ë‹¨ê³„: ê²¹ì¹¨ ê°ì§€ - ì™¼ìª½ í…ìŠ¤íŠ¸ê°€ ì˜¤ë¥¸ìª½ ì…€ì„ ì¹¨ë²”í•˜ëŠ”ì§€ ì²´í¬
    needs_abbreviation = set()
    logger.info(f"\n{'='*60}")
    logger.info(f"[Overlap Detection - replace] Total texts: {len(text_render_info)}")
    logger.info(f"{'='*60}")
    
    # 3-1: ì…€ ê²½ê³„ ì´ˆê³¼ ì²´í¬ (OCR ë¯¸ì¸ì‹ í…ìŠ¤íŠ¸ ëŒ€ì‘)
    OVERFLOW_THRESHOLD = 30  # 30px ì´ìƒ ì´ˆê³¼ì‹œ ë¬´ì¡°ê±´ ì¶•ì•½
    for i, info in enumerate(text_render_info):
        text_right_edge = info['x'] + info['text_width']
        cell_x, cell_y, cell_w, cell_h = info['cell_bbox']
        cell_right = cell_x + cell_w
        overflow = text_right_edge - cell_right
        if overflow > OVERFLOW_THRESHOLD:
            needs_abbreviation.add(i)
            logger.info(f"  â˜… OVERFLOW ABBREVIATE #{i} '{info['text'][:20]}' | overflow={overflow}px > {OVERFLOW_THRESHOLD}px")
    
    # 3-2: ì¸ì ‘ í…ìŠ¤íŠ¸ ì¹¨ë²” ì²´í¬
    for i, info in enumerate(text_render_info):
        text_right_edge = info['x'] + info['text_width']
        cell_x, cell_y, cell_w, cell_h = info['cell_bbox']
        logger.debug(f"[#{i}] '{info['text'][:30]}' | x={info['x']}, w={info['text_width']}, right={text_right_edge} | cell=({cell_x},{cell_y},{cell_w},{cell_h})")

        for j, other_info in enumerate(text_render_info):
            if i == j:
                continue
            other_cell_left = other_info['cell_bbox'][0]

            # í˜„ì¬ í…ìŠ¤íŠ¸ê°€ ì˜¤ë¥¸ìª½ ì…€ì˜ ì‹œì‘ì ì„ ì¹¨ë²”í–ˆëŠ”ì§€
            if text_right_edge > other_cell_left and info['x'] < other_cell_left:
                # Yì¶• ê²¹ì¹¨ ì²´í¬ (ê°™ì€ í–‰ì¸ì§€)
                my_y = info['cell_bbox'][1]
                my_h = info['cell_bbox'][3]
                other_y = other_info['cell_bbox'][1]
                other_h = other_info['cell_bbox'][3]

                y_overlap = not (my_y + my_h <= other_y or other_y + other_h <= my_y)
                logger.info(f"  â†’ #{i} INVADES #{j} '{other_info['text'][:20]}' | other_left={other_cell_left}")
                logger.info(f"     my_y={my_y}, my_h={my_h} (range: {my_y}~{my_y+my_h})")
                logger.info(f"     other_y={other_y}, other_h={other_h} (range: {other_y}~{other_y+other_h})")
                logger.info(f"     y_overlap={y_overlap}")

                if y_overlap:
                    needs_abbreviation.add(i)  # ì¹¨ë²”í•œ ìª½(ì™¼ìª½)ì„ ì•½ì–´ë¡œ
                    logger.info(f"  â˜… ABBREVIATE #{i}")
                    break
    logger.info(f"[Overlap Result] needs_abbreviation: {needs_abbreviation}")
    logger.info(f"{'='*60}\n")

    # 4ë‹¨ê³„: ì‹¤ì œ ë Œë”ë§
    img_result = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_result)

    used_abbreviations = set()
    all_text_bboxes = []

    for i, info in enumerate(text_render_info):
        # â˜… ì˜ì–´ í…ìŠ¤íŠ¸ëŠ” ë Œë”ë§ ê±´ë„ˆë›°ê¸° (ì›ë³¸ ìœ ì§€)
        if not info.get('has_korean', True):
            continue
            
        display_text = info['text']

        if i in needs_abbreviation:
            display_text = abbreviate_text(info['text'], used_abbreviations, target_lang)

        text_color = get_text_color_for_background(info['bg_color'])
        text_color_rgb = (text_color[2], text_color[1], text_color[0]) if text_color == (255, 255, 255) else text_color

        if info['is_vertical']:
            draw_vertical_text(draw, display_text, info['x'], info['y'], info['font'],
                             text_color_rgb, info['cell_bbox'][2], info['cell_bbox'][3])
        else:
            # í´ë¦¬í•‘: í…ìŠ¤íŠ¸ë¥¼ ì„ì‹œ ì´ë¯¸ì§€ì— ê·¸ë¦° í›„ ì…€ ë†’ì´ë§Œí¼ë§Œ ì˜ë¼ì„œ ë¶™ì„
            cell_left = info['cell_bbox'][0]
            cell_top = info['cell_bbox'][1]
            cell_width = info['cell_bbox'][2]
            cell_height = info['cell_bbox'][3]

            # í…ìŠ¤íŠ¸ bbox ê³„ì‚° (ì¶©ë¶„í•œ ì—¬ë°±ì—ì„œ)
            margin = 50
            text_bbox_temp = draw.textbbox((margin, margin), display_text, font=info['font'], anchor="lt")
            text_width_temp = text_bbox_temp[2] - text_bbox_temp[0]
            text_height_temp = text_bbox_temp[3] - text_bbox_temp[1]
            text_left = text_bbox_temp[0]
            text_top = text_bbox_temp[1]

            # ì„ì‹œ ì´ë¯¸ì§€ ìƒì„± (ì¶©ë¶„íˆ í¬ê²Œ)
            temp_img = Image.new('RGBA', (text_width_temp + margin * 2, text_height_temp + margin * 2), (0, 0, 0, 0))
            temp_draw = ImageDraw.Draw(temp_img)
            temp_draw.text((margin, margin), display_text, fill=text_color_rgb, font=info['font'], anchor="lt")

            # ì‹¤ì œ í…ìŠ¤íŠ¸ ì˜ì—­ë§Œ crop
            temp_img = temp_img.crop((text_left, text_top, text_bbox_temp[2], text_bbox_temp[3]))

            # ì…€ ë†’ì´ì— ë§ì¶° ì¶”ê°€ crop ë° ìœ„ì¹˜ ê³„ì‚°
            y_offset = 2  # ê¸€ìë¥¼ ì•„ë˜ë¡œ ë‚´ë¦¬ëŠ” ì˜¤í”„ì…‹ (í”½ì…€)
            if text_height_temp > cell_height:
                # í…ìŠ¤íŠ¸ê°€ ì…€ë³´ë‹¤ í¼ â†’ LANCZOS ë¦¬ì‚¬ì´ì¦ˆ (ì˜ë¦¼ ë°©ì§€)
                ratio = cell_height / text_height_temp
                new_width = max(1, int(text_width_temp * ratio))
                new_height = cell_height
                
                # ë¦¬ì‚¬ì´ì¦ˆ
                try:
                    resample_filter = Image.Resampling.LANCZOS
                except AttributeError:
                    resample_filter = Image.LANCZOS
                
                temp_img = temp_img.resize((new_width, new_height), resample=resample_filter)
                
                # ë¶™ì—¬ë„£ê¸° ìœ„ì¹˜ (resize í–ˆìœ¼ë¯€ë¡œ crop ë¶ˆí•„ìš”)
                paste_y = cell_top + y_offset
                
                # ë¦¬ì‚¬ì´ì¦ˆëœ í¬ê¸°ë¡œ ì—…ë°ì´íŠ¸ (ì •ë ¬ìš©)
                text_width_temp = new_width
                text_height_temp = new_height
            else:
                # í…ìŠ¤íŠ¸ê°€ ì…€ë³´ë‹¤ ì‘ìŒ â†’ ì…€ ì¤‘ì•™ì— ë°°ì¹˜
                paste_y = cell_top + (cell_height - text_height_temp) // 2 + y_offset

            # â˜… Xì¶• ì •ë ¬: í…Œì´ë¸” ì•ˆì´ë©´ ì¤‘ì•™, ì•„ë‹ˆë©´ ì™¼ìª½
            if info.get('is_in_table', False):
                # í…Œì´ë¸” ë‚´ í…ìŠ¤íŠ¸ â†’ ì¤‘ì•™ ì •ë ¬
                original_center_x = cell_left + cell_width // 2
                paste_x = original_center_x - text_width_temp // 2
                # ì™¼ìª½ ê²½ê³„ ì œí•œ
                if paste_x < cell_left:
                    paste_x = cell_left
            else:
                # í…Œì´ë¸” ë°– í…ìŠ¤íŠ¸ â†’ ì™¼ìª½ ì •ë ¬
                paste_x = info['x']

            # ì›ë³¸ ì´ë¯¸ì§€ì— ë¶™ì—¬ë„£ê¸°
            img_result.paste(temp_img, (paste_x, paste_y), temp_img)

        text_bbox_new = draw.textbbox((0, 0), display_text, font=info['font'])
        new_width = text_bbox_new[2] - text_bbox_new[0]
        all_text_bboxes.append((info['x'], info['y_adjusted'], new_width, info['text_height']))

    # â˜… ë²”ë¡€ ë Œë”ë§ (ì•½ì–´ ì‚¬ìš© ì‹œ)
    if used_abbreviations:
        legend_y = find_bottom_empty_area(height, all_text_bboxes)
        if legend_y is not None:
            render_legend(draw, used_abbreviations, width, legend_y)

    img_result.save(output_path)
    return output_path


def generate_preview_image(image_base64, translations, target_lang='english'):
    """ë¯¸ë¦¬ë³´ê¸° ì´ë¯¸ì§€ ìƒì„± (ë©”ëª¨ë¦¬ì—ì„œ ì²˜ë¦¬) - v1.8.0 (ê²¹ì¹¨ ê°ì§€ + ì•½ì–´)"""
    # base64 ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
    image_data = base64.b64decode(image_base64)
    nparr = np.frombuffer(image_data, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    height, width = img.shape[:2]
    
    # â˜… í…Œì´ë¸” ì˜ì—­ ê°ì§€ (ì¤‘ì•™ ì •ë ¬ ì ìš© ì—¬ë¶€ íŒë‹¨ìš©)
    temp_img_path = os.path.join(UPLOAD_FOLDER, f"temp_table_detect_{id(image_base64)}.png")
    cv2.imwrite(temp_img_path, img)
    table_regions = detect_table_regions(temp_img_path)
    try:
        os.remove(temp_img_path)
    except:
        pass

    # 1ë‹¨ê³„: í•œê¸€ í…ìŠ¤íŠ¸ ì˜ì—­ë§Œ ë°°ê²½ìƒ‰ìœ¼ë¡œ ì§€ìš°ê¸° (ì˜ì–´ëŠ” ì›ë³¸ ìœ ì§€)
    bg_colors = {}
    for i, item in enumerate(translations):
        if item.get("has_korean", True):  # í•œê¸€ í…ìŠ¤íŠ¸ë§Œ erase
            bbox = item["bbox"]
            img, bg_color = erase_text_region(img, bbox)
            bg_colors[i] = bg_color
        else:
            bg_colors[i] = (255, 255, 255)  # ì˜ì–´ í…ìŠ¤íŠ¸ëŠ” erase ì•ˆ í•¨

    # 2ë‹¨ê³„: í…ìŠ¤íŠ¸ ì •ë³´ ì‚¬ì „ ê³„ì‚° (ê²¹ì¹¨ ê°ì§€ìš©)
    font_sizes = [13, 12, 11, 10, 9, 8, 7]  # í°íŠ¸ í¬ê¸° ì•½ê°„ ì¦ê°€
    text_render_info = []  # [(x, y_adjusted, text, font, text_width, height, cell_bbox, bg_color, is_vertical)]

    img_pil_temp = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw_temp = ImageDraw.Draw(img_pil_temp)

    for i, item in enumerate(translations):
        bbox = item["bbox"]
        translated_text = item.get("translated", item.get("text", ""))

        xs = [p[0] for p in bbox]
        ys = [p[1] for p in bbox]
        box_width = max(xs) - min(xs)
        box_height = max(ys) - min(ys)

        x = int(min(xs))
        y = int(min(ys))

        font = None
        text_width = 0
        for size in font_sizes:
            try:
                font = ImageFont.truetype("malgun.ttf", size)
            except:
                try:
                    font = ImageFont.truetype("C:/Windows/Fonts/malgun.ttf", size)
                except:
                    font = ImageFont.load_default()
                    break

            text_bbox_size = draw_temp.textbbox((0, 0), translated_text, font=font, anchor="lt")
            text_width = text_bbox_size[2] - text_bbox_size[0]
            selected_text_height = text_bbox_size[3] - text_bbox_size[1]

            if selected_text_height <= box_height:  # ì…€ ë†’ì´ì— ë§ì¶¤ (í´ë¦¬í•‘ìœ¼ë¡œ ê²½ê³„ ì²˜ë¦¬)
                break

        text_bbox_actual = draw_temp.textbbox((0, 0), translated_text, font=font, anchor="lt")
        actual_text_width = text_bbox_actual[2] - text_bbox_actual[0]
        actual_text_height = text_bbox_actual[3] - text_bbox_actual[1]
        text_top_offset = text_bbox_actual[1]  # textbboxì˜ top offset (ê¸€ë¦¬í”„ ìƒë‹¨ê¹Œì§€ ê±°ë¦¬)

        # â˜… ìŠ¤ì¼€ì¼ë§ ë°˜ì˜: í…ìŠ¤íŠ¸ê°€ ì…€ë³´ë‹¤ í¬ë©´ ë¦¬ì‚¬ì´ì¦ˆëœ í­/ë†’ì´ ê³„ì‚°
        if actual_text_height > box_height:
            ratio = box_height / actual_text_height
            text_width = max(1, int(actual_text_width * ratio))  # ìŠ¤ì¼€ì¼ë§ëœ í­
            render_height = box_height
            actual_text_height = box_height # ì •ë³´ ì—…ë°ì´íŠ¸
        else:
            text_width = actual_text_width # ì›ë³¸ í­
            render_height = actual_text_height

        # Yì¶• ì¤‘ì•™ ì •ë ¬: ì…€ ì¤‘ì•™ì— í…ìŠ¤íŠ¸ ì¤‘ì•™ì„ ë§ì¶¤
        cell_top = int(min(ys))
        cell_center = cell_top + box_height // 2
        y_adjusted = cell_center - render_height // 2 - text_top_offset + 1  # +1: í…ìŠ¤íŠ¸ë¥¼ ì•½ê°„ ì•„ë˜ë¡œ

        bg_color = bg_colors.get(i, (255, 255, 255))
        is_vertical = is_vertical_text(bbox)
        # ê²¹ì¹¨ ê°ì§€ìš©: OCR bbox ì‚¬ìš© (ê°™ì€ í–‰ íŒë‹¨ì„ ìœ„í•´ ì›ë³¸ ì¢Œí‘œ ì‚¬ìš©)
        cell_bbox = (x, int(min(ys)), box_width, box_height)
        # â˜… í…Œì´ë¸” ì•ˆì— ìˆëŠ”ì§€ í™•ì¸
        in_table = is_inside_table(bbox, table_regions)

        text_render_info.append({
            'x': x, 'y': y, 'y_adjusted': y_adjusted,
            'text': translated_text, 'font': font,
            'text_width': text_width, 'text_height': actual_text_height,
            'cell_bbox': cell_bbox, 'bg_color': bg_color,
            'is_vertical': is_vertical, 'bbox': bbox,
            'has_korean': item.get("has_korean", True),  # í•œê¸€ í¬í•¨ ì—¬ë¶€ í”Œë˜ê·¸
            'is_in_table': in_table  # â˜… í…Œì´ë¸” ë‚´ ì—¬ë¶€
        })

    # 3ë‹¨ê³„: ê²¹ì¹¨ ê°ì§€ - ì™¼ìª½ í…ìŠ¤íŠ¸ê°€ ì˜¤ë¥¸ìª½ ì…€ì„ ì¹¨ë²”í•˜ëŠ”ì§€ ì²´í¬
    needs_abbreviation = set()
    logger.info(f"\n{'='*60}")
    logger.info(f"[Overlap Detection - preview] Total texts: {len(text_render_info)}")
    logger.info(f"{'='*60}")
    
    # 3-1: ì…€ ê²½ê³„ ì´ˆê³¼ ì²´í¬ (OCR ë¯¸ì¸ì‹ í…ìŠ¤íŠ¸ ëŒ€ì‘)
    OVERFLOW_THRESHOLD = 30  # 30px ì´ìƒ ì´ˆê³¼ì‹œ ë¬´ì¡°ê±´ ì¶•ì•½
    for i, info in enumerate(text_render_info):
        text_right_edge = info['x'] + info['text_width']
        cell_x, cell_y, cell_w, cell_h = info['cell_bbox']
        cell_right = cell_x + cell_w
        overflow = text_right_edge - cell_right
        if overflow > OVERFLOW_THRESHOLD:
            needs_abbreviation.add(i)
            logger.info(f"  â˜… OVERFLOW ABBREVIATE #{i} '{info['text'][:20]}' | overflow={overflow}px > {OVERFLOW_THRESHOLD}px")
    
    # 3-2: ì¸ì ‘ í…ìŠ¤íŠ¸ ì¹¨ë²” ì²´í¬
    for i, info in enumerate(text_render_info):
        # í˜„ì¬ í…ìŠ¤íŠ¸ì˜ ì‹¤ì œ ë Œë”ë§ ì˜ì—­ (x ~ x+text_width)
        text_right_edge = info['x'] + info['text_width']
        cell_x, cell_y, cell_w, cell_h = info['cell_bbox']
        logger.debug(f"[#{i}] '{info['text'][:25]}' | x={info['x']}, w={info['text_width']}, right={text_right_edge} | cell=({cell_x},{cell_y},{cell_w},{cell_h})")

        # ì˜¤ë¥¸ìª½ì— ìˆëŠ” ëª¨ë“  ì…€ê³¼ ë¹„êµ
        for j, other_info in enumerate(text_render_info):
            if i == j:
                continue
            other_cell_left = other_info['cell_bbox'][0]

            # í˜„ì¬ í…ìŠ¤íŠ¸ê°€ ì˜¤ë¥¸ìª½ ì…€ì˜ ì‹œì‘ì ì„ ì¹¨ë²”í–ˆëŠ”ì§€
            if text_right_edge > other_cell_left and info['x'] < other_cell_left:
                # Yì¶•ë„ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸ (ê°™ì€ í–‰ì¸ì§€)
                my_y = info['cell_bbox'][1]
                my_h = info['cell_bbox'][3]
                other_y = other_info['cell_bbox'][1]
                other_h = other_info['cell_bbox'][3]

                # Yì¶• ê²¹ì¹¨ ì²´í¬
                y_overlap = not (my_y + my_h <= other_y or other_y + other_h <= my_y)
                logger.info(f"  â†’ #{i} INVADES #{j} '{other_info['text'][:15]}' | other_left={other_cell_left}")
                logger.info(f"     my_y={my_y}, my_h={my_h} (range: {my_y}~{my_y+my_h})")
                logger.info(f"     other_y={other_y}, other_h={other_h} (range: {other_y}~{other_y+other_h})")
                logger.info(f"     y_overlap={y_overlap}")
                if y_overlap:
                    needs_abbreviation.add(i)  # ì¹¨ë²”í•œ ìª½(ì™¼ìª½)ì„ ì•½ì–´ë¡œ
                    logger.info(f"  â˜… ABBREVIATE #{i}")
                    break
    logger.info(f"[Overlap Result] needs_abbreviation: {needs_abbreviation}")
    logger.info(f"{'='*60}\n")

    # 4ë‹¨ê³„: ì‹¤ì œ ë Œë”ë§
    img_result = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_result)

    used_abbreviations = set()
    all_text_bboxes = []

    for i, info in enumerate(text_render_info):
        # â˜… ì˜ì–´ í…ìŠ¤íŠ¸ëŠ” ë Œë”ë§ ê±´ë„ˆë›°ê¸° (ì›ë³¸ ìœ ì§€)
        if not info.get('has_korean', True):
            continue
            
        display_text = info['text']

        # ì¹¨ë²”í•œ í…ìŠ¤íŠ¸ëŠ” ì•½ì–´ë¡œ ë³€í™˜
        if i in needs_abbreviation:
            display_text = abbreviate_text(info['text'], used_abbreviations, target_lang)

        text_color = get_text_color_for_background(info['bg_color'])
        text_color_rgb = (text_color[2], text_color[1], text_color[0]) if text_color == (255, 255, 255) else text_color

        if info['is_vertical']:
            draw_vertical_text(draw, display_text, info['x'], info['y'], info['font'],
                             text_color_rgb, info['cell_bbox'][2], info['cell_bbox'][3])
        else:
            # í´ë¦¬í•‘: í…ìŠ¤íŠ¸ë¥¼ ì„ì‹œ ì´ë¯¸ì§€ì— ê·¸ë¦° í›„ ì…€ ë†’ì´ë§Œí¼ë§Œ ì˜ë¼ì„œ ë¶™ì„
            cell_left = info['cell_bbox'][0]
            cell_top = info['cell_bbox'][1]
            cell_width = info['cell_bbox'][2]
            cell_height = info['cell_bbox'][3]

            # í…ìŠ¤íŠ¸ bbox ê³„ì‚° (ì¶©ë¶„í•œ ì—¬ë°±ì—ì„œ)
            margin = 50
            text_bbox_temp = draw.textbbox((margin, margin), display_text, font=info['font'], anchor="lt")
            text_width_temp = text_bbox_temp[2] - text_bbox_temp[0]
            text_height_temp = text_bbox_temp[3] - text_bbox_temp[1]
            text_left = text_bbox_temp[0]
            text_top = text_bbox_temp[1]

            # ì„ì‹œ ì´ë¯¸ì§€ ìƒì„± (ì¶©ë¶„íˆ í¬ê²Œ)
            temp_img = Image.new('RGBA', (text_width_temp + margin * 2, text_height_temp + margin * 2), (0, 0, 0, 0))
            temp_draw = ImageDraw.Draw(temp_img)
            temp_draw.text((margin, margin), display_text, fill=text_color_rgb, font=info['font'], anchor="lt")

            # ì‹¤ì œ í…ìŠ¤íŠ¸ ì˜ì—­ë§Œ crop
            temp_img = temp_img.crop((text_left, text_top, text_bbox_temp[2], text_bbox_temp[3]))

            # ì…€ ë†’ì´ì— ë§ì¶° ì¶”ê°€ crop ë° ìœ„ì¹˜ ê³„ì‚°
            y_offset = 2  # ê¸€ìë¥¼ ì•„ë˜ë¡œ ë‚´ë¦¬ëŠ” ì˜¤í”„ì…‹ (í”½ì…€)
            if text_height_temp > cell_height:
                # í…ìŠ¤íŠ¸ê°€ ì…€ë³´ë‹¤ í¼ â†’ LANCZOS ë¦¬ì‚¬ì´ì¦ˆ (ì˜ë¦¼ ë°©ì§€)
                ratio = cell_height / text_height_temp
                new_width = max(1, int(text_width_temp * ratio))
                new_height = cell_height
                
                # ë¦¬ì‚¬ì´ì¦ˆ
                try:
                    resample_filter = Image.Resampling.LANCZOS
                except AttributeError:
                    resample_filter = Image.LANCZOS
                
                temp_img = temp_img.resize((new_width, new_height), resample=resample_filter)
                
                # ë¶™ì—¬ë„£ê¸° ìœ„ì¹˜ (resize í–ˆìœ¼ë¯€ë¡œ crop ë¶ˆí•„ìš”)
                paste_y = cell_top + y_offset
                
                # ë¦¬ì‚¬ì´ì¦ˆëœ í¬ê¸°ë¡œ ì—…ë°ì´íŠ¸ (ì •ë ¬ìš©)
                text_width_temp = new_width
                text_height_temp = new_height
            else:
                # í…ìŠ¤íŠ¸ê°€ ì…€ë³´ë‹¤ ì‘ìŒ â†’ ì…€ ì¤‘ì•™ì— ë°°ì¹˜
                paste_y = cell_top + (cell_height - text_height_temp) // 2 + y_offset

            # â˜… Xì¶• ì •ë ¬: í…Œì´ë¸” ì•ˆì´ë©´ ì¤‘ì•™, ì•„ë‹ˆë©´ ì™¼ìª½
            if info.get('is_in_table', False):
                # í…Œì´ë¸” ë‚´ í…ìŠ¤íŠ¸ â†’ ì¤‘ì•™ ì •ë ¬
                original_center_x = cell_left + cell_width // 2
                paste_x = original_center_x - text_width_temp // 2
                # ì™¼ìª½ ê²½ê³„ ì œí•œ
                if paste_x < cell_left:
                    paste_x = cell_left
            else:
                # í…Œì´ë¸” ë°– í…ìŠ¤íŠ¸ â†’ ì™¼ìª½ ì •ë ¬
                paste_x = info['x']

            # ì›ë³¸ ì´ë¯¸ì§€ì— ë¶™ì—¬ë„£ê¸°
            img_result.paste(temp_img, (paste_x, paste_y), temp_img)

        # bbox ê¸°ë¡
        text_bbox_new = draw.textbbox((0, 0), display_text, font=info['font'])
        new_width = text_bbox_new[2] - text_bbox_new[0]
        all_text_bboxes.append((info['x'], info['y_adjusted'], new_width, info['text_height']))

    # â˜… ë²”ë¡€ ë Œë”ë§ (ì•½ì–´ ì‚¬ìš© ì‹œ)
    if used_abbreviations:
        legend_y = find_bottom_empty_area(height, all_text_bboxes)
        if legend_y is not None:
            render_legend(draw, used_abbreviations, width, legend_y)

    # ê²°ê³¼ë¥¼ base64ë¡œ ë°˜í™˜
    buffer = io.BytesIO()
    img_result.save(buffer, format='PNG')
    buffer.seek(0)
    return base64.b64encode(buffer.read()).decode()


# HTML í…œí”Œë¦¿
HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PDF Translator - ì˜ë¥˜ ê¸°ìˆ ì„œ ë²ˆì—­</title>
    <style>
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 5px;
        }
        .container {
            width: 100%;
            max-width: 100%;
            margin: 0 auto;
            background: white;
            border-radius: 6px;
            padding: 5px 10px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            min-height: calc(100vh - 10px);
        }
        .header-row {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 8px;
            margin-bottom: 8px;
            flex-wrap: nowrap;
            border-bottom: 1px solid #eee;
            padding-bottom: 8px;
        }
        .header-row h1 {
            color: #333;
            font-size: 1.2em;
            margin: 0;
            white-space: nowrap;
        }
        .header-row .subtitle {
            color: #666;
            font-size: 0.7em;
            margin: 0;
            white-space: nowrap;
        }
        .version-badge {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2px 6px;
            border-radius: 10px;
            font-size: 0.6em;
            font-weight: bold;
            white-space: nowrap;
        }
        .lang-btn {
            padding: 3px 6px;
            border: 2px solid #667eea;
            border-radius: 10px;
            background: white;
            color: #667eea;
            cursor: pointer;
            transition: all 0.3s;
            font-size: 0.65em;
            white-space: nowrap;
        }
        .lang-btn:hover, .lang-btn.active {
            background: #667eea;
            color: white;
        }
        .file-select-btn {
            padding: 3px 8px;
            border: 2px solid #28a745;
            border-radius: 10px;
            background: white;
            color: #28a745;
            cursor: pointer;
            font-size: 0.65em;
            white-space: nowrap;
            transition: all 0.3s;
        }
        .file-select-btn:hover {
            background: #28a745;
            color: white;
        }
        .file-select-btn.has-file {
            background: #28a745;
            color: white;
        }
        .translate-btn {
            padding: 3px 10px;
            border: none;
            border-radius: 10px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            cursor: pointer;
            font-size: 0.65em;
            white-space: nowrap;
            transition: all 0.3s;
        }
        .translate-btn:hover:not(:disabled) {
            transform: scale(1.05);
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        }
        .translate-btn:disabled {
            background: #ccc;
            cursor: not-allowed;
        }
        .settings-btn {
            padding: 3px 8px;
            border: 2px solid #6c757d;
            border-radius: 10px;
            background: white;
            color: #6c757d;
            cursor: pointer;
            font-size: 0.7em;
            transition: all 0.3s;
        }
        .settings-btn:hover {
            background: #6c757d;
            color: white;
        }
        .dict-btn {
            padding: 3px 8px;
            border: 2px solid #28a745;
            border-radius: 10px;
            background: white;
            color: #28a745;
            cursor: pointer;
            font-size: 0.7em;
            transition: all 0.3s;
        }
        .dict-btn:hover {
            background: #28a745;
            color: white;
        }
        input[type="file"] { display: none; }

        /* ëª¨ë‹¬ ìŠ¤íƒ€ì¼ */
        .modal-overlay {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0,0,0,0.5);
            z-index: 1000;
            justify-content: center;
            align-items: center;
        }
        .modal-overlay.active {
            display: flex;
        }
        .modal-content {
            background: white;
            border-radius: 12px;
            width: 90%;
            max-width: 500px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            overflow: hidden;
        }
        .modal-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 15px 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }
        .modal-header h2 {
            margin: 0;
            font-size: 1.2em;
        }
        .modal-close {
            background: none;
            border: none;
            color: white;
            font-size: 1.5em;
            cursor: pointer;
            opacity: 0.8;
        }
        .modal-close:hover {
            opacity: 1;
        }
        .modal-body {
            padding: 20px;
        }
        .modal-footer {
            display: flex;
            justify-content: flex-end;
            gap: 10px;
            padding: 15px 20px;
            background: #f8f9fa;
            border-top: 1px solid #eee;
        }
        .setting-group {
            margin-bottom: 20px;
        }
        .setting-group label {
            display: block;
            font-weight: bold;
            color: #333;
            margin-bottom: 8px;
        }
        .setting-group select {
            width: 100%;
            padding: 10px;
            border: 2px solid #ddd;
            border-radius: 8px;
            font-size: 1em;
            cursor: pointer;
        }
        .setting-group select:focus {
            outline: none;
            border-color: #667eea;
        }
        .setting-hint {
            font-size: 0.85em;
            color: #666;
            margin-top: 5px;
        }
        .api-key-input-wrapper {
            display: flex;
            gap: 8px;
        }
        .api-key-input-wrapper input {
            flex: 1;
            padding: 10px;
            border: 2px solid #ddd;
            border-radius: 8px;
            font-size: 1em;
        }
        .api-key-input-wrapper input:focus {
            outline: none;
            border-color: #667eea;
        }
        .toggle-visibility {
            padding: 10px 12px;
            border: 2px solid #ddd;
            border-radius: 8px;
            background: white;
            cursor: pointer;
            font-size: 1em;
        }
        .toggle-visibility:hover {
            background: #f0f0f0;
        }
        .setting-info {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 8px;
            margin-top: 15px;
        }
        .setting-info h4 {
            margin: 0 0 10px 0;
            color: #333;
        }
        .setting-info ul {
            margin: 0;
            padding-left: 20px;
        }
        .setting-info li {
            margin-bottom: 5px;
            font-size: 0.9em;
            color: #555;
        }
        .btn-primary {
            padding: 10px 20px;
            border: none;
            border-radius: 8px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            cursor: pointer;
            font-size: 1em;
            transition: all 0.3s;
        }
        .btn-primary:hover {
            transform: scale(1.02);
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        }
        .btn-secondary {
            padding: 10px 20px;
            border: 2px solid #6c757d;
            border-radius: 8px;
            background: white;
            color: #6c757d;
            cursor: pointer;
            font-size: 1em;
            transition: all 0.3s;
        }
        .btn-secondary:hover {
            background: #6c757d;
            color: white;
        }

        /* ì—ë””í„° ë ˆì´ì•„ì›ƒ */
        .editor-container {
            display: none;
            height: calc(100vh - 70px);
            position: relative;
        }
        .editor-container.active {
            display: flex;
        }

        /* ì¢Œì¸¡: í˜ì´ì§€ í”„ë¦¬ë·° */
        .preview-panel {
            flex: 1;
            min-width: 200px;
            border: 1px solid #ddd;
            border-radius: 8px;
            overflow: hidden;
            display: flex;
            flex-direction: column;
        }

        /* ë¦¬ì‚¬ì´ì € (ë“œë˜ê·¸ í•¸ë“¤) */
        .resizer {
            width: 12px;
            background: linear-gradient(90deg, #ddd 0%, #bbb 50%, #ddd 100%);
            cursor: col-resize;
            flex-shrink: 0;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.2s;
            border-radius: 6px;
            margin: 0 4px;
            position: relative;
        }
        .resizer:hover {
            background: linear-gradient(90deg, #667eea 0%, #764ba2 50%, #667eea 100%);
            width: 14px;
        }
        .resizer:active {
            background: #764ba2;
        }
        .resizer::before {
            content: '';
            position: absolute;
            left: 3px;
            top: 50%;
            transform: translateY(-50%);
            width: 2px;
            height: 40px;
            background: rgba(255,255,255,0.5);
            border-radius: 1px;
        }
        .resizer::after {
            content: '';
            position: absolute;
            right: 3px;
            top: 50%;
            transform: translateY(-50%);
            width: 2px;
            height: 40px;
            background: rgba(255,255,255,0.5);
            border-radius: 1px;
        }
        .preview-header {
            background: #f8f9fa;
            padding: 8px 12px;
            border-bottom: 1px solid #ddd;
            display: flex;
            justify-content: space-between;
            align-items: center;
            gap: 10px;
        }
        .preview-header .page-info {
            font-weight: bold;
            color: #333;
        }
        .preview-toggle {
            display: flex;
            gap: 2px;
            background: #e9ecef;
            padding: 2px;
            border-radius: 6px;
        }
        .toggle-btn {
            padding: 4px 10px;
            border: none;
            background: transparent;
            color: #666;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.8em;
            transition: all 0.2s;
        }
        .toggle-btn:hover {
            background: rgba(102, 126, 234, 0.1);
        }
        .toggle-btn.active {
            background: #667eea;
            color: white;
        }
        .toggle-btn.loading {
            opacity: 0.6;
            cursor: wait;
        }
        .preview-nav {
            display: flex;
            gap: 5px;
        }
        .preview-nav button {
            padding: 4px 10px;
            border: 1px solid #667eea;
            background: white;
            color: #667eea;
            border-radius: 5px;
            cursor: pointer;
            font-size: 0.8em;
        }
        .preview-nav button:hover {
            background: #667eea;
            color: white;
        }
        .preview-nav button:disabled {
            border-color: #ccc;
            color: #ccc;
            cursor: not-allowed;
            background: white;
        }
        .preview-image {
            flex: 1;
            overflow: auto;
            padding: 10px;
            background: #f0f0f0;
            display: flex;
            justify-content: center;
            align-items: flex-start;
        }
        .preview-image img {
            max-width: none;
            max-height: none;
            object-fit: contain;
            box-shadow: 0 2px 10px rgba(0,0,0,0.2);
            transform-origin: top center;
            transition: transform 0.2s ease;
        }
        /* í™•ëŒ€/ì¶•ì†Œ ì»¨íŠ¸ë¡¤ */
        .zoom-controls {
            display: flex;
            gap: 4px;
            background: #e9ecef;
            padding: 2px 4px;
            border-radius: 6px;
            align-items: center;
        }
        .zoom-btn {
            width: 26px;
            height: 26px;
            padding: 0;
            border: none;
            background: transparent;
            color: #667eea;
            border-radius: 4px;
            cursor: pointer;
            font-size: 1.1em;
            font-weight: bold;
            transition: all 0.2s;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        .zoom-btn:hover {
            background: rgba(102, 126, 234, 0.2);
        }
        .zoom-btn:active {
            transform: scale(0.95);
        }
        .zoom-level {
            font-size: 0.75em;
            color: #666;
            min-width: 42px;
            text-align: center;
            font-weight: bold;
        }

        /* ìš°ì¸¡: ë²ˆì—­ í…Œì´ë¸” */
        .translation-panel {
            width: 450px;
            min-width: 300px;
            flex-shrink: 0;
            border: 1px solid #ddd;
            border-radius: 8px;
            overflow: hidden;
            display: flex;
            flex-direction: column;
        }
        .translation-header {
            background: #f8f9fa;
            padding: 8px 12px;
            border-bottom: 1px solid #ddd;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        .translation-header .title {
            font-weight: bold;
            color: #333;
        }
        .confirm-btn {
            padding: 5px 15px;
            border: none;
            border-radius: 5px;
            background: #28a745;
            color: white;
            cursor: pointer;
            font-size: 0.85em;
            transition: all 0.3s;
        }
        .confirm-btn:hover {
            background: #218838;
        }
        .confirm-btn.confirmed {
            background: #6c757d;
        }
        .translation-table-wrapper {
            flex: 1;
            overflow: auto;
            padding: 10px;
        }
        .translation-table {
            width: 100%;
            border-collapse: collapse;
        }
        .translation-table th {
            background: #667eea;
            color: white;
            padding: 10px;
            text-align: left;
            position: sticky;
            top: 0;
        }
        .translation-table th:first-child {
            width: 30px;
        }
        .translation-table td {
            padding: 8px 10px;
            border-bottom: 1px solid #eee;
            vertical-align: top;
        }
        .translation-table tr:hover {
            background: #f8f9fa;
        }
        .translation-table .idx {
            color: #999;
            font-size: 0.85em;
            text-align: center;
        }
        .translation-table .korean {
            color: #333;
            font-size: 0.9em;
        }
        .translation-table .trans-input {
            width: 100%;
            padding: 6px 8px;
            border: 1px solid #ddd;
            border-radius: 4px;
            font-size: 0.9em;
            transition: border-color 0.3s;
        }
        .translation-table .trans-input:focus {
            outline: none;
            border-color: #667eea;
            box-shadow: 0 0 0 2px rgba(102, 126, 234, 0.2);
        }
        .translation-table .trans-input.modified {
            border-color: #ffc107;
            background: #fffde7;
        }

        /* ìš©ì–´ ì‚¬ì „ ëª¨ë‹¬ ìŠ¤íƒ€ì¼ */
        .dict-modal {
            width: 890px;
            max-width: 95vw;
            max-height: 99vh;
        }
        .dict-tabs {
            display: flex;
            gap: 5px;
            margin-bottom: 15px;
            flex-wrap: wrap;
        }
        .dict-tab {
            padding: 8px 12px;
            border: 2px solid #ddd;
            border-radius: 20px;
            background: white;
            cursor: pointer;
            font-size: 0.85em;
            transition: all 0.2s;
        }
        .dict-tab:hover {
            border-color: #667eea;
        }
        .dict-tab.active {
            background: #667eea;
            color: white;
            border-color: #667eea;
        }
        .dict-add-form {
            display: flex;
            gap: 10px;
            margin-bottom: 15px;
            flex-wrap: nowrap;
        }
        .dict-add-form input {
            flex: 1;
            min-width: 120px;
            padding: 10px;
            border: 2px solid #ddd;
            border-radius: 8px;
            font-size: 0.95em;
        }
        .dict-add-form input:focus {
            outline: none;
            border-color: #667eea;
        }
        .dict-add-form button {
            flex-shrink: 0;
            white-space: nowrap;
        }
        .dict-search {
            margin-bottom: 10px;
        }
        .dict-search input {
            width: 100%;
            padding: 10px;
            border: 2px solid #ddd;
            border-radius: 8px;
            font-size: 0.95em;
        }
        .dict-search input:focus {
            outline: none;
            border-color: #667eea;
        }
        .dict-table-wrapper {
            max-height: 350px;
            overflow-y: auto;
            border: 1px solid #ddd;
            border-radius: 8px;
        }
        .dict-table {
            width: 100%;
            border-collapse: collapse;
        }
        .dict-table th, .dict-table td {
            padding: 10px 12px;
            text-align: left;
            border-bottom: 1px solid #eee;
        }
        .dict-table th {
            background: #f8f9fa;
            font-weight: bold;
            position: sticky;
            top: 0;
        }
        .dict-table th:nth-child(1) { width: 25%; }  /* í•œê¸€ */
        .dict-table th:nth-child(2) { width: 35%; }  /* ë²ˆì—­ */
        .dict-table th:nth-child(3) { width: 20%; }  /* ì•½ì–´ */
        .dict-table th:nth-child(4) { width: 20%; }  /* ì‘ì—… */
        .dict-table .abbr-cell {
            color: #666;
            font-style: italic;
        }
        .dict-table tr:hover {
            background: #f8f9fa;
        }
        .dict-table .actions {
            display: flex;
            gap: 5px;
        }
        .dict-table .edit-btn, .dict-table .delete-btn, .dict-table .save-btn, .dict-table .cancel-btn {
            padding: 4px 8px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.85em;
        }
        .dict-table .edit-btn {
            background: #ffc107;
            color: #333;
        }
        .dict-table .delete-btn {
            background: #dc3545;
            color: white;
        }
        .dict-table .save-btn {
            background: #28a745;
            color: white;
        }
        .dict-table .cancel-btn {
            background: #6c757d;
            color: white;
        }
        .dict-table .edit-input {
            width: 100%;
            padding: 5px;
            border: 2px solid #667eea;
            border-radius: 4px;
        }
        .dict-count {
            color: #666;
            font-size: 0.9em;
        }

        /* ìƒíƒœ ë©”ì‹œì§€ */
        .status {
            text-align: center;
            padding: 8px;
            margin: 8px 0;
            border-radius: 6px;
            display: none;
            font-size: 0.9em;
        }
        .status.processing {
            display: block;
            background: #fff3cd;
            color: #856404;
        }
        .status.success {
            display: block;
            background: #d4edda;
            color: #155724;
        }
        .status.error {
            display: block;
            background: #f8d7da;
            color: #721c24;
        }

        /* ê²°ê³¼ ê·¸ë¦¬ë“œ */
        .results {
            display: none;
            grid-template-columns: repeat(auto-fill, minmax(180px, 1fr));
            gap: 12px;
            margin-top: 10px;
        }
        .results.active {
            display: grid;
        }
        .result-item {
            border: 1px solid #ddd;
            border-radius: 8px;
            overflow: hidden;
            transition: transform 0.2s;
        }
        .result-item:hover {
            transform: scale(1.02);
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }
        .result-item img {
            width: 100%;
            display: block;
        }
        .result-item .download {
            display: block;
            text-align: center;
            padding: 8px;
            background: #667eea;
            color: white;
            text-decoration: none;
            font-size: 0.85em;
        }

        .spinner {
            display: inline-block;
            width: 16px;
            height: 16px;
            border: 2px solid #f3f3f3;
            border-top: 2px solid #667eea;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            margin-right: 8px;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        /* ì´ˆê¸° ì•ˆë‚´ */
        .initial-guide {
            text-align: center;
            padding: 60px 20px;
            color: #666;
        }
        .initial-guide .icon {
            font-size: 4em;
            margin-bottom: 20px;
        }
        .initial-guide h2 {
            color: #333;
            margin-bottom: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <input type="file" id="fileInput" accept=".pdf,.png,.jpg,.jpeg">
        <input type="hidden" id="targetLang" value="english">

        <div class="header-row">
            <h1>ğŸ“„ PDF Translator</h1>
            <span class="version-badge">v{{ version }}</span>
            <span class="subtitle">í•œê¸€â†’ë‹¤êµ­ì–´</span>
            <button type="button" class="lang-btn active" data-lang="english">ğŸ‡ºğŸ‡¸EN</button>
            <button type="button" class="lang-btn" data-lang="vietnamese">ğŸ‡»ğŸ‡³VI</button>
            <button type="button" class="lang-btn" data-lang="chinese">ğŸ‡¨ğŸ‡³ä¸­</button>
            <button type="button" class="lang-btn" data-lang="indonesian">ğŸ‡®ğŸ‡©ID</button>
            <button type="button" class="lang-btn" data-lang="bengali">ğŸ‡§ğŸ‡©BN</button>
            <button type="button" class="lang-btn" data-lang="myanmar">ğŸ‡²ğŸ‡²MY</button>
            <button type="button" class="file-select-btn" id="fileSelectBtn">ğŸ“ íŒŒì¼ì„ íƒ</button>
            <button type="button" class="translate-btn" id="translateBtn" disabled>ğŸš€ ë²ˆì—­</button>
            <button type="button" class="dict-btn" id="dictBtn" title="ìš©ì–´ ì‚¬ì „ ê´€ë¦¬">ğŸ“–</button>
            <button type="button" class="settings-btn" id="settingsBtn">âš™ï¸</button>
        </div>

        <!-- ì„¤ì • ëª¨ë‹¬ -->
        <div class="modal-overlay" id="settingsModal">
            <div class="modal-content">
                <div class="modal-header">
                    <h2>âš™ï¸ AI ì„¤ì •</h2>
                    <button class="modal-close" id="closeSettings">&times;</button>
                </div>
                <div class="modal-body">
                    <div class="setting-group">
                        <label>AI ì—”ì§„ ì„ íƒ</label>
                        <select id="aiEngineSelect">
                            <option value="ollama" selected>ğŸ–¥ï¸ Ollama (ë¡œì»¬) - ë¬´ë£Œ</option>
                            <option value="claude">ğŸŸ£ Claude API</option>
                            <option value="openai">ğŸŸ¢ OpenAI GPT-4</option>
                            <option value="gemini">ğŸ”µ Google Gemini</option>
                        </select>
                        <p class="setting-hint">OllamaëŠ” ë¡œì»¬ì—ì„œ ì‹¤í–‰ë˜ë©° API í‚¤ê°€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.</p>
                    </div>

                    <div class="setting-group api-key-group" id="apiKeyGroup" style="display: none;">
                        <label id="apiKeyLabel">API Key</label>
                        <div class="api-key-input-wrapper">
                            <input type="password" id="apiKeyInput" placeholder="API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”">
                            <button type="button" class="toggle-visibility" id="toggleApiKey">ğŸ‘ï¸</button>
                        </div>
                        <p class="setting-hint" id="apiKeyHint">
                            API í‚¤ëŠ” ë¸Œë¼ìš°ì €ì—ë§Œ ì €ì¥ë˜ë©° ì„œë²„ë¡œ ì „ì†¡ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
                        </p>
                    </div>

                    <div class="setting-group" id="modelGroup">
                        <label>ëª¨ë¸ ì„ íƒ</label>
                        <select id="modelSelect">
                            <!-- JavaScriptë¡œ ë™ì  ìƒì„± -->
                        </select>
                        <p class="setting-hint" id="modelHint">ì„ íƒí•œ AI ì—”ì§„ì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”.</p>
                    </div>

                    <div class="setting-info">
                        <h4>AIë³„ íŠ¹ì§•</h4>
                        <ul>
                            <li><strong>Ollama</strong>: ë¬´ë£Œ, ë¡œì»¬ ì‹¤í–‰, ì¸í„°ë„· ë¶ˆí•„ìš”</li>
                            <li><strong>Claude</strong>: ë†’ì€ ì •í™•ë„, Vision ì§€ì›</li>
                            <li><strong>GPT-4</strong>: ë²”ìš©ì„± ë†’ìŒ, Vision ì§€ì›</li>
                            <li><strong>Gemini</strong>: ë¹ ë¥¸ ì†ë„, ë¹„ìš© ì €ë ´</li>
                        </ul>
                    </div>
                </div>
                <div class="modal-footer">
                    <button type="button" class="btn-secondary" id="cancelSettings">ì·¨ì†Œ</button>
                    <button type="button" class="btn-primary" id="saveSettings">ì €ì¥</button>
                </div>
            </div>
        </div>

        <!-- ìš©ì–´ ì‚¬ì „ ëª¨ë‹¬ -->
        <div class="modal-overlay" id="dictModal">
            <div class="modal-content dict-modal">
                <div class="modal-header">
                    <h2>ğŸ“– ìš©ì–´ ì‚¬ì „ ê´€ë¦¬</h2>
                    <button class="modal-close" id="closeDict">&times;</button>
                </div>
                <div class="modal-body">
                    <div class="dict-tabs">
                        <button class="dict-tab active" data-lang="english">ğŸ‡ºğŸ‡¸ ì˜ì–´</button>
                        <button class="dict-tab" data-lang="vietnamese">ğŸ‡»ğŸ‡³ ë² íŠ¸ë‚¨ì–´</button>
                        <button class="dict-tab" data-lang="chinese">ğŸ‡¨ğŸ‡³ ì¤‘êµ­ì–´</button>
                        <button class="dict-tab" data-lang="indonesian">ğŸ‡®ğŸ‡© ì¸ë„ë„¤ì‹œì•„ì–´</button>
                        <button class="dict-tab" data-lang="bengali">ğŸ‡§ğŸ‡© ë²µê³¨ì–´</button>
                        <button class="dict-tab" data-lang="myanmar">ğŸ‡²ğŸ‡² ë¯¸ì–€ë§ˆì–´</button>
                    </div>
                    <div class="dict-add-form">
                        <input type="text" id="dictKorean" placeholder="í•œê¸€ ìš©ì–´">
                        <input type="text" id="dictTranslation" placeholder="ë²ˆì—­">
                        <input type="text" id="dictAbbr" placeholder="ì•½ì–´ (ì„ íƒ)">
                        <button type="button" class="btn-primary" id="addTermBtn">â• ì¶”ê°€</button>
                    </div>
                    <div class="dict-search">
                        <input type="text" id="dictSearch" placeholder="ğŸ” ê²€ìƒ‰...">
                    </div>
                    <div class="dict-table-wrapper">
                        <table class="dict-table">
                            <thead>
                                <tr>
                                    <th>í•œê¸€</th>
                                    <th>ë²ˆì—­</th>
                                    <th>ì•½ì–´</th>
                                    <th>ì‘ì—…</th>
                                </tr>
                            </thead>
                            <tbody id="dictBody">
                            </tbody>
                        </table>
                    </div>
                </div>
                <div class="modal-footer">
                    <span class="dict-count" id="dictCount">ì´ 0ê°œ ìš©ì–´</span>
                    <button type="button" class="btn-secondary" id="closeDictBtn">ë‹«ê¸°</button>
                </div>
            </div>
        </div>

        <div class="status" id="status"></div>

        <!-- ì´ˆê¸° ì•ˆë‚´ í™”ë©´ -->
        <div class="initial-guide" id="initialGuide">
            <div class="icon">ğŸ“‚</div>
            <h2>íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”</h2>
            <p>PDF ë˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ì„ ì„ íƒí•˜ë©´ ìë™ìœ¼ë¡œ OCRì´ ì‹¤í–‰ë©ë‹ˆë‹¤</p>
        </div>

        <!-- ì—ë””í„° ì»¨í…Œì´ë„ˆ -->
        <div class="editor-container" id="editorContainer">
            <!-- ì¢Œì¸¡: í˜ì´ì§€ í”„ë¦¬ë·° -->
            <div class="preview-panel" id="previewPanel">
                <div class="preview-header">
                    <span class="page-info" id="pageInfo">í˜ì´ì§€ 1 / 1</span>
                    <div class="zoom-controls">
                        <button class="zoom-btn" id="zoomOut" title="ì¶•ì†Œ">âˆ’</button>
                        <span class="zoom-level" id="zoomLevel">100%</span>
                        <button class="zoom-btn" id="zoomIn" title="í™•ëŒ€">+</button>
                        <button class="zoom-btn" id="zoomReset" title="ì›ë˜ í¬ê¸°" style="font-size:0.75em;">â†º</button>
                    </div>
                    <div class="preview-toggle">
                        <button class="toggle-btn active" id="showOriginal">ğŸ“„ ì›ë³¸</button>
                        <button class="toggle-btn" id="showPreview">ğŸ”„ ë¯¸ë¦¬ë³´ê¸°</button>
                    </div>
                    <div class="preview-nav">
                        <button id="prevPageBtn" disabled>â—€ ì´ì „</button>
                        <button id="nextPageBtn" disabled>ë‹¤ìŒ â–¶</button>
                    </div>
                </div>
                <div class="preview-image">
                    <img id="previewImg" src="" alt="í˜ì´ì§€ í”„ë¦¬ë·°">
                </div>
            </div>

            <!-- ë¦¬ì‚¬ì´ì € í•¸ë“¤ -->
            <div class="resizer" id="resizer"></div>

            <!-- ìš°ì¸¡: ë²ˆì—­ í…Œì´ë¸” -->
            <div class="translation-panel" id="translationPanel">
                <div class="translation-header">
                    <span class="title">ë²ˆì—­ í¸ì§‘</span>
                    <button class="confirm-btn" id="confirmBtn">âœ… í™•ì •</button>
                </div>
                <div class="translation-table-wrapper">
                    <table class="translation-table">
                        <thead>
                            <tr>
                                <th>#</th>
                                <th>í•œêµ­ì–´ (ì›ë³¸)</th>
                                <th>ë²ˆì—­</th>
                            </tr>
                        </thead>
                        <tbody id="translationBody">
                        </tbody>
                    </table>
                </div>
            </div>
        </div>

        <!-- ê²°ê³¼ í‘œì‹œ -->
        <div class="results" id="results"></div>
    </div>

    <script>
        // ìƒíƒœ ë³€ìˆ˜
        let currentPage = 0;
        let totalPages = 0;
        let pagesData = [];  // [{image: base64, texts: [...], translations: [...], confirmed: bool}]
        let currentZoom = 100;  // í˜„ì¬ í™•ëŒ€ ë¹„ìœ¨ (%)
        const ZOOM_MIN = 25;
        const ZOOM_MAX = 400;
        const ZOOM_STEP = 25;

        // DOM ìš”ì†Œ
        const fileInput = document.getElementById('fileInput');
        const fileSelectBtn = document.getElementById('fileSelectBtn');
        const translateBtn = document.getElementById('translateBtn');
        const langBtns = document.querySelectorAll('.lang-btn');
        const targetLang = document.getElementById('targetLang');
        const status = document.getElementById('status');
        const initialGuide = document.getElementById('initialGuide');
        const editorContainer = document.getElementById('editorContainer');
        const previewImg = document.getElementById('previewImg');
        const pageInfo = document.getElementById('pageInfo');
        const prevPageBtn = document.getElementById('prevPageBtn');
        const nextPageBtn = document.getElementById('nextPageBtn');
        const translationBody = document.getElementById('translationBody');
        const confirmBtn = document.getElementById('confirmBtn');
        const results = document.getElementById('results');

        // í™•ëŒ€/ì¶•ì†Œ ì»¨íŠ¸ë¡¤
        const zoomIn = document.getElementById('zoomIn');
        const zoomOut = document.getElementById('zoomOut');
        const zoomReset = document.getElementById('zoomReset');
        const zoomLevel = document.getElementById('zoomLevel');

        // ë¯¸ë¦¬ë³´ê¸° í† ê¸€ ë²„íŠ¼
        const showOriginalBtn = document.getElementById('showOriginal');
        const showPreviewBtn = document.getElementById('showPreview');

        // ë¯¸ë¦¬ë³´ê¸° ìƒíƒœ
        let isPreviewMode = false;
        let previewCache = {};  // í˜ì´ì§€ë³„ ë¯¸ë¦¬ë³´ê¸° ìºì‹œ

        // í™•ëŒ€/ì¶•ì†Œ í•¨ìˆ˜
        function applyZoom(zoom) {
            currentZoom = Math.max(ZOOM_MIN, Math.min(ZOOM_MAX, zoom));
            previewImg.style.transform = `scale(${currentZoom / 100})`;
            zoomLevel.textContent = `${currentZoom}%`;
        }
        
        // í™•ëŒ€/ì¶•ì†Œ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
        zoomIn.addEventListener('click', () => applyZoom(currentZoom + ZOOM_STEP));
        zoomOut.addEventListener('click', () => applyZoom(currentZoom - ZOOM_STEP));
        zoomReset.addEventListener('click', () => applyZoom(100));
        
        // ë§ˆìš°ìŠ¤ íœ ë¡œ í™•ëŒ€/ì¶•ì†Œ (Ctrl + íœ ) - PDF ì˜ì—­ì—ì„œë§Œ
        const previewImageContainer = document.querySelector('.preview-image');
        
        // document ë ˆë²¨ì—ì„œ ìº¡ì²˜í•˜ì—¬ ë¸Œë¼ìš°ì € ê¸°ë³¸ ë™ì‘ ì°¨ë‹¨
        document.addEventListener('wheel', (e) => {
            if (e.ctrlKey && previewImageContainer && previewImageContainer.contains(e.target)) {
                e.preventDefault();
                e.stopPropagation();
                const delta = e.deltaY > 0 ? -ZOOM_STEP : ZOOM_STEP;
                applyZoom(currentZoom + delta);
            }
        }, { passive: false, capture: true });

        // ì„¤ì • ê´€ë ¨ ìš”ì†Œ
        const settingsBtn = document.getElementById('settingsBtn');
        const settingsModal = document.getElementById('settingsModal');
        const closeSettings = document.getElementById('closeSettings');
        const cancelSettings = document.getElementById('cancelSettings');
        const saveSettings = document.getElementById('saveSettings');
        const aiEngineSelect = document.getElementById('aiEngineSelect');
        const apiKeyGroup = document.getElementById('apiKeyGroup');
        const apiKeyInput = document.getElementById('apiKeyInput');
        const apiKeyLabel = document.getElementById('apiKeyLabel');
        const apiKeyHint = document.getElementById('apiKeyHint');
        const toggleApiKey = document.getElementById('toggleApiKey');
        const modelSelect = document.getElementById('modelSelect');
        const modelHint = document.getElementById('modelHint');

        // AI ì„¤ì • ìƒíƒœ (localStorageì—ì„œ ë¡œë“œ)
        let currentAiEngine = localStorage.getItem('pdf_translator_ai_engine') || 'ollama';
        let currentModel = localStorage.getItem('pdf_translator_model') || '';
        let apiKeys = JSON.parse(localStorage.getItem('pdf_translator_api_keys') || '{}');

        // AI ëª¨ë¸ ì •ë³´
        const aiModels = {
            ollama: {
                models: ['qwen2.5vl:latest', 'llava:latest', 'bakllava:latest'],
                default: 'qwen2.5vl:latest',
                hints: {
                    'qwen2.5vl:latest': 'ë‹¤êµ­ì–´ ì§€ì›, Vision ê°•ë ¥ (ê¶Œì¥)',
                    'llava:latest': 'ê²½ëŸ‰ ëª¨ë¸, ë¹ ë¥¸ ì†ë„',
                    'bakllava:latest': 'LLaVA ê¸°ë°˜, ê· í˜•ì¡íŒ ì„±ëŠ¥'
                }
            },
            claude: {
                models: ['claude-opus-4-20250514', 'claude-sonnet-4-20250514', 'claude-3-5-sonnet-20241022', 'claude-3-haiku-20240307'],
                default: 'claude-sonnet-4-20250514',
                hints: {
                    'claude-opus-4-20250514': 'Opus 4.5 - ìµœê³  ì„±ëŠ¥ (ë¹„ìš© ë†’ìŒ)',
                    'claude-sonnet-4-20250514': 'Sonnet 4 - ê³ ì„±ëŠ¥ (ê¶Œì¥)',
                    'claude-3-5-sonnet-20241022': 'ì•ˆì •ì ì¸ ì„±ëŠ¥',
                    'claude-3-haiku-20240307': 'ë¹ ë¥´ê³  ì €ë ´'
                }
            },
            openai: {
                models: ['gpt-4o', 'gpt-4o-mini', 'gpt-4-turbo'],
                default: 'gpt-4o',
                hints: {
                    'gpt-4o': 'ìµœì‹  ë©€í‹°ëª¨ë‹¬, ê³ ì„±ëŠ¥ (ê¶Œì¥)',
                    'gpt-4o-mini': 'ì €ë ´í•˜ê³  ë¹ ë¦„',
                    'gpt-4-turbo': 'ì•ˆì •ì , Vision ì§€ì›'
                }
            },
            gemini: {
                models: ['gemini-2.0-flash', 'gemini-1.5-flash', 'gemini-1.5-pro'],
                default: 'gemini-2.0-flash',
                hints: {
                    'gemini-2.0-flash': 'ìµœì‹  ëª¨ë¸, ë¹ ë¥´ê³  ì €ë ´ (ê¶Œì¥)',
                    'gemini-1.5-flash': 'ë¹ ë¥¸ ì†ë„, ë¹„ìš© íš¨ìœ¨',
                    'gemini-1.5-pro': 'ê³ ì„±ëŠ¥, ë³µì¡í•œ ì‘ì—…ìš©'
                }
            }
        };

        // API í‚¤ íŒíŠ¸ ì •ë³´
        const apiKeyInfo = {
            claude: {
                label: 'Claude API Key',
                hint: 'Anthropic Consoleì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.',
                placeholder: 'sk-ant-...'
            },
            openai: {
                label: 'OpenAI API Key',
                hint: 'OpenAI Platformì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.',
                placeholder: 'sk-...'
            },
            gemini: {
                label: 'Google Gemini API Key',
                hint: 'Google AI Studioì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.',
                placeholder: 'AIza...'
            }
        };

        // ì´ˆê¸° ì„¤ì • UI ì—…ë°ì´íŠ¸
        function initSettings() {
            aiEngineSelect.value = currentAiEngine;
            updateApiKeyVisibility();
            updateModelOptions();
        }

        // API í‚¤ ì…ë ¥ í•„ë“œ í‘œì‹œ/ìˆ¨ê¹€
        function updateApiKeyVisibility() {
            const engine = aiEngineSelect.value;
            if (engine === 'ollama') {
                apiKeyGroup.style.display = 'none';
            } else {
                apiKeyGroup.style.display = 'block';
                const info = apiKeyInfo[engine];
                apiKeyLabel.textContent = info.label;
                apiKeyHint.textContent = info.hint;
                apiKeyInput.placeholder = info.placeholder;
                apiKeyInput.value = apiKeys[engine] || '';
            }
        }

        // ëª¨ë¸ ì„ íƒ ì˜µì…˜ ì—…ë°ì´íŠ¸
        function updateModelOptions() {
            const engine = aiEngineSelect.value;
            const modelInfo = aiModels[engine];

            // ê¸°ì¡´ ì˜µì…˜ ì œê±°
            modelSelect.innerHTML = '';

            // ìƒˆ ì˜µì…˜ ì¶”ê°€
            modelInfo.models.forEach(model => {
                const option = document.createElement('option');
                option.value = model;
                option.textContent = model;
                if (model === modelInfo.default) {
                    option.textContent += ' (ê¸°ë³¸)';
                }
                modelSelect.appendChild(option);
            });

            // ì €ì¥ëœ ëª¨ë¸ì´ ìˆìœ¼ë©´ ì„ íƒ, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
            const savedModel = localStorage.getItem(`pdf_translator_model_${engine}`);
            if (savedModel && modelInfo.models.includes(savedModel)) {
                modelSelect.value = savedModel;
            } else {
                modelSelect.value = modelInfo.default;
            }

            // íŒíŠ¸ ì—…ë°ì´íŠ¸
            updateModelHint();
        }

        // ëª¨ë¸ íŒíŠ¸ ì—…ë°ì´íŠ¸
        function updateModelHint() {
            const engine = aiEngineSelect.value;
            const model = modelSelect.value;
            const hint = aiModels[engine].hints[model] || '';
            modelHint.textContent = hint;
        }

        // ì„¤ì • ëª¨ë‹¬ ì—´ê¸°
        settingsBtn.addEventListener('click', () => {
            initSettings();
            settingsModal.classList.add('active');
        });

        // ì„¤ì • ëª¨ë‹¬ ë‹«ê¸°
        function closeModal() {
            settingsModal.classList.remove('active');
        }
        closeSettings.addEventListener('click', closeModal);
        cancelSettings.addEventListener('click', closeModal);
        settingsModal.addEventListener('click', (e) => {
            if (e.target === settingsModal) closeModal();
        });

        // AI ì—”ì§„ ë³€ê²½ ì‹œ
        aiEngineSelect.addEventListener('change', () => {
            updateApiKeyVisibility();
            updateModelOptions();
        });

        // ëª¨ë¸ ë³€ê²½ ì‹œ
        modelSelect.addEventListener('change', updateModelHint);

        // API í‚¤ í‘œì‹œ/ìˆ¨ê¹€ í† ê¸€
        toggleApiKey.addEventListener('click', () => {
            if (apiKeyInput.type === 'password') {
                apiKeyInput.type = 'text';
                toggleApiKey.textContent = 'ğŸ™ˆ';
            } else {
                apiKeyInput.type = 'password';
                toggleApiKey.textContent = 'ğŸ‘ï¸';
            }
        });

        // ì„¤ì • ì €ì¥
        saveSettings.addEventListener('click', () => {
            const engine = aiEngineSelect.value;
            const model = modelSelect.value;
            currentAiEngine = engine;
            currentModel = model;

            // localStorageì— ì €ì¥
            localStorage.setItem('pdf_translator_ai_engine', engine);
            localStorage.setItem(`pdf_translator_model_${engine}`, model);

            // API í‚¤ ì €ì¥ (Ollama ì œì™¸)
            if (engine !== 'ollama' && apiKeyInput.value) {
                apiKeys[engine] = apiKeyInput.value;
                localStorage.setItem('pdf_translator_api_keys', JSON.stringify(apiKeys));
            }

            closeModal();
            status.className = 'status success';
            status.innerHTML = `âœ… ${getEngineName(engine)} - ${model} ì„¤ì • ì™„ë£Œ`;
        });

        // ì—”ì§„ ì´ë¦„ ë°˜í™˜
        function getEngineName(engine) {
            const names = {
                ollama: 'Ollama (ë¡œì»¬)',
                claude: 'Claude',
                openai: 'GPT-4',
                gemini: 'Gemini'
            };
            return names[engine] || engine;
        }

        // í˜„ì¬ API í‚¤ ê°€ì ¸ì˜¤ê¸°
        function getCurrentApiKey() {
            if (currentAiEngine === 'ollama') return null;
            return apiKeys[currentAiEngine] || null;
        }

        // í˜„ì¬ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        function getCurrentModel() {
            const savedModel = localStorage.getItem(`pdf_translator_model_${currentAiEngine}`);
            if (savedModel) return savedModel;
            return aiModels[currentAiEngine]?.default || null;
        }

        // íŒŒì¼ ì„ íƒ ë²„íŠ¼
        fileSelectBtn.addEventListener('click', () => fileInput.click());

        // íŒŒì¼ ì„ íƒ ì‹œ ìë™ OCR
        fileInput.addEventListener('change', async () => {
            if (!fileInput.files.length) return;

            const file = fileInput.files[0];
            fileSelectBtn.classList.add('has-file');
            fileSelectBtn.textContent = 'âœ… ' + file.name.substring(0, 8) + (file.name.length > 8 ? '...' : '');

            // OCR ì‹¤í–‰
            await loadAndProcessFile(file);
        });

        // ì–¸ì–´ ì„ íƒ
        langBtns.forEach(btn => {
            btn.addEventListener('click', async () => {
                langBtns.forEach(b => b.classList.remove('active'));
                btn.classList.add('active');
                targetLang.value = btn.dataset.lang;

                // ì´ë¯¸ íŒŒì¼ì´ ë¡œë“œë˜ì–´ ìˆìœ¼ë©´ ì „ì²´ í˜ì´ì§€ ì¬ë²ˆì—­
                if (pagesData.length > 0) {
                    await retranslateAllPages();
                }
            });
        });

        // íŒŒì¼ ë¡œë“œ ë° OCR ì²˜ë¦¬
        let progressInterval = null;
        
        async function loadAndProcessFile(file) {
            status.className = 'status processing';
            status.innerHTML = '<span class="spinner"></span>íŒŒì¼ ë¶„ì„ ì¤‘... ì‹œì‘ ì¤‘';
            initialGuide.style.display = 'none';
            editorContainer.classList.remove('active');
            results.classList.remove('active');

            // â˜… ì§„í–‰ ìƒí™© í´ë§ ì‹œì‘
            progressInterval = setInterval(async () => {
                try {
                    const progRes = await fetch('/progress');
                    const prog = await progRes.json();
                    if (prog.stage) {
                        // "ì™„ë£Œ" ìƒíƒœë©´ ìŠ¤í”¼ë„ˆ ì—†ì´ í‘œì‹œ
                        if (prog.stage === 'ì™„ë£Œ') {
                            status.innerHTML = `âœ… ${prog.stage} (${prog.current}/${prog.total}) - ${prog.detail}`;
                        } else {
                            status.innerHTML = `<span class="spinner"></span>${prog.stage} (${prog.current}/${prog.total}) - ${prog.detail} [${prog.elapsed}]`;
                        }
                    }
                } catch (e) {}
            }, 500);

            const formData = new FormData();
            formData.append('file', file);
            formData.append('target_lang', targetLang.value);
            formData.append('ai_engine', currentAiEngine);
            formData.append('model', getCurrentModel());
            const apiKey = getCurrentApiKey();
            if (apiKey) {
                formData.append('api_key', apiKey);
            }

            try {
                const response = await fetch('/analyze', {
                    method: 'POST',
                    body: formData
                });

                // â˜… í´ë§ ì¤‘ì§€
                if (progressInterval) {
                    clearInterval(progressInterval);
                    progressInterval = null;
                }

                const data = await response.json();

                if (data.success) {
                    pagesData = data.pages;
                    totalPages = pagesData.length;
                    currentPage = 0;

                    status.className = 'status success';
                    status.innerHTML = `âœ… ${totalPages}í˜ì´ì§€ ë¶„ì„ ì™„ë£Œ! ë²ˆì—­ì„ í¸ì§‘í•˜ì„¸ìš”.`;

                    // ì—ë””í„° í‘œì‹œ
                    editorContainer.classList.add('active');
                    translateBtn.disabled = false;

                    // ì²« í˜ì´ì§€ í‘œì‹œ
                    showPage(0);
                } else {
                    status.className = 'status error';
                    status.innerHTML = `âŒ ì˜¤ë¥˜: ${data.error}`;
                    initialGuide.style.display = 'block';
                }
            } catch (err) {
                // â˜… ì—ëŸ¬ ì‹œì—ë„ í´ë§ ì¤‘ì§€
                if (progressInterval) {
                    clearInterval(progressInterval);
                    progressInterval = null;
                }
                status.className = 'status error';
                status.innerHTML = `âŒ ì˜¤ë¥˜: ${err.message}`;
                initialGuide.style.display = 'block';
            }
        }

        // í˜ì´ì§€ í‘œì‹œ
        function showPage(pageIdx) {
            if (pageIdx < 0 || pageIdx >= totalPages) return;

            currentPage = pageIdx;
            const page = pagesData[pageIdx];

            // ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œì— ë”°ë¼ ì´ë¯¸ì§€ í‘œì‹œ
            if (isPreviewMode) {
                showPreviewImage(pageIdx);
            } else {
                previewImg.src = 'data:image/png;base64,' + page.image;
            }

            // í˜ì´ì§€ ì •ë³´
            pageInfo.textContent = `í˜ì´ì§€ ${pageIdx + 1} / ${totalPages}`;

            // ë„¤ë¹„ê²Œì´ì…˜ ë²„íŠ¼
            prevPageBtn.disabled = pageIdx === 0;
            nextPageBtn.disabled = pageIdx === totalPages - 1;

            // ë²ˆì—­ í…Œì´ë¸” ê°±ì‹ 
            updateTranslationTable(page);

            // í™•ì • ë²„íŠ¼ ìƒíƒœ
            if (page.confirmed) {
                confirmBtn.textContent = 'âœ” í™•ì •ë¨';
                confirmBtn.classList.add('confirmed');
            } else {
                confirmBtn.textContent = 'âœ… í™•ì •';
                confirmBtn.classList.remove('confirmed');
            }
        }

        // ë¯¸ë¦¬ë³´ê¸° ì´ë¯¸ì§€ ë¡œë“œ
        async function showPreviewImage(pageIdx, forceRefresh = false) {
            const page = pagesData[pageIdx];

            console.log('[Preview Debug] pageIdx:', pageIdx);
            console.log('[Preview Debug] translations:', page.translations);
            console.log('[Preview Debug] translations length:', page.translations ? page.translations.length : 'undefined');

            // ìºì‹œì— ìˆìœ¼ë©´ ë°”ë¡œ í‘œì‹œ (ê°•ì œ ìƒˆë¡œê³ ì¹¨ì´ ì•„ë‹Œ ê²½ìš°)
            if (!forceRefresh && previewCache[pageIdx]) {
                console.log('[Preview Debug] Using cached preview');
                previewImg.src = 'data:image/png;base64,' + previewCache[pageIdx];
                return;
            }

            // ë²ˆì—­ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì›ë³¸ í‘œì‹œ
            if (!page.translations || page.translations.length === 0) {
                console.log('[Preview Debug] No translations, showing original image');
                previewImg.src = 'data:image/png;base64,' + page.image;
                return;
            }

            // ë¡œë”© í‘œì‹œ
            showPreviewBtn.classList.add('loading');
            showPreviewBtn.textContent = 'â³ ìƒì„±ì¤‘...';

            try {
                console.log('[Preview Debug] Sending request to /generate_preview...');
                console.log('[Preview Debug] image length:', page.image ? page.image.length : 'null');
                console.log('[Preview Debug] translations count:', page.translations ? page.translations.length : 0);
                
                const response = await fetch('/generate_preview', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({
                        image: page.image,
                        translations: page.translations,
                        target_lang: targetLang.value
                    })
                });

                console.log('[Preview Debug] Response status:', response.status);
                const data = await response.json();
                console.log('[Preview Debug] Response data:', data.success, data.error || 'OK');

                if (data.success) {
                    previewCache[pageIdx] = data.preview;
                    previewImg.src = 'data:image/png;base64,' + data.preview;
                    console.log('[Preview Debug] Preview loaded successfully');
                } else {
                    console.error('Preview generation failed:', data.error);
                    alert('ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì‹¤íŒ¨: ' + data.error);
                    previewImg.src = 'data:image/png;base64,' + page.image;
                }
            } catch (error) {
                console.error('Preview error:', error);
                alert('ë¯¸ë¦¬ë³´ê¸° ì˜¤ë¥˜: ' + error.message);
                previewImg.src = 'data:image/png;base64,' + page.image;
            } finally {
                console.log('[Preview Debug] Finally block executed');
                showPreviewBtn.classList.remove('loading');
                showPreviewBtn.textContent = 'ğŸ”„ ë¯¸ë¦¬ë³´ê¸°';
            }
        }

        // ë¯¸ë¦¬ë³´ê¸° ìºì‹œ ì´ˆê¸°í™” (ë²ˆì—­ ìˆ˜ì • ì‹œ)
        function invalidatePreviewCache(pageIdx) {
            delete previewCache[pageIdx];
        }

        // ì›ë³¸/ë¯¸ë¦¬ë³´ê¸° í† ê¸€
        showOriginalBtn.addEventListener('click', () => {
            if (!isPreviewMode) return;
            isPreviewMode = false;
            showOriginalBtn.classList.add('active');
            showPreviewBtn.classList.remove('active');
            const page = pagesData[currentPage];
            previewImg.src = 'data:image/png;base64,' + page.image;
        });

        showPreviewBtn.addEventListener('click', (e) => {
            const forceRefresh = e.shiftKey;  // Shift+í´ë¦­ìœ¼ë¡œ ê°•ì œ ìƒˆë¡œê³ ì¹¨
            if (forceRefresh) {
                console.log('[Preview Debug] Force refresh requested');
                delete previewCache[currentPage];  // ìºì‹œ ì‚­ì œ
            }
            if (isPreviewMode && !forceRefresh) return;
            isPreviewMode = true;
            showPreviewBtn.classList.add('active');
            showOriginalBtn.classList.remove('active');
            showPreviewImage(currentPage, forceRefresh);
        });

        // ë²ˆì—­ í…Œì´ë¸” ê°±ì‹ 
        function updateTranslationTable(page) {
            translationBody.innerHTML = '';

            if (!page.translations || page.translations.length === 0) {
                translationBody.innerHTML = '<tr><td colspan="3" style="text-align:center;color:#999;padding:30px;">í•œê¸€ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤</td></tr>';
                return;
            }

            page.translations.forEach((item, idx) => {
                const tr = document.createElement('tr');
                tr.innerHTML = `
                    <td class="idx">${idx + 1}</td>
                    <td class="korean">${escapeHtml(item.text)}</td>
                    <td>
                        <input type="text" class="trans-input"
                               data-idx="${idx}"
                               data-original="${escapeHtml(item.translated)}"
                               value="${escapeHtml(item.translated)}">
                    </td>
                `;
                translationBody.appendChild(tr);
            });

            // ì…ë ¥ í•„ë“œ ì´ë²¤íŠ¸
            translationBody.querySelectorAll('.trans-input').forEach(input => {
                input.addEventListener('input', (e) => {
                    const original = e.target.dataset.original;
                    if (e.target.value !== original) {
                        e.target.classList.add('modified');
                    } else {
                        e.target.classList.remove('modified');
                    }
                    // ìˆ˜ì • ì‹œ í™•ì • í•´ì œ
                    pagesData[currentPage].confirmed = false;
                    confirmBtn.textContent = 'âœ… í™•ì •';
                    confirmBtn.classList.remove('confirmed');

                    // ë¯¸ë¦¬ë³´ê¸° ìºì‹œ ë¬´íš¨í™”
                    invalidatePreviewCache(currentPage);
                });
            });
        }

        // HTML ì´ìŠ¤ì¼€ì´í”„
        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }

        // í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜
        prevPageBtn.addEventListener('click', () => {
            saveCurrentTranslations();
            showPage(currentPage - 1);
        });

        nextPageBtn.addEventListener('click', () => {
            saveCurrentTranslations();
            showPage(currentPage + 1);
        });

        // í˜„ì¬ í˜ì´ì§€ ë²ˆì—­ ì €ì¥
        function saveCurrentTranslations() {
            const inputs = translationBody.querySelectorAll('.trans-input');
            inputs.forEach(input => {
                const idx = parseInt(input.dataset.idx);
                if (pagesData[currentPage].translations[idx]) {
                    pagesData[currentPage].translations[idx].translated = input.value;
                }
            });
        }

        // í™•ì • ë²„íŠ¼
        confirmBtn.addEventListener('click', () => {
            saveCurrentTranslations();
            pagesData[currentPage].confirmed = true;
            confirmBtn.textContent = 'âœ” í™•ì •ë¨';
            confirmBtn.classList.add('confirmed');

            // ëª¨ë“  ì…ë ¥ í•„ë“œ modified í´ë˜ìŠ¤ ì œê±°
            translationBody.querySelectorAll('.trans-input').forEach(input => {
                input.classList.remove('modified');
                input.dataset.original = input.value;
            });

            status.className = 'status success';
            status.innerHTML = `âœ… í˜ì´ì§€ ${currentPage + 1} ë²ˆì—­ í™•ì •ë¨`;
            
            // ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œë©´ ì¦‰ì‹œ ê°±ì‹  (ìºì‹œ ë¬´íš¨í™” í›„)
            if (isPreviewMode) {
                delete previewCache[currentPage];  // ìºì‹œ ì‚­ì œ
                showPreviewImage(currentPage, true);  // ê°•ì œ ìƒˆë¡œê³ ì¹¨
            }
        });

        // ëª¨ë“  í˜ì´ì§€ ì¬ë²ˆì—­ (ì–¸ì–´ ë³€ê²½ ì‹œ)
        async function retranslateAllPages() {
            if (pagesData.length === 0) return;

            // ë¯¸ë¦¬ë³´ê¸° ìºì‹œ ì „ì²´ ì´ˆê¸°í™”
            previewCache = {};

            status.className = 'status processing';
            status.innerHTML = '<span class="spinner"></span>ì–¸ì–´ ë³€ê²½ ì¤‘... ì „ì²´ í˜ì´ì§€ ì¬ë²ˆì—­ ì¤‘ì…ë‹ˆë‹¤';

            try {
                // ëª¨ë“  í˜ì´ì§€ ì¬ë²ˆì—­
                for (let i = 0; i < pagesData.length; i++) {
                    status.innerHTML = `<span class="spinner"></span>ì¬ë²ˆì—­ ì¤‘... (${i + 1}/${pagesData.length})`;

                    const response = await fetch('/retranslate', {
                        method: 'POST',
                        headers: {'Content-Type': 'application/json'},
                        body: JSON.stringify({
                            page_idx: i,
                            target_lang: targetLang.value,
                            ai_engine: currentAiEngine,
                            model: getCurrentModel(),
                            api_key: getCurrentApiKey(),
                            image: pagesData[i].image,
                            texts: pagesData[i].translations.map(t => ({
                                text: t.text,
                                bbox: t.bbox
                            }))
                        })
                    });

                    const data = await response.json();
                    if (data.success) {
                        pagesData[i].translations = data.translations;
                        pagesData[i].confirmed = false;
                    }
                }

                // í˜„ì¬ í˜ì´ì§€ ë‹¤ì‹œ í‘œì‹œ
                showPage(currentPage);
                status.className = 'status success';
                status.innerHTML = `âœ… ì „ì²´ ${pagesData.length}í˜ì´ì§€ ì¬ë²ˆì—­ ì™„ë£Œ`;
            } catch (err) {
                status.className = 'status error';
                status.innerHTML = `âŒ ì¬ë²ˆì—­ ì˜¤ë¥˜: ${err.message}`;
            }
        }

        // ë¦¬ì‚¬ì´ì € ë“œë˜ê·¸ ê¸°ëŠ¥
        const resizer = document.getElementById('resizer');
        const previewPanel = document.getElementById('previewPanel');
        const translationPanel = document.getElementById('translationPanel');

        let isResizing = false;

        resizer.addEventListener('mousedown', (e) => {
            isResizing = true;
            document.body.style.cursor = 'col-resize';
            document.body.style.userSelect = 'none';
        });

        document.addEventListener('mousemove', (e) => {
            if (!isResizing) return;

            const containerRect = editorContainer.getBoundingClientRect();
            const containerWidth = containerRect.width;
            const mouseX = e.clientX - containerRect.left;

            // ë²ˆì—­ íŒ¨ë„ ë„ˆë¹„ = ì»¨í…Œì´ë„ˆ ì˜¤ë¥¸ìª½ ëì—ì„œ ë§ˆìš°ìŠ¤ ìœ„ì¹˜ê¹Œì§€
            const newTranslationWidth = containerWidth - mouseX - 8; // 8px for resizer

            // ìµœì†Œ/ìµœëŒ€ ì œí•œ
            if (newTranslationWidth >= 300 && newTranslationWidth <= containerWidth - 300) {
                translationPanel.style.width = newTranslationWidth + 'px';
            }
        });

        document.addEventListener('mouseup', () => {
            if (isResizing) {
                isResizing = false;
                document.body.style.cursor = '';
                document.body.style.userSelect = '';
            }
        });

        // ìµœì¢… ë²ˆì—­ ë²„íŠ¼
        translateBtn.addEventListener('click', async () => {
            // í˜„ì¬ í˜ì´ì§€ ì €ì¥
            saveCurrentTranslations();

            // ë¯¸í™•ì • í˜ì´ì§€ í™•ì¸
            const unconfirmed = pagesData.filter(p => !p.confirmed).length;
            if (unconfirmed > 0) {
                if (!confirm(`${unconfirmed}ê°œ í˜ì´ì§€ê°€ ë¯¸í™•ì •ì…ë‹ˆë‹¤. ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?`)) {
                    return;
                }
            }

            translateBtn.disabled = true;
            status.className = 'status processing';
            status.innerHTML = '<span class="spinner"></span>ìµœì¢… ë²ˆì—­ë³¸ ìƒì„± ì¤‘...';

            try {
                const response = await fetch('/generate', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({
                        pages: pagesData,
                        target_lang: targetLang.value
                    })
                });

                const data = await response.json();

                if (data.success) {
                    status.className = 'status success';
                    status.innerHTML = `âœ… ë²ˆì—­ ì™„ë£Œ! ${data.files.length}ê°œ íŒŒì¼ ìƒì„±ë¨`;

                    // ê²°ê³¼ í‘œì‹œ
                    editorContainer.classList.remove('active');
                    results.classList.add('active');
                    results.innerHTML = data.files.map(file => `
                        <div class="result-item">
                            <img src="/output/${file}" alt="${file}">
                            <a href="/download/${file}" class="download">ğŸ“¥ ë‹¤ìš´ë¡œë“œ</a>
                        </div>
                    `).join('');
                } else {
                    status.className = 'status error';
                    status.innerHTML = `âŒ ì˜¤ë¥˜: ${data.error}`;
                }
            } catch (err) {
                status.className = 'status error';
                status.innerHTML = `âŒ ì˜¤ë¥˜: ${err.message}`;
            }

            translateBtn.disabled = false;
        });

        // ============================================================================
        // ìš©ì–´ ì‚¬ì „ ê´€ë¦¬
        // ============================================================================
        const dictBtn = document.getElementById('dictBtn');
        const dictModal = document.getElementById('dictModal');
        const closeDict = document.getElementById('closeDict');
        const closeDictBtn = document.getElementById('closeDictBtn');
        const dictTabs = document.querySelectorAll('.dict-tab');
        const dictBody = document.getElementById('dictBody');
        const dictKorean = document.getElementById('dictKorean');
        const dictTranslation = document.getElementById('dictTranslation');
        const addTermBtn = document.getElementById('addTermBtn');
        const dictSearch = document.getElementById('dictSearch');
        const dictCount = document.getElementById('dictCount');

        let currentDictLang = 'english';
        let dictData = {};

        // ëª¨ë‹¬ ì—´ê¸°
        dictBtn.addEventListener('click', async () => {
            dictModal.classList.add('active');
            await loadDictionary();
        });

        // ëª¨ë‹¬ ë‹«ê¸°
        closeDict.addEventListener('click', () => dictModal.classList.remove('active'));
        closeDictBtn.addEventListener('click', () => dictModal.classList.remove('active'));
        dictModal.addEventListener('click', (e) => {
            if (e.target === dictModal) dictModal.classList.remove('active');
        });

        // íƒ­ ì „í™˜
        dictTabs.forEach(tab => {
            tab.addEventListener('click', () => {
                dictTabs.forEach(t => t.classList.remove('active'));
                tab.classList.add('active');
                currentDictLang = tab.dataset.lang;
                renderDictTable();
            });
        });

        // ì‚¬ì „ ë¡œë“œ
        async function loadDictionary() {
            try {
                const res = await fetch('/api/dictionary');
                dictData = await res.json();
                renderDictTable();
            } catch (err) {
                console.error('Failed to load dictionary:', err);
            }
        }

        // í…Œì´ë¸” ë Œë”ë§
        function renderDictTable() {
            const langDict = dictData[currentDictLang] || {};
            const searchTerm = dictSearch.value.toLowerCase();

            const entries = Object.entries(langDict)
                .filter(([kr, termData]) => {
                    const full = typeof termData === 'object' ? termData.full : termData;
                    const abbr = typeof termData === 'object' ? (termData.abbr || '') : '';
                    return kr.toLowerCase().includes(searchTerm) ||
                           full.toLowerCase().includes(searchTerm) ||
                           abbr.toLowerCase().includes(searchTerm);
                })
                .sort((a, b) => a[0].localeCompare(b[0], 'ko'));

            dictBody.innerHTML = entries.map(([korean, termData]) => {
                const full = typeof termData === 'object' ? termData.full : termData;
                const abbr = typeof termData === 'object' ? (termData.abbr || '') : '';
                return `
                <tr data-korean="${korean}">
                    <td class="korean-cell">${korean}</td>
                    <td class="trans-cell">${full}</td>
                    <td class="abbr-cell">${abbr}</td>
                    <td class="actions">
                        <button class="edit-btn" onclick="editTerm('${korean}')">âœï¸</button>
                        <button class="delete-btn" onclick="deleteTerm('${korean}')">ğŸ—‘ï¸</button>
                    </td>
                </tr>
            `}).join('');

            dictCount.textContent = `ì´ ${entries.length}ê°œ ìš©ì–´`;
        }

        // ê²€ìƒ‰
        dictSearch.addEventListener('input', renderDictTable);

        // ìš©ì–´ ì¶”ê°€
        addTermBtn.addEventListener('click', async () => {
            const korean = dictKorean.value.trim();
            const translation = dictTranslation.value.trim();
            const abbr = document.getElementById('dictAbbr').value.trim();

            if (!korean || !translation) {
                alert('í•œê¸€ ìš©ì–´ì™€ ë²ˆì—­ì„ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.');
                return;
            }

            try {
                const res = await fetch(`/api/dictionary/${currentDictLang}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ korean, translation, abbr })
                });
                const data = await res.json();

                if (data.success) {
                    dictKorean.value = '';
                    dictTranslation.value = '';
                    document.getElementById('dictAbbr').value = '';
                    await loadDictionary();
                } else {
                    alert('ì¶”ê°€ ì‹¤íŒ¨: ' + data.error);
                }
            } catch (err) {
                alert('ì˜¤ë¥˜: ' + err.message);
            }
        });

        // ìš©ì–´ ìˆ˜ì •
        window.editTerm = function(korean) {
            const row = document.querySelector(`tr[data-korean="${korean}"]`);
            const transCell = row.querySelector('.trans-cell');
            const abbrCell = row.querySelector('.abbr-cell');
            const actionsCell = row.querySelector('.actions');
            const currentTrans = transCell.textContent;
            const currentAbbr = abbrCell.textContent;

            transCell.innerHTML = `<input type="text" class="edit-input edit-trans" value="${currentTrans}">`;
            abbrCell.innerHTML = `<input type="text" class="edit-input edit-abbr" value="${currentAbbr}">`;
            actionsCell.innerHTML = `
                <button class="save-btn" onclick="saveTerm('${korean}')">ğŸ’¾</button>
                <button class="cancel-btn" onclick="renderDictTable()">âœ–ï¸</button>
            `;
            transCell.querySelector('input').focus();
        };

        // ìš©ì–´ ì €ì¥
        window.saveTerm = async function(korean) {
            const row = document.querySelector(`tr[data-korean="${korean}"]`);
            const transInput = row.querySelector('.edit-trans');
            const abbrInput = row.querySelector('.edit-abbr');
            const translation = transInput.value.trim();
            const abbr = abbrInput ? abbrInput.value.trim() : '';

            if (!translation) {
                alert('ë²ˆì—­ì„ ì…ë ¥í•˜ì„¸ìš”.');
                return;
            }

            try {
                const res = await fetch(`/api/dictionary/${currentDictLang}/${encodeURIComponent(korean)}`, {
                    method: 'PUT',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ translation, abbr })
                });
                const data = await res.json();

                if (data.success) {
                    await loadDictionary();
                } else {
                    alert('ìˆ˜ì • ì‹¤íŒ¨: ' + data.error);
                }
            } catch (err) {
                alert('ì˜¤ë¥˜: ' + err.message);
            }
        };

        // ìš©ì–´ ì‚­ì œ
        window.deleteTerm = async function(korean) {
            if (!confirm(`"${korean}" ìš©ì–´ë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?`)) return;

            try {
                const res = await fetch(`/api/dictionary/${currentDictLang}/${encodeURIComponent(korean)}`, {
                    method: 'DELETE'
                });
                const data = await res.json();

                if (data.success) {
                    await loadDictionary();
                } else {
                    alert('ì‚­ì œ ì‹¤íŒ¨: ' + data.error);
                }
            } catch (err) {
                alert('ì˜¤ë¥˜: ' + err.message);
            }
        };
    </script>
</body>
</html>
"""


@app.route('/')
def index():
    return render_template_string(HTML_TEMPLATE, version=VERSION)


# ì„ì‹œ ì €ì¥ì†Œ: ì„¸ì…˜ë³„ ì´ë¯¸ì§€ ê²½ë¡œ
temp_image_paths = {}

# â˜… ì§„í–‰ ìƒí™© ì¶”ì  (v1.4.5)
progress_status = {
    "stage": "",           # í˜„ì¬ ë‹¨ê³„
    "current": 0,          # í˜„ì¬ ì§„í–‰
    "total": 0,            # ì „ì²´
    "detail": "",          # ì„¸ë¶€ ì •ë³´
    "start_time": None     # ì‹œì‘ ì‹œê°„
}

def update_progress(stage, current, total, detail=""):
    """ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸"""
    global progress_status
    progress_status["stage"] = stage
    progress_status["current"] = current
    progress_status["total"] = total
    progress_status["detail"] = detail
    if current == 0:
        progress_status["start_time"] = datetime.now()


@app.route('/progress', methods=['GET'])
def get_progress():
    """ì§„í–‰ ìƒí™© ì¡°íšŒ API"""
    elapsed = ""
    if progress_status["start_time"]:
        delta = datetime.now() - progress_status["start_time"]
        elapsed = f"{int(delta.total_seconds())}ì´ˆ ê²½ê³¼"
    
    return jsonify({
        "stage": progress_status["stage"],
        "current": progress_status["current"],
        "total": progress_status["total"],
        "detail": progress_status["detail"],
        "elapsed": elapsed
    })


@app.route('/analyze', methods=['POST'])
def analyze():
    """íŒŒì¼ ì—…ë¡œë“œ + OCR + ì´ˆê¸° ë²ˆì—­ (ë°°ì¹˜ OCR + ë³‘ë ¬ ë²ˆì—­ ìµœì í™”)"""
    try:
        if 'file' not in request.files:
            return jsonify({"success": False, "error": "íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤"})

        file = request.files['file']
        target_lang = request.form.get('target_lang', 'english')
        ai_engine = request.form.get('ai_engine', 'ollama')
        api_key = request.form.get('api_key', None)
        model = request.form.get('model', None)

        print(f"[AI Engine] {ai_engine}, [Model] {model}", flush=True)
        print(f"[Debug] ai_engine raw: '{request.form.get('ai_engine')}' -> parsed: '{ai_engine}'", flush=True)
        print(f"[Debug] api_key present: {bool(api_key)}, length: {len(api_key) if api_key else 0}", flush=True)

        if file.filename == '':
            return jsonify({"success": False, "error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"})

        # íŒŒì¼ ì €ì¥
        filename = file.filename
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        file.save(filepath)

        # PDFì¸ ê²½ìš° ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if filename.lower().endswith('.pdf'):
            image_paths = pdf_to_images(filepath)
        else:
            image_paths = [filepath]

        # ì„¸ì…˜ ID ìƒì„±
        session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        temp_image_paths[session_id] = image_paths

        pages = []
        total_pages = len(image_paths)
        all_pages_data = []
        
        import time  # ì„±ëŠ¥ ì¸¡ì •ìš©

        # ===== 1ë‹¨ê³„: ë°°ì¹˜ OCR (ëª¨ë“  í˜ì´ì§€ í•œë²ˆì—) =====
        update_progress("OCR", 1, total_pages, f"ì „ì²´ {total_pages}ê°œ í˜ì´ì§€ ì¼ê´„ OCR ì²˜ë¦¬ ì¤‘...")
        print(f"[Batch OCR] Processing {total_pages} pages at once...", flush=True)
        
        ocr_start = time.time()
        all_ocr_results = get_ocr_results_batch(image_paths)
        ocr_time = time.time() - ocr_start
        print(f"[TIMING] OCR took {ocr_time:.2f}s for {total_pages} pages", flush=True)
        
        # OCR ê²°ê³¼ì™€ ì´ë¯¸ì§€ ì •ë³´ ê²°í•©
        for i, (img_path, texts) in enumerate(zip(image_paths, all_ocr_results)):
            with open(img_path, "rb") as f:
                image_base64 = base64.b64encode(f.read()).decode()
            
            all_pages_data.append({
                "page_idx": i,
                "img_path": img_path,
                "image_base64": image_base64,
                "texts": texts
            })
        
        print(f"[Batch OCR] Complete - {sum(len(p['texts']) for p in all_pages_data)} total texts", flush=True)

        # ===== 2ë‹¨ê³„: ë²ˆì—­ (ì—”ì§„ë³„ ìµœì í™”) =====
        total_texts = sum(len(p["texts"]) for p in all_pages_data)
        translate_start = time.time()
        
        if ai_engine == "gemini" and api_key and total_texts > 0:
            # Gemini: ë°°ì¹˜ ë²ˆì—­ (1íšŒ API í˜¸ì¶œ)
            update_progress("ë²ˆì—­", 1, 1, f"ì „ì²´ {total_texts}ê°œ í…ìŠ¤íŠ¸ ì¼ê´„ ë²ˆì—­ ì¤‘... (Gemini ë°°ì¹˜)")
            print(f"[Gemini Batch] Total {total_texts} texts from {total_pages} pages", flush=True)
            
            batch_input = [{"page_idx": p["page_idx"], "texts": p["texts"]} for p in all_pages_data]
            translations_by_page = translate_batch_with_gemini(batch_input, target_lang, api_key, model)
            
            translate_time = time.time() - translate_start
            print(f"[TIMING] Gemini Batch Translation took {translate_time:.2f}s for {total_texts} texts", flush=True)

            for page_data in all_pages_data:
                page_idx = page_data["page_idx"]
                translations = translations_by_page.get(page_idx, [])
                pages.append({
                    "image": page_data["image_base64"],
                    "image_path": page_data["img_path"],
                    "translations": translations,
                    "confirmed": False
                })
                
        elif ai_engine in ("claude", "openai") and api_key and total_texts > 0:
            # Claude/OpenAI: ë³‘ë ¬ ë²ˆì—­ (ë™ì‹œ API í˜¸ì¶œ)
            update_progress("ë²ˆì—­", 1, 1, f"ì „ì²´ {total_texts}ê°œ í…ìŠ¤íŠ¸ ë³‘ë ¬ ë²ˆì—­ ì¤‘... ({ai_engine.upper()} ë³‘ë ¬)")
            print(f"[Parallel Translation] {ai_engine.upper()} - {total_pages} pages", flush=True)
            
            translations_by_page = translate_pages_parallel(
                all_pages_data, target_lang, ai_engine, api_key, model, max_workers=5
            )
            
            translate_time = time.time() - translate_start
            print(f"[TIMING] {ai_engine.upper()} Parallel Translation took {translate_time:.2f}s for {total_texts} texts ({total_pages} pages)", flush=True)
            
            for page_data in all_pages_data:
                page_idx = page_data["page_idx"]
                translations = translations_by_page.get(page_idx, [])
                pages.append({
                    "image": page_data["image_base64"],
                    "image_path": page_data["img_path"],
                    "translations": translations,
                    "confirmed": False
                })
                
        else:
            # Ollama ë“±: ìˆœì°¨ ë²ˆì—­ (ë¡œì»¬ ëª¨ë¸ì€ ë³‘ë ¬í™” ì´ì  ì ìŒ)
            for page_data in all_pages_data:
                update_progress("ë²ˆì—­", page_data["page_idx"]+1, total_pages,
                               f"í˜ì´ì§€ {page_data['page_idx']+1}/{total_pages} - {len(page_data['texts'])}ê°œ í…ìŠ¤íŠ¸ ë²ˆì—­ ì¤‘...")

                translations = []
                if page_data["texts"]:
                    translations = translate_with_vlm(page_data["img_path"], page_data["texts"],
                                                      target_lang, ai_engine, api_key, model)

                pages.append({
                    "image": page_data["image_base64"],
                    "image_path": page_data["img_path"],
                    "translations": translations,
                    "confirmed": False
                })

        # â˜… ì§„í–‰ ìƒí™©: ì™„ë£Œ
        update_progress("ì™„ë£Œ", total_pages, total_pages, "ë¶„ì„ ì™„ë£Œ!")

        return jsonify({
            "success": True,
            "session_id": session_id,
            "pages": pages
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"success": False, "error": str(e)})


@app.route('/retranslate', methods=['POST'])
def retranslate():
    """ì–¸ì–´ ë³€ê²½ ì‹œ ì¬ë²ˆì—­ (VLM ì‚¬ìš©)"""
    try:
        data = request.get_json()
        target_lang = data.get('target_lang', 'english')
        ai_engine = data.get('ai_engine', 'ollama')
        api_key = data.get('api_key', None)
        model = data.get('model', None)
        image_base64 = data.get('image', None)
        texts = data.get('texts', [])

        print(f"[Retranslate] AI Engine: {ai_engine}, Model: {model}, Target: {target_lang}")

        # ì´ë¯¸ì§€ê°€ ìˆê³  AI ì—”ì§„ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° VLMìœ¼ë¡œ ë²ˆì—­
        if image_base64 and texts:
            # base64 ì´ë¯¸ì§€ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
            temp_img_path = os.path.join(UPLOAD_FOLDER, f"temp_retrans_{timestamp}.png")
            with open(temp_img_path, 'wb') as f:
                f.write(base64.b64decode(image_base64))

            try:
                # VLMìœ¼ë¡œ ë²ˆì—­ (ì„ íƒëœ AI ì—”ì§„ ì‚¬ìš©)
                text_items = [{"text": item['text'], "bbox": item['bbox']} for item in texts]
                translations = translate_with_vlm(temp_img_path, text_items, target_lang, ai_engine, api_key, model)
            finally:
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                try:
                    os.remove(temp_img_path)
                except:
                    pass
        else:
            # fallback: ì‚¬ì „ ê¸°ë°˜ ë²ˆì—­
            translations = []
            for item in texts:
                translated = translate_with_dict(item['text'], target_lang)
                translations.append({
                    "text": item['text'],
                    "bbox": item['bbox'],
                    "translated": translated
                })

        return jsonify({
            "success": True,
            "translations": translations
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"success": False, "error": str(e)})


@app.route('/generate_preview', methods=['POST'])
def generate_preview():
    """ë²ˆì—­ëœ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸° ìƒì„±"""
    try:
        data = request.get_json()
        image_base64 = data.get('image')
        translations = data.get('translations', [])
        target_lang = data.get('target_lang', 'english')

        print(f"[generate_preview] Received {len(translations)} translations, target_lang={target_lang}")
        for i, t in enumerate(translations[:3]):  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
            print(f"  [{i}] bbox: {t.get('bbox', 'N/A')}, text: {t.get('text', 'N/A')[:20]}...")

        if not image_base64:
            return jsonify({"success": False, "error": "ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤"})

        if not translations:
            print("[generate_preview] ERROR: No translations provided!")
            return jsonify({"success": False, "error": "ë²ˆì—­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"})

        # ë¯¸ë¦¬ë³´ê¸° ì´ë¯¸ì§€ ìƒì„±
        print("[generate_preview] Calling generate_preview_image...")
        preview_base64 = generate_preview_image(image_base64, translations, target_lang)
        print("[generate_preview] Preview generated successfully")

        return jsonify({
            "success": True,
            "preview": preview_base64
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"success": False, "error": str(e)})


@app.route('/generate', methods=['POST'])
def generate():
    """ìµœì¢… ë²ˆì—­ ì´ë¯¸ì§€ ìƒì„±"""
    try:
        data = request.get_json()
        pages = data.get('pages', [])
        target_lang = data.get('target_lang', 'english')

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_files = []

        for i, page in enumerate(pages):
            print(f"[Generate {i+1}/{len(pages)}]")

            # base64 ì´ë¯¸ì§€ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            image_data = base64.b64decode(page['image'])
            temp_img_path = os.path.join(UPLOAD_FOLDER, f"temp_gen_{timestamp}_{i}.png")
            with open(temp_img_path, 'wb') as f:
                f.write(image_data)

            translations = page.get('translations', [])

            if translations:
                # ì´ë¯¸ì§€ì— ë²ˆì—­ ì ìš©
                output_filename = f"translated_{timestamp}_page{i+1}_{target_lang}.png"
                output_path = os.path.join(OUTPUT_FOLDER, output_filename)
                replace_text_in_image(temp_img_path, translations, output_path, target_lang)
                output_files.append(output_filename)
            else:
                print(f"  No translations, skipping...")

            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            try:
                os.remove(temp_img_path)
            except:
                pass

        return jsonify({
            "success": True,
            "files": output_files
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"success": False, "error": str(e)})


@app.route('/translate', methods=['POST'])
def translate():
    """ê¸°ì¡´ í˜¸í™˜ìš©: ë°”ë¡œ ë²ˆì—­"""
    try:
        if 'file' not in request.files:
            return jsonify({"success": False, "error": "íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤"})

        file = request.files['file']
        target_lang = request.form.get('target_lang', 'english')

        if file.filename == '':
            return jsonify({"success": False, "error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"})

        # íŒŒì¼ ì €ì¥
        filename = file.filename
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        file.save(filepath)

        # PDFì¸ ê²½ìš° ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if filename.lower().endswith('.pdf'):
            image_paths = pdf_to_images(filepath)
        else:
            image_paths = [filepath]

        # ê° ì´ë¯¸ì§€ ì²˜ë¦¬
        output_files = []
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        for i, img_path in enumerate(image_paths):
            print(f"[{i+1}/{len(image_paths)}] Processing: {img_path}")

            # OCR
            texts = get_ocr_results(img_path)
            print(f"  Found {len(texts)} Korean texts")

            if texts:
                # ë²ˆì—­
                translations = translate_with_vlm(img_path, texts, target_lang)

                # ì´ë¯¸ì§€ êµì²´
                output_filename = f"translated_{timestamp}_page{i+1}_{target_lang}.png"
                output_path = os.path.join(OUTPUT_FOLDER, output_filename)
                replace_text_in_image(img_path, translations, output_path, target_lang)
                output_files.append(output_filename)
            else:
                print(f"  No Korean text found, skipping...")

        return jsonify({"success": True, "files": output_files})

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"success": False, "error": str(e)})


@app.route('/output/<filename>')
def serve_output(filename):
    return send_file(os.path.join(OUTPUT_FOLDER, filename))


@app.route('/download/<filename>')
def download_file(filename):
    return send_file(
        os.path.join(OUTPUT_FOLDER, filename),
        as_attachment=True,
        download_name=filename
    )


# ============================================================================
# ìš©ì–´ ì‚¬ì „ API
# ============================================================================

@app.route('/api/dictionary', methods=['GET'])
def get_dictionary():
    """ì „ì²´ ìš©ì–´ ì‚¬ì „ ì¡°íšŒ"""
    global GARMENT_DICT
    GARMENT_DICT = load_garment_dict()  # ìµœì‹  ë°ì´í„° ë¡œë“œ
    return jsonify(GARMENT_DICT)

@app.route('/api/dictionary/<language>', methods=['GET'])
def get_dictionary_by_language(language):
    """íŠ¹ì • ì–¸ì–´ì˜ ìš©ì–´ ì‚¬ì „ ì¡°íšŒ"""
    global GARMENT_DICT
    GARMENT_DICT = load_garment_dict()
    if language in GARMENT_DICT:
        return jsonify(GARMENT_DICT[language])
    return jsonify({"error": f"Language '{language}' not found"}), 404

@app.route('/api/dictionary/<language>', methods=['POST'])
def add_term(language):
    """ìš©ì–´ ì¶”ê°€ (í•œê¸€: {full: ë²ˆì—­, abbr: ì•½ì–´})"""
    global GARMENT_DICT
    GARMENT_DICT = load_garment_dict()

    data = request.json
    korean = data.get('korean', '').strip()
    translation = data.get('translation', '').strip()
    abbr = data.get('abbr', '').strip()

    if not korean or not translation:
        return jsonify({"error": "korean and translation are required"}), 400

    if language not in GARMENT_DICT:
        return jsonify({"error": f"Language '{language}' not found"}), 404

    GARMENT_DICT[language][korean] = {"full": translation, "abbr": abbr}

    if save_garment_dict(GARMENT_DICT):
        return jsonify({"success": True, "korean": korean, "translation": translation, "abbr": abbr})
    return jsonify({"error": "Failed to save dictionary"}), 500

@app.route('/api/dictionary/<language>/<korean>', methods=['PUT'])
def update_term(language, korean):
    """ìš©ì–´ ìˆ˜ì •"""
    global GARMENT_DICT
    GARMENT_DICT = load_garment_dict()

    data = request.json
    translation = data.get('translation', '').strip()
    abbr = data.get('abbr', '').strip()

    if not translation:
        return jsonify({"error": "translation is required"}), 400

    if language not in GARMENT_DICT:
        return jsonify({"error": f"Language '{language}' not found"}), 404

    if korean not in GARMENT_DICT[language]:
        return jsonify({"error": f"Term '{korean}' not found"}), 404

    GARMENT_DICT[language][korean] = {"full": translation, "abbr": abbr}

    if save_garment_dict(GARMENT_DICT):
        return jsonify({"success": True, "korean": korean, "translation": translation, "abbr": abbr})
    return jsonify({"error": "Failed to save dictionary"}), 500

@app.route('/api/dictionary/<language>/<korean>', methods=['DELETE'])
def delete_term(language, korean):
    """ìš©ì–´ ì‚­ì œ"""
    global GARMENT_DICT
    GARMENT_DICT = load_garment_dict()

    if language not in GARMENT_DICT:
        return jsonify({"error": f"Language '{language}' not found"}), 404

    if korean not in GARMENT_DICT[language]:
        return jsonify({"error": f"Term '{korean}' not found"}), 404

    del GARMENT_DICT[language][korean]

    if save_garment_dict(GARMENT_DICT):
        return jsonify({"success": True, "deleted": korean})
    return jsonify({"error": "Failed to save dictionary"}), 500

@app.route('/api/dictionary/bulk', methods=['POST'])
def bulk_add_terms():
    """ì—¬ëŸ¬ ì–¸ì–´ì— ë™ì‹œì— ìš©ì–´ ì¶”ê°€"""
    global GARMENT_DICT
    GARMENT_DICT = load_garment_dict()

    data = request.json
    korean = data.get('korean', '').strip()
    translations = data.get('translations', {})  # {language: translation}

    if not korean:
        return jsonify({"error": "korean is required"}), 400

    updated = []
    for lang, trans in translations.items():
        if lang in GARMENT_DICT and trans.strip():
            GARMENT_DICT[lang][korean] = trans.strip()
            updated.append(lang)

    if updated and save_garment_dict(GARMENT_DICT):
        return jsonify({"success": True, "korean": korean, "updated_languages": updated})
    return jsonify({"error": "No valid translations provided or save failed"}), 400


if __name__ == '__main__':
    print("=" * 60)
    print(f"PDF Translator v{VERSION} - ì˜ë¥˜ ê¸°ìˆ ì„œ ë²ˆì—­ ì•±")
    print("=" * 60)
    print(f"Version: {VERSION} ({VERSION_DATE})")
    print("Engine: PaddleOCR + VLM (qwen2.5vl)")
    print("Languages: English, Vietnamese, Chinese, Indonesian, Bengali")
    print("Port: 6009")
    print("=" * 60)

    # OCR ì—”ì§„ ë¯¸ë¦¬ ë¡œë“œ
    get_ocr_engine()

    app.run(host='0.0.0.0', port=6009, debug=True)
