"""
ìŠ¤ë§ˆíŠ¸ í…Œì´ë¸” ì¶”ì¶œê¸° v4
Perplexity Comet ë°©ì‹: ì›ë³¸ PDF ì´ë¯¸ì§€ ìœ„ì— OCR í…ìŠ¤íŠ¸ë¥¼ íˆ¬ëª… ì˜¤ë²„ë ˆì´ë¡œ ë°°ì¹˜
ì‚¬ìš©ìê°€ í…ìŠ¤íŠ¸ë¥¼ ì„ íƒ/ë³µì‚¬í•  ìˆ˜ ìˆê²Œ í•¨ (100% ì •í™•ë„)

v4 ë³€ê²½ì‚¬í•­:
- Comet ë°©ì‹ OCR ì˜¤ë²„ë ˆì´ ì‹œìŠ¤í…œ ì¶”ê°€
- PDF ì´ë¯¸ì§€ + OCR í…ìŠ¤íŠ¸ ì¢Œí‘œ ê¸°ë°˜ íˆ¬ëª… ì˜¤ë²„ë ˆì´
- HTML/CSSë¡œ í…ìŠ¤íŠ¸ ì„ íƒ ê°€ëŠ¥í•˜ê²Œ ë Œë”ë§

v3 ë³€ê²½ì‚¬í•­:
- Granite3.2-vision VLM ì¶”ê°€ (ë¬¸ì„œ ì´í•´ íŠ¹í™” ëª¨ë¸)
- Ollama ê¸°ë°˜ ë¡œì»¬ VLM ì¶”ì¶œ ëª¨ë“œ
- Table TransformerëŠ” í´ë°±ìœ¼ë¡œ ìœ ì§€

v2 ë³€ê²½ì‚¬í•­:
- PaddleOCR ì‚¬ìš© (Tesseract ëŒ€ë¹„ í•œê¸€ ì¸ì‹ë¥  í–¥ìƒ)
- PP-OCRv5 ëª¨ë¸ ì ìš©
"""

import fitz
from PIL import Image
import io
import os
import json
import re
import tempfile
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (PaddleOCR ì—°ê²° ì²´í¬ ìŠ¤í‚µ)
os.environ['DISABLE_MODEL_SOURCE_CHECK'] = 'True'

# Ollama VLM ì„¤ì •
OLLAMA_AVAILABLE = False
try:
    import ollama
    OLLAMA_AVAILABLE = True
except ImportError:
    ollama = None

# PaddleOCR ì„¤ì •
PADDLEOCR_AVAILABLE = False
_paddle_ocr = None

try:
    from paddleocr import PaddleOCR
    PADDLEOCR_AVAILABLE = True
except ImportError:
    PaddleOCR = None

# Tesseract OCR ì„¤ì • (í´ë°±ìš©)
TESSERACT_AVAILABLE = False
try:
    import pytesseract
    pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
    TESSDATA_DIR = str(Path(__file__).parent / "tessdata")
    os.environ['TESSDATA_PREFIX'] = TESSDATA_DIR
    TESSERACT_AVAILABLE = True
except ImportError:
    pytesseract = None

# OCR ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
OCR_AVAILABLE = PADDLEOCR_AVAILABLE or TESSERACT_AVAILABLE

# Table Transformer ì„¤ì •
TABLE_TRANSFORMER_AVAILABLE = False
try:
    import torch
    from transformers import AutoImageProcessor, TableTransformerForObjectDetection
    TABLE_TRANSFORMER_AVAILABLE = True
except ImportError:
    torch = None
    AutoImageProcessor = None
    TableTransformerForObjectDetection = None


# ëª¨ë¸ ìºì‹œ (í•œ ë²ˆë§Œ ë¡œë“œ)
_detection_model = None
_detection_processor = None
_structure_model = None
_structure_processor = None


def get_paddle_ocr():
    """PaddleOCR ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ì‹±ê¸€í†¤)"""
    global _paddle_ocr
    if _paddle_ocr is None and PADDLEOCR_AVAILABLE:
        _paddle_ocr = PaddleOCR(lang='korean')
    return _paddle_ocr


def load_detection_model():
    """í…Œì´ë¸” ê°ì§€ ëª¨ë¸ ë¡œë“œ (ìºì‹œ)"""
    global _detection_model, _detection_processor
    if _detection_model is None:
        _detection_processor = AutoImageProcessor.from_pretrained(
            "microsoft/table-transformer-detection"
        )
        _detection_model = TableTransformerForObjectDetection.from_pretrained(
            "microsoft/table-transformer-detection"
        )
    return _detection_processor, _detection_model


def load_structure_model():
    """í…Œì´ë¸” êµ¬ì¡° ì¸ì‹ ëª¨ë¸ ë¡œë“œ (ìºì‹œ)"""
    global _structure_model, _structure_processor
    if _structure_model is None:
        _structure_processor = AutoImageProcessor.from_pretrained(
            "microsoft/table-transformer-structure-recognition"
        )
        _structure_model = TableTransformerForObjectDetection.from_pretrained(
            "microsoft/table-transformer-structure-recognition"
        )
    return _structure_processor, _structure_model


def pdf_page_to_image(pdf_bytes: bytes, page_num: int = 0, zoom: float = 2.0) -> Image.Image:
    """PDF í˜ì´ì§€ë¥¼ PIL Imageë¡œ ë³€í™˜"""
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    page = doc[page_num]
    mat = fitz.Matrix(zoom, zoom)
    pix = page.get_pixmap(matrix=mat)
    img_bytes = pix.tobytes("png")
    img = Image.open(io.BytesIO(img_bytes))
    doc.close()
    return img


def detect_tables(image: Image.Image, threshold: float = 0.7) -> list:
    """ì´ë¯¸ì§€ì—ì„œ í…Œì´ë¸” ì˜ì—­ ê°ì§€"""
    if not TABLE_TRANSFORMER_AVAILABLE:
        return []

    processor, model = load_detection_model()
    inputs = processor(images=image, return_tensors="pt")

    with torch.no_grad():
        outputs = model(**inputs)

    target_sizes = torch.tensor([image.size[::-1]])
    results = processor.post_process_object_detection(
        outputs, threshold=threshold, target_sizes=target_sizes
    )[0]

    tables = []
    for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
        box_coords = [int(x) for x in box.tolist()]
        tables.append({
            "score": round(score.item(), 3),
            "label": model.config.id2label[label.item()],
            "box": box_coords  # [x1, y1, x2, y2]
        })

    return tables


def detect_table_structure(table_image: Image.Image, threshold: float = 0.5) -> dict:
    """í…Œì´ë¸” ì´ë¯¸ì§€ì—ì„œ ì…€/í–‰/ì—´ êµ¬ì¡° ê°ì§€"""
    if not TABLE_TRANSFORMER_AVAILABLE:
        return {"cells": [], "rows": [], "columns": []}

    processor, model = load_structure_model()
    inputs = processor(images=table_image, return_tensors="pt")

    with torch.no_grad():
        outputs = model(**inputs)

    target_sizes = torch.tensor([table_image.size[::-1]])
    results = processor.post_process_object_detection(
        outputs, threshold=threshold, target_sizes=target_sizes
    )[0]

    cells = []
    rows = []
    columns = []

    for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
        box_coords = [int(x) for x in box.tolist()]
        label_name = model.config.id2label[label.item()]

        item = {
            "score": round(score.item(), 3),
            "box": box_coords
        }

        if "cell" in label_name:
            cells.append(item)
        elif "row" in label_name:
            rows.append(item)
        elif "column" in label_name:
            columns.append(item)

    return {
        "cells": cells,
        "rows": rows,
        "columns": columns
    }


def ocr_cell_paddle(image: Image.Image, box: list) -> str:
    """PaddleOCRë¡œ ì…€ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    ocr = get_paddle_ocr()
    if ocr is None:
        return ""

    x1, y1, x2, y2 = box
    cell_img = image.crop((x1, y1, x2, y2))

    # PIL Imageë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    import tempfile
    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
        cell_img.save(tmp.name)
        tmp_path = tmp.name

    try:
        result = ocr.predict(tmp_path)
        os.unlink(tmp_path)

        if result:
            texts = []
            for res in result:
                if 'rec_texts' in res:
                    texts.extend(res['rec_texts'])
            return ' '.join(texts).strip()
    except Exception as e:
        if os.path.exists(tmp_path):
            os.unlink(tmp_path)
        return ""

    return ""


def ocr_cell_tesseract(image: Image.Image, box: list) -> str:
    """Tesseract OCRë¡œ ì…€ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í´ë°±)"""
    if not TESSERACT_AVAILABLE:
        return ""

    x1, y1, x2, y2 = box
    cell_img = image.crop((x1, y1, x2, y2))

    # OCR ì‹¤í–‰ (í•œê¸€+ì˜ì–´)
    text = pytesseract.image_to_string(cell_img, lang='kor+eng').strip()
    return text


def ocr_cell(image: Image.Image, box: list) -> str:
    """ì…€ ì´ë¯¸ì§€ì—ì„œ OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (PaddleOCR ìš°ì„ , Tesseract í´ë°±)"""
    if PADDLEOCR_AVAILABLE:
        return ocr_cell_paddle(image, box)
    elif TESSERACT_AVAILABLE:
        return ocr_cell_tesseract(image, box)
    return ""


def ocr_full_image_paddle(image: Image.Image) -> list:
    """PaddleOCRë¡œ ì „ì²´ ì´ë¯¸ì§€ OCR (ë” ë¹ ë¥¸ ë°©ì‹)"""
    ocr = get_paddle_ocr()
    if ocr is None:
        return []

    # PIL Imageë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    import tempfile
    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
        image.save(tmp.name)
        tmp_path = tmp.name

    try:
        result = ocr.predict(tmp_path)
        os.unlink(tmp_path)

        if result:
            ocr_results = []
            for res in result:
                if 'rec_texts' in res and 'rec_polys' in res:
                    texts = res['rec_texts']
                    polys = res['rec_polys']
                    scores = res.get('rec_scores', [1.0] * len(texts))

                    for text, poly, score in zip(texts, polys, scores):
                        # polyëŠ” 4ê°œì˜ ì  [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
                        if len(poly) >= 4:
                            x_coords = [p[0] for p in poly]
                            y_coords = [p[1] for p in poly]
                            # numpy int16 â†’ Python int ë³€í™˜ (JSON ì§ë ¬í™” í˜¸í™˜)
                            box = [int(min(x_coords)), int(min(y_coords)), int(max(x_coords)), int(max(y_coords))]
                            ocr_results.append({
                                "text": text,
                                "box": box,
                                "score": float(score) if hasattr(score, 'item') else score
                            })
            return ocr_results
    except Exception as e:
        if os.path.exists(tmp_path):
            os.unlink(tmp_path)

    return []


def organize_cells_to_table(cells: list, table_width: int, table_height: int) -> list:
    """ì…€ë“¤ì„ í–‰/ì—´ êµ¬ì¡°ë¡œ ì •ë¦¬í•˜ì—¬ 2D í…Œì´ë¸” ìƒì„±"""
    if not cells:
        return []

    # ì…€ë“¤ì„ y ì¢Œí‘œ(í–‰)ë¡œ ë¨¼ì € ì •ë ¬, ê°™ì€ í–‰ ë‚´ì—ì„œëŠ” x ì¢Œí‘œ(ì—´)ë¡œ ì •ë ¬
    sorted_cells = sorted(cells, key=lambda c: (c["box"][1], c["box"][0]))

    # í–‰ ê·¸ë£¹ ìƒì„± (y ì¢Œí‘œê°€ ë¹„ìŠ·í•œ ì…€ë“¤ì„ ê°™ì€ í–‰ìœ¼ë¡œ)
    rows = []
    current_row = []
    current_y = None
    y_tolerance = 20  # ê°™ì€ í–‰ìœ¼ë¡œ ê°„ì£¼í•  y ì˜¤ì°¨ ë²”ìœ„

    for cell in sorted_cells:
        y = cell["box"][1]

        if current_y is None:
            current_y = y
            current_row = [cell]
        elif abs(y - current_y) <= y_tolerance:
            current_row.append(cell)
        else:
            # ìƒˆë¡œìš´ í–‰ ì‹œì‘
            rows.append(sorted(current_row, key=lambda c: c["box"][0]))
            current_row = [cell]
            current_y = y

    if current_row:
        rows.append(sorted(current_row, key=lambda c: c["box"][0]))

    # í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì—¬ 2D ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    table_data = []
    for row in rows:
        row_data = [cell.get("text", "") for cell in row]
        table_data.append(row_data)

    return table_data


def extract_smart_tables(pdf_bytes: bytes, progress_callback=None, use_paddle=True) -> dict:
    """
    ìŠ¤ë§ˆíŠ¸ í…Œì´ë¸” ì¶”ì¶œ (Comet ë°©ì‹)
    1. PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    2. Table Transformerë¡œ í…Œì´ë¸” ì˜ì—­ ê°ì§€
    3. ê° í…Œì´ë¸”ì˜ ì…€ êµ¬ì¡° ì¸ì‹
    4. PaddleOCR/Tesseractë¡œ ê° ì…€ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    5. êµ¬ì¡°í™”ëœ í…Œì´ë¸” ë°ì´í„° ë°˜í™˜

    Args:
        pdf_bytes: PDF íŒŒì¼ ë°”ì´íŠ¸
        progress_callback: ì§„í–‰ìƒí™© ì½œë°± í•¨ìˆ˜ (page, total, message)
        use_paddle: PaddleOCR ì‚¬ìš© ì—¬ë¶€ (Falseë©´ Tesseract ì‚¬ìš©)
    """
    if not TABLE_TRANSFORMER_AVAILABLE:
        return {
            "tables": [],
            "error": "Table Transformerê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "is_ai_extracted": False
        }

    if not OCR_AVAILABLE:
        return {
            "tables": [],
            "error": "OCR(PaddleOCR ë˜ëŠ” Tesseract)ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "is_ai_extracted": False
        }

    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    total_pages = len(doc)

    # OCR ì—”ì§„ ì •ë³´
    ocr_engine = "PaddleOCR" if (use_paddle and PADDLEOCR_AVAILABLE) else "Tesseract"

    result = {
        "tables": [],
        "is_ai_extracted": True,
        "total_pages": total_pages,
        "ocr_engine": ocr_engine
    }

    for page_num in range(total_pages):
        if progress_callback:
            progress_callback(page_num + 1, total_pages, f"í˜ì´ì§€ {page_num + 1}/{total_pages} ì²˜ë¦¬ ì¤‘...")

        # PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        page = doc[page_num]
        mat = fitz.Matrix(2.0, 2.0)  # 2x í™•ëŒ€
        pix = page.get_pixmap(matrix=mat)
        img_bytes = pix.tobytes("png")
        page_image = Image.open(io.BytesIO(img_bytes))

        # í…Œì´ë¸” ì˜ì—­ ê°ì§€
        detected_tables = detect_tables(page_image, threshold=0.7)

        for table_idx, table_info in enumerate(detected_tables):
            if progress_callback:
                progress_callback(
                    page_num + 1, total_pages,
                    f"í˜ì´ì§€ {page_num + 1} - í…Œì´ë¸” {table_idx + 1} êµ¬ì¡° ë¶„ì„ ì¤‘..."
                )

            # í…Œì´ë¸” ì˜ì—­ í¬ë¡­
            x1, y1, x2, y2 = table_info["box"]
            table_image = page_image.crop((x1, y1, x2, y2))

            # ì…€ êµ¬ì¡° ì¸ì‹
            structure = detect_table_structure(table_image, threshold=0.5)
            cells = structure["cells"]

            if not cells:
                continue

            # ê° ì…€ì—ì„œ OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if progress_callback:
                progress_callback(
                    page_num + 1, total_pages,
                    f"í˜ì´ì§€ {page_num + 1} - í…Œì´ë¸” {table_idx + 1} OCR ì¤‘... ({ocr_engine})"
                )

            for cell in cells:
                if use_paddle and PADDLEOCR_AVAILABLE:
                    cell["text"] = ocr_cell_paddle(table_image, cell["box"])
                else:
                    cell["text"] = ocr_cell_tesseract(table_image, cell["box"])

            # ì…€ë“¤ì„ 2D í…Œì´ë¸” êµ¬ì¡°ë¡œ ì •ë¦¬
            table_data = organize_cells_to_table(
                cells,
                table_image.width,
                table_image.height
            )

            if table_data:
                result["tables"].append({
                    "page": page_num + 1,
                    "table_index": table_idx + 1,
                    "confidence": table_info["score"],
                    "data": table_data,
                    "cell_count": len(cells),
                    "row_count": len(table_data),
                    "col_count": max(len(row) for row in table_data) if table_data else 0
                })

    doc.close()
    return result


def is_scanned_pdf(pdf_bytes: bytes) -> bool:
    """PDFê°€ ìŠ¤ìº”(ì´ë¯¸ì§€ ê¸°ë°˜)ì¸ì§€ í™•ì¸"""
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")

    for page_num in range(min(3, len(doc))):  # ì²˜ìŒ 3í˜ì´ì§€ë§Œ í™•ì¸
        page = doc[page_num]
        text = page.get_text().strip()

        if len(text) > 50:  # í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ í…ìŠ¤íŠ¸ PDF
            doc.close()
            return False

    doc.close()
    return True


def extract_text_with_coordinates(pdf_bytes: bytes, progress_callback=None) -> dict:
    """
    í…ìŠ¤íŠ¸ PDFì—ì„œ PyMuPDFë¡œ ì§ì ‘ í…ìŠ¤íŠ¸+ì¢Œí‘œ ì¶”ì¶œ (OCR ìŠ¤í‚µ)
    OCR ëŒ€ì‹  PDF ë‚´ì¥ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ 100% ì •í™•ë„

    Args:
        pdf_bytes: PDF íŒŒì¼ ë°”ì´íŠ¸
        progress_callback: ì§„í–‰ìƒí™© ì½œë°± í•¨ìˆ˜

    Returns:
        OCR ê²°ê³¼ì™€ ë™ì¼í•œ í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬
        {
            "pages": [
                {
                    "page": 1,
                    "ocr_results": [{"text": "...", "box": [x1,y1,x2,y2], "score": 1.0}, ...],
                    "image_base64": "...",
                    "width": 1000,
                    "height": 1400
                },
                ...
            ],
            "total_pages": 5,
            "extraction_method": "text_direct",
            "ocr_engine": "PyMuPDF (Direct Text)"
        }
    """
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    total_pages = len(doc)

    result = {
        "pages": [],
        "total_pages": total_pages,
        "extraction_method": "text_direct",
        "ocr_engine": "PyMuPDF (Direct Text)"
    }

    zoom = 2.0  # ì´ë¯¸ì§€ ë Œë”ë§ ë°°ìœ¨

    for page_num in range(total_pages):
        if progress_callback:
            progress_callback(page_num + 1, total_pages, f"í˜ì´ì§€ {page_num + 1}/{total_pages} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")

        page = doc[page_num]

        # í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë Œë”ë§ (Comet ì˜¤ë²„ë ˆì´ìš©)
        mat = fitz.Matrix(zoom, zoom)
        pix = page.get_pixmap(matrix=mat)
        img_bytes = pix.tobytes("png")

        import base64
        img_base64 = base64.b64encode(img_bytes).decode('utf-8')

        # í…ìŠ¤íŠ¸ ë¸”ë¡ ì¶”ì¶œ (ì¢Œí‘œ í¬í•¨)
        # get_text("dict")ëŠ” ë¸”ë¡/ë¼ì¸/ìŠ¤íŒ¬ ë‹¨ìœ„ë¡œ ìƒì„¸ ì •ë³´ ì œê³µ
        text_dict = page.get_text("dict")

        ocr_results = []

        for block in text_dict.get("blocks", []):
            if block.get("type") == 0:  # í…ìŠ¤íŠ¸ ë¸”ë¡ë§Œ
                for line in block.get("lines", []):
                    for span in line.get("spans", []):
                        text = span.get("text", "").strip()
                        if text:
                            # bbox: (x0, y0, x1, y1) - PDF ì¢Œí‘œ
                            bbox = span.get("bbox", [0, 0, 0, 0])
                            # zoom ë°°ìœ¨ ì ìš© (ì´ë¯¸ì§€ ì¢Œí‘œì™€ ë§ì¶”ê¸°)
                            scaled_box = [
                                int(bbox[0] * zoom),
                                int(bbox[1] * zoom),
                                int(bbox[2] * zoom),
                                int(bbox[3] * zoom)
                            ]
                            ocr_results.append({
                                "text": text,
                                "box": scaled_box,
                                "score": 1.0  # ì§ì ‘ ì¶”ì¶œì´ë¯€ë¡œ 100% ì •í™•
                            })

        result["pages"].append({
            "page": page_num + 1,
            "ocr_results": ocr_results,
            "image_base64": img_base64,
            "width": pix.width,
            "height": pix.height
        })

    doc.close()
    return result


# ============================================================
# VLM (Vision Language Model) ê¸°ë°˜ í…Œì´ë¸” ì¶”ì¶œ - Comet ë°©ì‹
# ============================================================

def check_ollama_model(model_name: str = "granite3.2-vision") -> bool:
    """Ollamaì—ì„œ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    if not OLLAMA_AVAILABLE:
        return False
    try:
        result = ollama.list()
        # ollama.list()ëŠ” models ì†ì„±ì„ ê°€ì§„ ê°ì²´ ë°˜í™˜
        models_list = getattr(result, 'models', None)
        if models_list is None and isinstance(result, dict):
            models_list = result.get('models', [])
        if models_list is None:
            models_list = []

        model_names = []
        for m in models_list:
            # Model ê°ì²´ ë˜ëŠ” ë”•ì…”ë„ˆë¦¬ ì²˜ë¦¬
            name = getattr(m, 'model', None)
            if name is None and isinstance(m, dict):
                name = m.get('model')
            if name:
                model_names.append(name.split(':')[0])

        return model_name.split(':')[0] in model_names
    except Exception as e:
        print(f"Ollama ëª¨ë¸ í™•ì¸ ì˜¤ë¥˜: {e}")
        return False


def extract_table_with_vlm(image_path: str, model: str = "granite3.2-vision") -> dict:
    """
    VLMì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ
    Perplexity Comet ë°©ì‹: AIê°€ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ì§ì ‘ í…Œì´ë¸” ë‚´ìš©ì„ ì´í•´

    Args:
        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        model: ì‚¬ìš©í•  Ollama VLM ëª¨ë¸

    Returns:
        ì¶”ì¶œëœ í…Œì´ë¸” ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    if not OLLAMA_AVAILABLE:
        return {"error": "Ollamaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "raw_text": ""}

    # VLM í”„ë¡¬í”„íŠ¸ (ellipsis ... ì œê±°í•˜ì—¬ JSON íŒŒì‹± ì˜¤ë¥˜ ë°©ì§€)
    prompt = '''This is a garment manufacturing document (WORK SHEET).
Extract ALL text and data from this document image.

Focus on these key fields if present:
- STYLE NO / Style Number
- SEASON
- COLOR WAY (all color codes like BK, NA, SV and their names)
- GOODS KIND / Product type
- BRAND
- FACTORY
- ORDER NO
- DELIVERY DATE
- Any table data with rows and columns

Return the data as valid JSON. Example format:
{
    "fields": {
        "STYLE_NO": "ABC123",
        "SEASON": "2024FW",
        "COLOR_WAY": [{"code": "BK", "name": "BLACK"}, {"code": "NA", "name": "NAVY"}],
        "GOODS_KIND": "JACKET",
        "BRAND": "BRAND_NAME"
    },
    "tables": [
        {
            "title": "Size Chart",
            "headers": ["SIZE", "CHEST", "LENGTH"],
            "rows": [["S", "100", "65"], ["M", "105", "67"]]
        }
    ],
    "raw_text": "all visible text"
}

IMPORTANT:
- Return ONLY valid JSON, no ellipsis (...) or placeholder text
- Only include fields that are actually visible in the image
- If no tables found, use empty array: "tables": []'''

    try:
        response = ollama.chat(
            model=model,
            messages=[{
                'role': 'user',
                'content': prompt,
                'images': [image_path]
            }],
            options={'num_predict': 4000, 'temperature': 0.1}
        )

        content = response['message']['content']

        # JSON ì¶”ì¶œ ì‹œë„
        json_match = re.search(r'\{[\s\S]*\}', content)
        if json_match:
            json_str = json_match.group()

            # VLMì´ ellipsisë¥¼ í¬í•¨í–ˆì„ ê²½ìš° ì œê±° (JSON íŒŒì‹± ì˜¤ë¥˜ ë°©ì§€)
            # íŒ¨í„´: , ...] ë˜ëŠ” , ...]
            json_str = re.sub(r',\s*\.\.\.(\s*[\]\}])', r'\1', json_str)
            # íŒ¨í„´: [..., ...] -> [...] (ë°°ì—´ ëì˜ ellipsis)
            json_str = re.sub(r'\.\.\.\s*,?\s*(?=[\]\}])', '', json_str)

            try:
                data = json.loads(json_str)
                data['raw_response'] = content
                return data
            except json.JSONDecodeError as e:
                # ë””ë²„ê·¸ìš©: íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì €ì¥
                return {
                    "raw_text": content,
                    "fields": {},
                    "tables": [],
                    "parse_error": str(e),
                    "json_attempted": json_str[:500]
                }

        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        return {
            "raw_text": content,
            "fields": {},
            "tables": []
        }

    except Exception as e:
        return {
            "error": str(e),
            "raw_text": ""
        }


def extract_vlm_tables(pdf_bytes: bytes, progress_callback=None, model: str = "granite3.2-vision") -> dict:
    """
    VLM(Vision Language Model)ì„ ì‚¬ìš©í•˜ì—¬ PDFì—ì„œ í…Œì´ë¸” ì¶”ì¶œ
    Perplexity Comet ë°©ì‹: AIê°€ ë¬¸ì„œë¥¼ ë³´ê³  ì§ì ‘ ì´í•´í•˜ì—¬ ë°ì´í„° ì¶”ì¶œ

    Args:
        pdf_bytes: PDF íŒŒì¼ ë°”ì´íŠ¸
        progress_callback: ì§„í–‰ìƒí™© ì½œë°± í•¨ìˆ˜ (page, total, message)
        model: ì‚¬ìš©í•  VLM ëª¨ë¸ (ê¸°ë³¸: granite3.2-vision)

    Returns:
        ì¶”ì¶œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if not OLLAMA_AVAILABLE:
        return {
            "tables": [],
            "error": "Ollamaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install ollama' ì‹¤í–‰ í•„ìš”",
            "is_ai_extracted": False,
            "extraction_method": "vlm"
        }

    if not check_ollama_model(model):
        return {
            "tables": [],
            "error": f"ëª¨ë¸ '{model}'ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'ollama pull {model}' ì‹¤í–‰ í•„ìš”",
            "is_ai_extracted": False,
            "extraction_method": "vlm"
        }

    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    total_pages = len(doc)

    result = {
        "tables": [],
        "pages": [],
        "is_ai_extracted": True,
        "total_pages": total_pages,
        "extraction_method": "vlm",
        "model": model
    }

    for page_num in range(total_pages):
        if progress_callback:
            progress_callback(page_num + 1, total_pages, f"í˜ì´ì§€ {page_num + 1}/{total_pages} VLM ë¶„ì„ ì¤‘...")

        # PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        page = doc[page_num]
        mat = fitz.Matrix(2.0, 2.0)  # 2x í™•ëŒ€ë¡œ ë” ì„ ëª…í•˜ê²Œ
        pix = page.get_pixmap(matrix=mat)

        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (Windows í˜¸í™˜)
        tmp_path = os.path.join(tempfile.gettempdir(), f"vlm_page_{page_num}.png")
        pix.save(tmp_path)

        try:
            # VLMìœ¼ë¡œ ì¶”ì¶œ
            vlm_result = extract_table_with_vlm(tmp_path, model)

            # ê²°ê³¼ ì €ì¥
            page_data = {
                "page": page_num + 1,
                "fields": vlm_result.get("fields", {}),
                "tables": vlm_result.get("tables", []),
                "raw_text": vlm_result.get("raw_text", "")
            }

            if "error" in vlm_result:
                page_data["error"] = vlm_result["error"]

            result["pages"].append(page_data)

            # í…Œì´ë¸” ë°ì´í„°ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            for table_idx, table in enumerate(vlm_result.get("tables", [])):
                table_data = []

                # í—¤ë”ê°€ ìˆìœ¼ë©´ ì¶”ê°€
                if table.get("headers"):
                    table_data.append(table["headers"])

                # í–‰ ë°ì´í„° ì¶”ê°€
                for row in table.get("rows", []):
                    table_data.append(row)

                if table_data:
                    result["tables"].append({
                        "page": page_num + 1,
                        "table_index": table_idx + 1,
                        "confidence": 0.95,  # VLMì€ ì‹ ë¢°ë„ë¥¼ ì§ì ‘ ì œê³µí•˜ì§€ ì•ŠìŒ
                        "data": table_data,
                        "title": table.get("title", ""),
                        "row_count": len(table_data),
                        "col_count": max(len(row) for row in table_data) if table_data else 0
                    })

            # í•„ë“œ ë°ì´í„°ë„ í…Œì´ë¸”ë¡œ ë³€í™˜ (í‚¤-ê°’ ìŒ)
            fields = vlm_result.get("fields", {})
            if fields:
                field_table = []
                for key, value in fields.items():
                    if isinstance(value, list):
                        # COLOR_WAY ë“± ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ì²˜ë¦¬
                        for item in value:
                            if isinstance(item, dict):
                                field_table.append([key, f"{item.get('code', '')} - {item.get('name', '')}"])
                            else:
                                field_table.append([key, str(item)])
                    else:
                        field_table.append([key, str(value)])

                if field_table:
                    result["tables"].insert(0, {
                        "page": page_num + 1,
                        "table_index": 0,
                        "confidence": 0.95,
                        "data": [["í•„ë“œ", "ê°’"]] + field_table,
                        "title": "ë¬¸ì„œ í•„ë“œ",
                        "row_count": len(field_table) + 1,
                        "col_count": 2
                    })

        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)

    doc.close()
    return result


# ============================================================
# í†µí•© ì¶”ì¶œ í•¨ìˆ˜
# ============================================================

# ============================================================
# Comet ë°©ì‹ OCR ì˜¤ë²„ë ˆì´ ì‹œìŠ¤í…œ
# PDF ì›ë³¸ ì´ë¯¸ì§€ + íˆ¬ëª… OCR í…ìŠ¤íŠ¸ ë ˆì´ì–´ = ì„ íƒ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸
# ============================================================

import base64


def extract_ocr_with_coordinates(pdf_bytes: bytes, progress_callback=None, zoom: float = 2.0) -> dict:
    """
    Comet ë°©ì‹: PDF í˜ì´ì§€ë³„ë¡œ ì›ë³¸ ì´ë¯¸ì§€ + OCR í…ìŠ¤íŠ¸ ì¢Œí‘œ ì¶”ì¶œ

    Args:
        pdf_bytes: PDF íŒŒì¼ ë°”ì´íŠ¸
        progress_callback: ì§„í–‰ìƒí™© ì½œë°± í•¨ìˆ˜ (page, total, message)
        zoom: ì´ë¯¸ì§€ í™•ëŒ€ ë°°ìœ¨ (ê¸°ë³¸ 2.0)

    Returns:
        {
            "pages": [
                {
                    "page": 1,
                    "image_base64": "...",  # PNG ì´ë¯¸ì§€ base64
                    "width": 1200,
                    "height": 1600,
                    "ocr_results": [
                        {"text": "í…ìŠ¤íŠ¸", "box": [x1, y1, x2, y2], "score": 0.99},
                        ...
                    ]
                },
                ...
            ],
            "total_pages": 6,
            "extraction_method": "comet"
        }
    """
    if not PADDLEOCR_AVAILABLE:
        return {
            "pages": [],
            "error": "PaddleOCRê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "extraction_method": "comet"
        }

    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    total_pages = len(doc)

    result = {
        "pages": [],
        "total_pages": total_pages,
        "extraction_method": "comet",
        "ocr_engine": "PaddleOCR PP-OCRv5"
    }

    for page_num in range(total_pages):
        if progress_callback:
            progress_callback(page_num + 1, total_pages, f"í˜ì´ì§€ {page_num + 1}/{total_pages} OCR ì²˜ë¦¬ ì¤‘...")

        # PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        page = doc[page_num]
        mat = fitz.Matrix(zoom, zoom)
        pix = page.get_pixmap(matrix=mat)
        img_bytes = pix.tobytes("png")

        # ì´ë¯¸ì§€ë¥¼ PIL Imageë¡œ ë³€í™˜
        img = Image.open(io.BytesIO(img_bytes))

        # PaddleOCRë¡œ í…ìŠ¤íŠ¸ + ì¢Œí‘œ ì¶”ì¶œ
        ocr_results = ocr_full_image_paddle(img)

        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        img_base64 = base64.b64encode(img_bytes).decode('utf-8')

        page_data = {
            "page": page_num + 1,
            "image_base64": img_base64,
            "width": img.width,
            "height": img.height,
            "ocr_results": ocr_results
        }

        result["pages"].append(page_data)

    doc.close()
    return result


def generate_comet_overlay_html(page_data: dict, scale: float = 1.0) -> str:
    """
    Comet ë°©ì‹ HTML ì˜¤ë²„ë ˆì´ ìƒì„±
    ì›ë³¸ ì´ë¯¸ì§€ ìœ„ì— íˆ¬ëª…í•œ ì„ íƒ ê°€ëŠ¥ í…ìŠ¤íŠ¸ ë ˆì´ì–´ ë°°ì¹˜

    Args:
        page_data: extract_ocr_with_coordinatesì˜ í˜ì´ì§€ ë°ì´í„°
        scale: í‘œì‹œ ìŠ¤ì¼€ì¼ (ê¸°ë³¸ 1.0)

    Returns:
        HTML ë¬¸ìì—´ (ì´ë¯¸ì§€ + íˆ¬ëª… í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´)
    """
    img_base64 = page_data["image_base64"]
    width = page_data["width"]
    height = page_data["height"]
    ocr_results = page_data["ocr_results"]
    page_num = page_data["page"]

    # ìŠ¤ì¼€ì¼ ì ìš©
    display_width = int(width * scale)
    display_height = int(height * scale)

    # í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ìš”ì†Œ ìƒì„±
    text_elements = []
    for item in ocr_results:
        text = item["text"]
        box = item["box"]  # [x1, y1, x2, y2]

        # ì¢Œí‘œ ìŠ¤ì¼€ì¼ ì ìš©
        x1 = int(box[0] * scale)
        y1 = int(box[1] * scale)
        x2 = int(box[2] * scale)
        y2 = int(box[3] * scale)

        box_width = x2 - x1
        box_height = y2 - y1

        # í°íŠ¸ í¬ê¸° ê³„ì‚° (ë°•ìŠ¤ ë†’ì´ ê¸°ì¤€)
        font_size = max(8, int(box_height * 0.8))

        # HTML íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
        escaped_text = text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;").replace('"', "&quot;")

        text_elements.append(f'''
            <span style="
                position: absolute;
                left: {x1}px;
                top: {y1}px;
                width: {box_width}px;
                height: {box_height}px;
                font-size: {font_size}px;
                line-height: {box_height}px;
                color: transparent;
                background: transparent;
                cursor: text;
                user-select: text;
                -webkit-user-select: text;
                overflow: hidden;
                white-space: nowrap;
            " data-text="{escaped_text}">{escaped_text}</span>
        ''')

    # ì „ì²´ HTML ìƒì„±
    html = f'''
    <div class="comet-page-container" style="
        position: relative;
        width: {display_width}px;
        height: {display_height}px;
        margin: 10px auto;
        border: 1px solid #ddd;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    ">
        <!-- ì›ë³¸ ì´ë¯¸ì§€ (ë°°ê²½) -->
        <img src="data:image/png;base64,{img_base64}"
             style="
                 position: absolute;
                 top: 0;
                 left: 0;
                 width: {display_width}px;
                 height: {display_height}px;
                 pointer-events: none;
             "
             alt="í˜ì´ì§€ {page_num}"
        />

        <!-- OCR í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ (íˆ¬ëª…, ì„ íƒ ê°€ëŠ¥) -->
        <div class="comet-text-layer" style="
            position: absolute;
            top: 0;
            left: 0;
            width: {display_width}px;
            height: {display_height}px;
            z-index: 10;
        ">
            {''.join(text_elements)}
        </div>
    </div>
    '''

    return html


def generate_comet_full_html(comet_data: dict, scale: float = 0.8) -> str:
    """
    ì „ì²´ PDFì— ëŒ€í•œ Comet HTML ìƒì„± (ëª¨ë“  í˜ì´ì§€)

    Args:
        comet_data: extract_ocr_with_coordinatesì˜ ì „ì²´ ê²°ê³¼
        scale: í‘œì‹œ ìŠ¤ì¼€ì¼ (ê¸°ë³¸ 0.8 = 80%)

    Returns:
        ì „ì²´ HTML ë¬¸ìì—´
    """
    pages = comet_data.get("pages", [])
    total_pages = comet_data.get("total_pages", len(pages))

    page_htmls = []
    for page_data in pages:
        page_html = generate_comet_overlay_html(page_data, scale)
        page_num = page_data["page"]

        page_htmls.append(f'''
            <div class="comet-page-wrapper" style="margin-bottom: 20px;">
                <h3 style="text-align: center; color: #333; margin: 10px 0;">
                    í˜ì´ì§€ {page_num} / {total_pages}
                </h3>
                {page_html}
            </div>
        ''')

    # ì „ì²´ HTML ë¬¸ì„œ
    full_html = f'''
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <title>Comet OCR ì˜¤ë²„ë ˆì´</title>
        <style>
            body {{
                font-family: 'Malgun Gothic', sans-serif;
                background-color: #f5f5f5;
                padding: 20px;
                margin: 0;
            }}
            .comet-header {{
                text-align: center;
                padding: 20px;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                border-radius: 8px;
                margin-bottom: 20px;
            }}
            .comet-info {{
                text-align: center;
                color: #666;
                margin-bottom: 20px;
            }}
            .comet-page-wrapper {{
                background: white;
                border-radius: 8px;
                padding: 15px;
                margin-bottom: 20px;
            }}
            /* í…ìŠ¤íŠ¸ ì„ íƒ ì‹œ í•˜ì´ë¼ì´íŠ¸ */
            .comet-text-layer span::selection {{
                background: rgba(0, 120, 215, 0.3);
                color: transparent;
            }}
        </style>
    </head>
    <body>
        <div class="comet-header">
            <h1>ğŸ“„ Comet OCR ì˜¤ë²„ë ˆì´ ë·°ì–´</h1>
            <p>í…ìŠ¤íŠ¸ë¥¼ ë“œë˜ê·¸í•˜ì—¬ ì„ íƒ â†’ Ctrl+Cë¡œ ë³µì‚¬</p>
        </div>

        <div class="comet-info">
            <p>ì´ {total_pages} í˜ì´ì§€ | OCR ì—”ì§„: PaddleOCR PP-OCRv5</p>
        </div>

        <div class="comet-pages">
            {''.join(page_htmls)}
        </div>
    </body>
    </html>
    '''

    return full_html


# ============================================================
# Comet + Table Transformer í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹
# Table Transformerë¡œ í…Œì´ë¸” ì˜ì—­ ê°ì§€ â†’ ê° ì˜ì—­ë³„ Comet OCR
# ============================================================

def detect_table_regions_by_lines(img: Image.Image, min_area_ratio: float = 0.02,
                                    line_threshold: int = 50) -> list:
    """
    êµµì€ ìˆ˜í‰ì„ ì„ ê¸°ì¤€ìœ¼ë¡œ í…Œì´ë¸” ì˜ì—­ ë¶„í• 
    WORKSHEETì²˜ëŸ¼ ë‘êº¼ìš´ ê°€ë¡œì„ ìœ¼ë¡œ êµ¬ë¶„ëœ ì˜ì—­ì„ ì°¾ìŒ

    Args:
        img: PIL Image
        min_area_ratio: ìµœì†Œ ì˜ì—­ ë¹„ìœ¨ (í˜ì´ì§€ ëŒ€ë¹„)
        line_threshold: ì„  ê°ì§€ ì„ê³„ê°’

    Returns:
        ê°ì§€ëœ í…Œì´ë¸” ì˜ì—­ ë¦¬ìŠ¤íŠ¸ [{"box": [x1,y1,x2,y2], "score": 0.9}, ...]
    """
    try:
        import cv2
        import numpy as np
    except ImportError:
        return []

    # PIL â†’ OpenCV
    img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
    gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
    h, w = gray.shape

    # ì´ì§„í™” (ê²€ì€ ì„  ê°ì§€)
    _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)

    # êµµì€ ìˆ˜í‰ì„  ê°ì§€ (í˜ì´ì§€ ë„ˆë¹„ì˜ 30% ì´ìƒ)
    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (w // 3, 3))
    horizontal_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, horizontal_kernel)

    # ìˆ˜í‰ì„ ì˜ Y ì¢Œí‘œ ì°¾ê¸°
    row_sums = np.sum(horizontal_lines, axis=1)
    threshold = w * 128  # ìˆ˜í‰ì„  ê°ì§€ ì„ê³„ê°’

    line_y_positions = []
    in_line = False
    line_start = 0

    for y in range(h):
        if row_sums[y] > threshold:
            if not in_line:
                line_start = y
                in_line = True
        else:
            if in_line:
                line_center = (line_start + y) // 2
                line_y_positions.append(line_center)
                in_line = False

    # í˜ì´ì§€ ê²½ê³„ ì¶”ê°€
    if not line_y_positions or line_y_positions[0] > 50:
        line_y_positions.insert(0, 0)
    if not line_y_positions or line_y_positions[-1] < h - 50:
        line_y_positions.append(h)

    # ì¸ì ‘í•œ ì„  ë³‘í•© (30í”½ì…€ ì´ë‚´)
    merged_lines = []
    for y in line_y_positions:
        if not merged_lines or y - merged_lines[-1] > 30:
            merged_lines.append(y)
    line_y_positions = merged_lines

    # ìˆ˜í‰ì„  ì‚¬ì´ ì˜ì—­ì„ í…Œì´ë¸”ë¡œ ë¶„í• 
    regions = []
    min_height = h * 0.05  # ìµœì†Œ ë†’ì´ 5%

    for i in range(len(line_y_positions) - 1):
        y1 = line_y_positions[i]
        y2 = line_y_positions[i + 1]

        # ìµœì†Œ ë†’ì´ ì²´í¬
        if y2 - y1 < min_height:
            continue

        # ì¢Œìš° ì—¬ë°± ê°ì§€ (ë‚´ìš©ì´ ìˆëŠ” ì˜ì—­ ì°¾ê¸°)
        region_binary = binary[y1:y2, :]
        col_sums = np.sum(region_binary, axis=0)
        content_cols = np.where(col_sums > 0)[0]

        if len(content_cols) == 0:
            continue

        x1 = max(0, content_cols[0] - 10)
        x2 = min(w, content_cols[-1] + 10)

        # ìµœì†Œ ë„ˆë¹„ ì²´í¬
        if x2 - x1 < w * 0.1:
            continue

        regions.append({
            "box": [int(x1), int(y1), int(x2), int(y2)],
            "score": 0.9,
            "label": "table_by_hlines"
        })

    return regions


def detect_grid_lines(img: Image.Image, min_line_length_ratio: float = 0.1,
                       min_h_ratio: float = None, min_v_ratio: float = None) -> dict:
    """
    í…Œì´ë¸” ì´ë¯¸ì§€ì—ì„œ ìˆ˜í‰ì„ ê³¼ ìˆ˜ì§ì„  ì¶”ì¶œ
    ìˆœìˆ˜ Morphological ì—°ì‚° ë°©ì‹ - ë‚´ë¶€ ê²©ìì„ ê¹Œì§€ ê°ì§€

    Args:
        img: PIL Image (í…Œì´ë¸” ì˜ì—­ ë˜ëŠ” ì „ì²´ í˜ì´ì§€)
        min_line_length_ratio: ìµœì†Œ ì„  ê¸¸ì´ ë¹„ìœ¨ (ì´ë¯¸ì§€ í¬ê¸° ëŒ€ë¹„, ê¸°ë³¸ê°’)
        min_h_ratio: ìˆ˜í‰ì„  ìµœì†Œ ê¸¸ì´ ë¹„ìœ¨ (Noneì´ë©´ min_line_length_ratio ì‚¬ìš©)
        min_v_ratio: ìˆ˜ì§ì„  ìµœì†Œ ê¸¸ì´ ë¹„ìœ¨ (Noneì´ë©´ min_line_length_ratio ì‚¬ìš©)

    Returns:
        {
            "horizontal_lines": [(y1, x_start, x_end), ...],  # Y ì¢Œí‘œë³„ ìˆ˜í‰ì„ 
            "vertical_lines": [(x1, y_start, y_end), ...],    # X ì¢Œí‘œë³„ ìˆ˜ì§ì„ 
            "row_boundaries": [y1, y2, y3, ...],  # í–‰ ê²½ê³„ Y ì¢Œí‘œ
            "col_boundaries": [x1, x2, x3, ...],  # ì—´ ê²½ê³„ X ì¢Œí‘œ
            "cells": [(row_idx, col_idx, x1, y1, x2, y2), ...],  # ì…€ ì˜ì—­
        }
    """
    try:
        import cv2
        import numpy as np
    except ImportError:
        return {"horizontal_lines": [], "vertical_lines": [],
                "row_boundaries": [], "col_boundaries": [], "cells": []}

    # PIL â†’ OpenCV
    img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
    gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
    h, w = gray.shape

    # === ì „ì²˜ë¦¬: ì„  ê°ì§€ë¥¼ ìœ„í•œ ì´ì§„í™” ===
    # ê³ ì • ì„ê³„ê°’ ì´ì§„í™” (ì„ ì€ ì¼ë°˜ì ìœ¼ë¡œ ì–´ë‘ì›€)
    _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)

    # ìµœì†Œ ì„  ê¸¸ì´ ê³„ì‚° - ë‚´ë¶€ ê²©ìì„  ê°ì§€ë¥¼ ìœ„í•´ ì‘ì€ ê°’ ì‚¬ìš©
    h_ratio = min_h_ratio if min_h_ratio is not None else min_line_length_ratio
    v_ratio = min_v_ratio if min_v_ratio is not None else min_line_length_ratio

    # ìˆ˜í‰ì„  ìµœì†Œ ê¸¸ì´: í…Œì´ë¸” ë„ˆë¹„ì˜ 5% ì´ìƒ (ë‚´ë¶€ ê²©ìì„ ë„ ê°ì§€)
    min_h_length = max(int(w * max(h_ratio, 0.05)), 30)
    # ìˆ˜ì§ì„  ìµœì†Œ ê¸¸ì´: í…Œì´ë¸” ë†’ì´ì˜ 5% ì´ìƒ
    min_v_length = max(int(h * max(v_ratio, 0.05)), 20)

    # === ìˆ˜í‰ì„  ê°ì§€ ===
    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (min_h_length, 1))
    horizontal_lines_img = cv2.morphologyEx(binary, cv2.MORPH_OPEN, horizontal_kernel)

    # ìˆ˜í‰ì„  ì—°ê²° ê°•í™” (ëŠì–´ì§„ ì„  ì—°ê²°)
    connect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 1))
    horizontal_lines_img = cv2.dilate(horizontal_lines_img, connect_kernel, iterations=1)
    horizontal_lines_img = cv2.erode(horizontal_lines_img, connect_kernel, iterations=1)

    # === ìˆ˜ì§ì„  ê°ì§€ ===
    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, min_v_length))
    vertical_lines_img = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel)

    # ìˆ˜ì§ì„  ì—°ê²° ê°•í™”
    connect_kernel_v = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 10))
    vertical_lines_img = cv2.dilate(vertical_lines_img, connect_kernel_v, iterations=1)
    vertical_lines_img = cv2.erode(vertical_lines_img, connect_kernel_v, iterations=1)

    # === ìˆ˜í‰ì„  Y ì¢Œí‘œ ì¶”ì¶œ ===
    horizontal_lines = []
    row_sums = np.sum(horizontal_lines_img, axis=1)
    # ì„ê³„ê°’: ì»¤ë„ ê¸¸ì´ì˜ ì ˆë°˜ ì •ë„ë§Œ ì±„ì›Œì ¸ë„ ê°ì§€
    line_threshold = min_h_length * 128

    in_line = False
    line_start_y = 0

    for y in range(h):
        if row_sums[y] > line_threshold:
            if not in_line:
                line_start_y = y
                in_line = True
        else:
            if in_line:
                line_center_y = (line_start_y + y) // 2
                # ìˆ˜í‰ì„ ì˜ X ë²”ìœ„ ì°¾ê¸°
                row_pixels = horizontal_lines_img[line_center_y]
                x_indices = np.where(row_pixels > 0)[0]
                if len(x_indices) > 0:
                    x_start = x_indices[0]
                    x_end = x_indices[-1]
                    # ìµœì†Œ ê¸¸ì´ ì´ìƒì´ë©´ ìœ íš¨
                    if (x_end - x_start) >= min_h_length:
                        horizontal_lines.append((line_center_y, int(x_start), int(x_end)))
                in_line = False

    # ë§ˆì§€ë§‰ ì„  ì²˜ë¦¬
    if in_line:
        line_center_y = (line_start_y + h) // 2
        if line_center_y < h:
            row_pixels = horizontal_lines_img[min(line_center_y, h-1)]
            x_indices = np.where(row_pixels > 0)[0]
            if len(x_indices) > 0:
                x_start = x_indices[0]
                x_end = x_indices[-1]
                if (x_end - x_start) >= min_h_length:
                    horizontal_lines.append((line_center_y, int(x_start), int(x_end)))

    # === ìˆ˜ì§ì„  X ì¢Œí‘œ ì¶”ì¶œ ===
    vertical_lines = []
    col_sums = np.sum(vertical_lines_img, axis=0)
    # ì„ê³„ê°’: ì»¤ë„ ê¸¸ì´ì˜ ì ˆë°˜ ì •ë„ë§Œ ì±„ì›Œì ¸ë„ ê°ì§€
    line_threshold_v = min_v_length * 128

    in_line = False
    line_start_x = 0

    for x in range(w):
        if col_sums[x] > line_threshold_v:
            if not in_line:
                line_start_x = x
                in_line = True
        else:
            if in_line:
                line_center_x = (line_start_x + x) // 2
                # ìˆ˜ì§ì„ ì˜ Y ë²”ìœ„ ì°¾ê¸°
                col_pixels = vertical_lines_img[:, line_center_x]
                y_indices = np.where(col_pixels > 0)[0]
                if len(y_indices) > 0:
                    y_start = y_indices[0]
                    y_end = y_indices[-1]
                    # ìµœì†Œ ê¸¸ì´ ì´ìƒì´ë©´ ìœ íš¨
                    if (y_end - y_start) >= min_v_length:
                        vertical_lines.append((line_center_x, int(y_start), int(y_end)))
                in_line = False

    # ë§ˆì§€ë§‰ ì„  ì²˜ë¦¬
    if in_line:
        line_center_x = (line_start_x + w) // 2
        if line_center_x < w:
            col_pixels = vertical_lines_img[:, min(line_center_x, w-1)]
            y_indices = np.where(col_pixels > 0)[0]
            if len(y_indices) > 0:
                y_start = y_indices[0]
                y_end = y_indices[-1]
                if (y_end - y_start) >= min_v_length:
                    vertical_lines.append((line_center_x, int(y_start), int(y_end)))

    # === ì¸ì ‘í•œ ì„  ë³‘í•© ===
    def merge_adjacent_values(values, min_gap=15):
        """ì¸ì ‘í•œ ê°’ë“¤ì„ ë³‘í•©"""
        if not values:
            return []
        values = sorted(set(values))
        merged = [values[0]]
        for v in values[1:]:
            if v - merged[-1] > min_gap:
                merged.append(v)
        return merged

    # í–‰ ê²½ê³„ (ìˆ˜í‰ì„  Y ì¢Œí‘œ)
    row_y_values = [line[0] for line in horizontal_lines]
    row_boundaries = merge_adjacent_values(row_y_values, min_gap=15)

    # ì—´ ê²½ê³„ (ìˆ˜ì§ì„  X ì¢Œí‘œ)
    col_x_values = [line[0] for line in vertical_lines]
    col_boundaries = merge_adjacent_values(col_x_values, min_gap=15)

    # ê²½ê³„ ì¶”ê°€ (ì‹œì‘/ë)
    if row_boundaries and row_boundaries[0] > 20:
        row_boundaries.insert(0, 0)
    if row_boundaries and row_boundaries[-1] < h - 20:
        row_boundaries.append(h)

    if col_boundaries and col_boundaries[0] > 20:
        col_boundaries.insert(0, 0)
    if col_boundaries and col_boundaries[-1] < w - 20:
        col_boundaries.append(w)

    # === ì…€ ì˜ì—­ ê³„ì‚° ===
    cells = []
    for row_idx in range(len(row_boundaries) - 1):
        for col_idx in range(len(col_boundaries) - 1):
            y1 = row_boundaries[row_idx]
            y2 = row_boundaries[row_idx + 1]
            x1 = col_boundaries[col_idx]
            x2 = col_boundaries[col_idx + 1]

            if (x2 - x1) > 10 and (y2 - y1) > 10:
                cells.append((row_idx, col_idx, int(x1), int(y1), int(x2), int(y2)))

    return {
        "horizontal_lines": horizontal_lines,
        "vertical_lines": vertical_lines,
        "row_boundaries": row_boundaries,
        "col_boundaries": col_boundaries,
        "cells": cells,
        "row_count": len(row_boundaries) - 1 if len(row_boundaries) > 1 else 0,
        "col_count": len(col_boundaries) - 1 if len(col_boundaries) > 1 else 0
    }


def map_ocr_to_grid_cells(ocr_results: list, grid_info: dict, use_ocr_columns: bool = True) -> list:
    """
    OCR ê²°ê³¼ë¥¼ ê²©ì ì…€ì— ì •í™•í•˜ê²Œ ë§¤í•‘
    í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹: ìˆ˜í‰ì„ (í–‰)ì€ ê²©ìì„ ì—ì„œ, ìˆ˜ì§ì„ (ì—´)ì€ OCR Xì¢Œí‘œì—ì„œ ì¶”ì¶œ

    Args:
        ocr_results: OCR ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ [{"text": "...", "box": [x1,y1,x2,y2]}, ...]
        grid_info: detect_grid_lines()ì˜ ë°˜í™˜ê°’
        use_ocr_columns: Trueë©´ OCR Xì¢Œí‘œë¡œ ì—´ ê²½ê³„ ì¶”ì • (ì…€ ë³‘í•© í…Œì´ë¸”ìš©)

    Returns:
        2D í…Œì´ë¸” ë°ì´í„° [[row1_col1, row1_col2, ...], ...]
    """
    row_boundaries = grid_info.get("row_boundaries", [])
    col_boundaries = grid_info.get("col_boundaries", [])

    # í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹: ê²©ìì„  ì—´ì´ ë¶€ì¡±í•˜ë©´ OCR Xì¢Œí‘œë¡œ ì—´ ê²½ê³„ ì¶”ì •
    if use_ocr_columns and len(col_boundaries) < 3 and ocr_results:
        col_boundaries = estimate_column_boundaries_from_ocr(ocr_results)
        if col_boundaries:
            col_boundaries = [0] + col_boundaries + [max(item["box"][2] for item in ocr_results) + 20]

    if len(row_boundaries) < 2 or len(col_boundaries) < 2:
        # ê²©ì ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
        return None

    num_rows = len(row_boundaries) - 1
    num_cols = len(col_boundaries) - 1

    # 2D ë°°ì—´ ì´ˆê¸°í™”
    table_data = [["" for _ in range(num_cols)] for _ in range(num_rows)]

    for item in ocr_results:
        text = item["text"].strip()
        if not text:
            continue

        box = item["box"]
        # OCR ë°•ìŠ¤ì˜ ì¤‘ì‹¬ì  ê³„ì‚°
        center_x = (box[0] + box[2]) / 2
        center_y = (box[1] + box[3]) / 2

        # ì¤‘ì‹¬ì ì´ ì†í•˜ëŠ” ì…€ ì°¾ê¸°
        row_idx = -1
        col_idx = -1

        for i in range(num_rows):
            if row_boundaries[i] <= center_y < row_boundaries[i + 1]:
                row_idx = i
                break

        for j in range(num_cols):
            if col_boundaries[j] <= center_x < col_boundaries[j + 1]:
                col_idx = j
                break

        # ìœ íš¨í•œ ì…€ì— í…ìŠ¤íŠ¸ í• ë‹¹
        if row_idx >= 0 and col_idx >= 0:
            if table_data[row_idx][col_idx]:
                table_data[row_idx][col_idx] += " " + text
            else:
                table_data[row_idx][col_idx] = text

    # ë¹ˆ í–‰ ì œê±° (ëª¨ë“  ì…€ì´ ë¹ˆ í–‰)
    table_data = [row for row in table_data if any(cell.strip() for cell in row)]

    return table_data


def detect_table_regions_by_thick_lines(img: Image.Image) -> list:
    """
    ë‘êº¼ìš´ ê²€ì€ ë°•ìŠ¤ í…Œë‘ë¦¬ë¡œ êµ¬ë¶„ëœ ì˜ì—­ ê°ì§€
    ë‚´ë¶€ ì»¨íˆ¬ì–´(RETR_CCOMP)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°•ìŠ¤ ì•ˆì˜ ì˜ì—­ ì°¾ê¸°

    Args:
        img: PIL Image

    Returns:
        ê°ì§€ëœ í…Œì´ë¸” ì˜ì—­ ë¦¬ìŠ¤íŠ¸
    """
    try:
        import cv2
        import numpy as np
    except ImportError:
        return []

    # PIL â†’ OpenCV
    img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
    gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
    h, w = gray.shape

    # ì´ì§„í™”
    _, binary = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV)

    # ë‘êº¼ìš´ ì„ ë§Œ ë‚¨ê¸°ê¸° ìœ„í•´ erosion í›„ dilation
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    thick_lines = cv2.erode(binary, kernel, iterations=1)
    thick_lines = cv2.dilate(thick_lines, kernel, iterations=2)

    # ë‚´ë¶€ ì»¨íˆ¬ì–´ ì°¾ê¸° (RETR_CCOMP: 2ë ˆë²¨ ê³„ì¸µ)
    contours, hierarchy = cv2.findContours(thick_lines, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)

    if hierarchy is None:
        return []

    page_area = w * h
    min_area = page_area * 0.02  # ìµœì†Œ 2%
    max_area = page_area * 0.8   # ìµœëŒ€ 80%

    regions = []
    for i, contour in enumerate(contours):
        # ë‚´ë¶€ ì»¨íˆ¬ì–´ë§Œ ì„ íƒ (parentê°€ ìˆëŠ” ì»¨íˆ¬ì–´)
        if hierarchy[0][i][3] == -1:  # ì™¸ë¶€ ì»¨íˆ¬ì–´
            continue

        x, y, cw, ch = cv2.boundingRect(contour)
        area = cw * ch

        if area < min_area or area > max_area:
            continue

        if cw < 100 or ch < 50:
            continue

        regions.append({
            "box": [x, y, x + cw, y + ch],
            "score": 0.85,
            "label": "table_by_thick_border",
            "area": area
        })

    # Y ì¢Œí‘œë¡œ ì •ë ¬
    regions.sort(key=lambda r: (r["box"][1], r["box"][0]))

    return regions


def detect_table_regions_combined(img: Image.Image, detection_threshold: float = 0.5) -> list:
    """
    Table Transformer + ì„  ê¸°ë°˜ ê°ì§€ ì¡°í•©
    ì—¬ëŸ¬ ë°©ì‹ì„ ì‹œë„í•˜ì—¬ ê°€ì¥ ë§ì€ í…Œì´ë¸”ì„ ì°¾ëŠ” ë°©ì‹ ì„ íƒ

    Args:
        img: PIL Image
        detection_threshold: Table Transformer ì„ê³„ê°’

    Returns:
        ê°ì§€ëœ í…Œì´ë¸” ì˜ì—­ ë¦¬ìŠ¤íŠ¸
    """
    results = []

    # 1. Table Transformer ì‹œë„
    if TABLE_TRANSFORMER_AVAILABLE:
        tt_tables = detect_tables(img, threshold=detection_threshold)
        results.append(("Table Transformer", tt_tables))

    # 2. ìˆ˜í‰ì„  ê¸°ë°˜ ê°ì§€ ì‹œë„
    hline_regions = detect_table_regions_by_lines(img)
    results.append(("Horizontal Lines", hline_regions))

    # 3. ë‘êº¼ìš´ ë°•ìŠ¤ í…Œë‘ë¦¬ ê¸°ë°˜ ê°ì§€ ì‹œë„
    thick_regions = detect_table_regions_by_thick_lines(img)
    results.append(("Thick Border", thick_regions))

    # ê°€ì¥ ë§ì€ ì˜ì—­ì„ ì°¾ì€ ë°©ì‹ ì„ íƒ (ìµœì†Œ 2ê°œ ì´ìƒ)
    best_method = None
    best_regions = []

    for method, regions in results:
        if len(regions) > len(best_regions):
            best_method = method
            best_regions = regions

    # ì–´ë–¤ ë°©ì‹ë„ 2ê°œ ì´ìƒ ì°¾ì§€ ëª»í–ˆìœ¼ë©´ Table Transformer ê²°ê³¼ ì‚¬ìš©
    if len(best_regions) < 2 and TABLE_TRANSFORMER_AVAILABLE:
        tt_tables = detect_tables(img, threshold=detection_threshold)
        if tt_tables:
            return tt_tables

    return best_regions


def extract_comet_with_table_detection(pdf_bytes: bytes, progress_callback=None,
                                        detection_threshold: float = 0.5) -> dict:
    """
    Comet + Table Transformer í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹
    1. Table Transformerë¡œ í…Œì´ë¸” ì˜ì—­(bbox) ê°ì§€
    2. ê° í…Œì´ë¸” ì˜ì—­ì— ëŒ€í•´ Comet OCR ì ìš©
    3. í…Œì´ë¸”ë³„ë¡œ êµ¬ì¡°í™”ëœ ë°ì´í„° ë°˜í™˜

    Args:
        pdf_bytes: PDF íŒŒì¼ ë°”ì´íŠ¸
        progress_callback: ì§„í–‰ìƒí™© ì½œë°± í•¨ìˆ˜
        detection_threshold: í…Œì´ë¸” ê°ì§€ ì„ê³„ê°’ (ê¸°ë³¸ 0.5)

    Returns:
        {
            "tables": [
                {
                    "page": 1,
                    "table_index": 1,
                    "table_name": "COLOR/SIZE QTY",  # ê°ì§€ëœ í…Œì´ë¸” ì œëª©
                    "bbox": [x1, y1, x2, y2],
                    "confidence": 0.95,
                    "data": [[...], [...], ...],
                    "row_count": 10,
                    "col_count": 5,
                    "ocr_results": [...]  # ì›ë³¸ OCR ë°ì´í„°
                },
                ...
            ],
            "pages": [...],
            "comet_html": [...],
            "total_tables": 5,
            "extraction_method": "comet_hybrid"
        }
    """
    if not PADDLEOCR_AVAILABLE:
        return {
            "tables": [],
            "error": "PaddleOCRê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "extraction_method": "comet_hybrid"
        }

    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    total_pages = len(doc)

    result = {
        "tables": [],
        "pages": [],
        "comet_html": [],
        "total_pages": total_pages,
        "total_tables": 0,
        "is_ai_extracted": True,
        "extraction_method": "comet_hybrid",
        "ocr_engine": "PaddleOCR PP-OCRv5",
        "table_detector": "Table Transformer" if TABLE_TRANSFORMER_AVAILABLE else "Y-coordinate clustering"
    }

    table_index_global = 0

    for page_num in range(total_pages):
        if progress_callback:
            progress_callback(page_num + 1, total_pages, f"í˜ì´ì§€ {page_num + 1}/{total_pages} ì²˜ë¦¬ ì¤‘...")

        # PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        page = doc[page_num]
        zoom = 2.0
        mat = fitz.Matrix(zoom, zoom)
        pix = page.get_pixmap(matrix=mat)
        img_bytes = pix.tobytes("png")
        img = Image.open(io.BytesIO(img_bytes))

        # ì „ì²´ í˜ì´ì§€ OCR ìˆ˜í–‰
        if progress_callback:
            progress_callback(page_num + 1, total_pages, f"í˜ì´ì§€ {page_num + 1} OCR ì²˜ë¦¬ ì¤‘...")

        page_ocr_results = ocr_full_image_paddle(img)

        # ì´ë¯¸ì§€ base64 ì¸ì½”ë”©
        img_base64 = base64.b64encode(img_bytes).decode('utf-8')

        # í˜ì´ì§€ ë°ì´í„° ì €ì¥
        page_data = {
            "page": page_num + 1,
            "image_base64": img_base64,
            "width": img.width,
            "height": img.height,
            "ocr_results": page_ocr_results
        }
        result["pages"].append(page_data)

        # Comet HTML ìƒì„±
        page_html = generate_comet_overlay_html(page_data, scale=0.8)
        result["comet_html"].append({
            "page": page_num + 1,
            "html": page_html
        })

        # í…Œì´ë¸” ì˜ì—­ ê°ì§€ (Table Transformer + ì„  ê¸°ë°˜ ê°ì§€ ì¡°í•©)
        if progress_callback:
            progress_callback(page_num + 1, total_pages, f"í˜ì´ì§€ {page_num + 1} í…Œì´ë¸” ì˜ì—­ ê°ì§€ ì¤‘...")

        # Table Transformer + ì„  ê¸°ë°˜ ê°ì§€ ì¡°í•© ì‚¬ìš©
        detected_tables = detect_table_regions_combined(img, detection_threshold)

        if not detected_tables:
            # ì•„ë¬´ê²ƒë„ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ Y ì¢Œí‘œ í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ í…Œì´ë¸” ì˜ì—­ ì¶”ì •
            detected_tables = estimate_table_regions_from_ocr(page_ocr_results, img.width, img.height)

        # ê° í…Œì´ë¸” ì˜ì—­ë³„ë¡œ ì²˜ë¦¬
        for table_idx, table_info in enumerate(detected_tables):
            table_index_global += 1
            table_box = table_info["box"]  # [x1, y1, x2, y2]
            table_score = table_info.get("score", 0.99)

            # í…Œì´ë¸” ì˜ì—­ ë‚´ì˜ OCR ê²°ê³¼ë§Œ í•„í„°ë§
            table_ocr = filter_ocr_by_bbox(page_ocr_results, table_box)

            if not table_ocr:
                continue

            # í…Œì´ë¸” ì œëª© ì¶”ì • (í…Œì´ë¸” ì˜ì—­ ìœ„ìª½ í…ìŠ¤íŠ¸)
            table_name = estimate_table_name(page_ocr_results, table_box)

            # â˜… ê²©ìì„  ê¸°ë°˜ ì…€ ê°ì§€ (ìƒˆë¡œìš´ ë°©ì‹)
            if progress_callback:
                progress_callback(page_num + 1, total_pages,
                    f"í˜ì´ì§€ {page_num + 1} - í…Œì´ë¸” {table_idx + 1} ê²©ìì„  ë¶„ì„ ì¤‘...")

            # í…Œì´ë¸” ì˜ì—­ í¬ë¡­
            x1, y1, x2, y2 = table_box
            table_img = img.crop((x1, y1, x2, y2))

            # ê²©ìì„  ê°ì§€ (ìˆ˜í‰ì„  + ìˆ˜ì§ì„ ) - ëª¨ë“  ì„  ê°ì§€
            # í…Œì´ë¸” ì˜ì—­ ì•ˆì˜ ëª¨ë“  ì„ ì„ ê°ì§€ (ì¸ìœ„ì  í•„í„°ë§ ì—†ìŒ)
            grid_info = detect_grid_lines(table_img, min_h_ratio=0.02, min_v_ratio=0.02)

            # ê²©ìì„ ì´ ì¶©ë¶„íˆ ê°ì§€ë˜ì—ˆìœ¼ë©´ ê²©ì ê¸°ë°˜ ë§¤í•‘ ì‚¬ìš©
            table_data = None
            extraction_mode = "grid_lines"  # ì¶”ì¶œ ë°©ì‹ ê¸°ë¡

            if grid_info["row_count"] >= 2 and grid_info["col_count"] >= 2:
                # ê²©ìì„  ê¸°ë°˜ìœ¼ë¡œ OCR ê²°ê³¼ ë§¤í•‘
                table_data = map_ocr_to_grid_cells(table_ocr, grid_info)

            # ê²©ìì„  ê°ì§€ ì‹¤íŒ¨ ë˜ëŠ” ë§¤í•‘ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
            if table_data is None:
                table_data = ocr_to_table_structure(table_ocr, table_box)
                extraction_mode = "header_based"

            if table_data:
                result["tables"].append({
                    "page": page_num + 1,
                    "table_index": table_idx + 1,
                    "table_index_global": table_index_global,
                    "table_name": table_name,
                    "bbox": table_box,
                    "confidence": float(table_score),
                    "data": table_data,
                    "row_count": len(table_data),
                    "col_count": max(len(row) for row in table_data) if table_data else 0,
                    "ocr_results": table_ocr,
                    "extraction_method": "comet_hybrid",
                    "grid_detection": extraction_mode,
                    "grid_info": {
                        "rows_detected": grid_info.get("row_count", 0),
                        "cols_detected": grid_info.get("col_count", 0),
                        "horizontal_lines": len(grid_info.get("horizontal_lines", [])),
                        "vertical_lines": len(grid_info.get("vertical_lines", []))
                    }
                })

    doc.close()
    result["total_tables"] = len(result["tables"])

    return result


def filter_ocr_by_bbox(ocr_results: list, bbox: list, margin: int = 5) -> list:
    """
    ë°”ìš´ë”© ë°•ìŠ¤ ë‚´ì˜ OCR ê²°ê³¼ë§Œ í•„í„°ë§

    Args:
        ocr_results: OCR ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        bbox: [x1, y1, x2, y2] í…Œì´ë¸” ì˜ì—­
        margin: ë§ˆì§„ (í”½ì…€)

    Returns:
        í•„í„°ë§ëœ OCR ê²°ê³¼
    """
    x1, y1, x2, y2 = bbox
    filtered = []

    for item in ocr_results:
        box = item["box"]
        # OCR ë°•ìŠ¤ì˜ ì¤‘ì‹¬ì ì´ í…Œì´ë¸” ì˜ì—­ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
        center_x = (box[0] + box[2]) / 2
        center_y = (box[1] + box[3]) / 2

        if (x1 - margin <= center_x <= x2 + margin and
            y1 - margin <= center_y <= y2 + margin):
            # ìƒëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
            filtered.append({
                "text": item["text"],
                "box": [
                    item["box"][0] - x1,  # ìƒëŒ€ x1
                    item["box"][1] - y1,  # ìƒëŒ€ y1
                    item["box"][2] - x1,  # ìƒëŒ€ x2
                    item["box"][3] - y1   # ìƒëŒ€ y2
                ],
                "box_absolute": item["box"],  # ì ˆëŒ€ ì¢Œí‘œ ìœ ì§€
                "score": item.get("score", 1.0)
            })

    return filtered


def estimate_table_name(ocr_results: list, table_bbox: list, search_height: int = 60) -> str:
    """
    í…Œì´ë¸” ì˜ì—­ ìœ„ìª½ì—ì„œ í…Œì´ë¸” ì œëª© ì¶”ì •

    Args:
        ocr_results: í˜ì´ì§€ ì „ì²´ OCR ê²°ê³¼
        table_bbox: í…Œì´ë¸” ë°”ìš´ë”© ë°•ìŠ¤ [x1, y1, x2, y2]
        search_height: í…Œì´ë¸” ìœ„ìª½ ê²€ìƒ‰ ë†’ì´ (í”½ì…€)

    Returns:
        ì¶”ì •ëœ í…Œì´ë¸” ì œëª©
    """
    x1, y1, x2, y2 = table_bbox

    # í…Œì´ë¸” ìœ„ìª½ ì˜ì—­ì—ì„œ í…ìŠ¤íŠ¸ ì°¾ê¸°
    candidates = []
    for item in ocr_results:
        box = item["box"]
        text_center_y = (box[1] + box[3]) / 2
        text_center_x = (box[0] + box[2]) / 2

        # í…Œì´ë¸” ìœ„ìª½ search_height í”½ì…€ ë‚´ì— ìˆê³ , x ë²”ìœ„ê°€ ê²¹ì¹˜ëŠ” í…ìŠ¤íŠ¸
        if (y1 - search_height <= text_center_y < y1 and
            x1 <= text_center_x <= x2):
            candidates.append({
                "text": item["text"],
                "y": box[1]
            })

    if candidates:
        # ê°€ì¥ ì•„ë˜ìª½(í…Œì´ë¸”ì— ê°€ê¹Œìš´) í…ìŠ¤íŠ¸ ì„ íƒ
        candidates.sort(key=lambda x: x["y"], reverse=True)
        return candidates[0]["text"]

    return ""


def estimate_table_regions_from_ocr(ocr_results: list, page_width: int, page_height: int,
                                     gap_threshold: int = 50) -> list:
    """
    OCR ê²°ê³¼ì˜ Y ì¢Œí‘œ ë¶„í¬ë¥¼ ë¶„ì„í•˜ì—¬ í…Œì´ë¸” ì˜ì—­ ì¶”ì •
    í° Y ê°­ì´ ìˆìœ¼ë©´ í…Œì´ë¸” êµ¬ë¶„ìœ¼ë¡œ íŒë‹¨

    Args:
        ocr_results: OCR ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        page_width: í˜ì´ì§€ ë„ˆë¹„
        page_height: í˜ì´ì§€ ë†’ì´
        gap_threshold: í…Œì´ë¸” êµ¬ë¶„ ê°­ ì„ê³„ê°’ (í”½ì…€)

    Returns:
        ì¶”ì •ëœ í…Œì´ë¸” ì˜ì—­ ë¦¬ìŠ¤íŠ¸
    """
    if not ocr_results:
        return []

    # Y ì¢Œí‘œë¡œ ì •ë ¬
    sorted_items = sorted(ocr_results, key=lambda x: x["box"][1])

    # í…Œì´ë¸” ì˜ì—­ ê·¸ë£¹í™”
    groups = []
    current_group = [sorted_items[0]]

    for i in range(1, len(sorted_items)):
        prev_y2 = current_group[-1]["box"][3]  # ì´ì „ í•­ëª©ì˜ y2
        curr_y1 = sorted_items[i]["box"][1]     # í˜„ì¬ í•­ëª©ì˜ y1

        if curr_y1 - prev_y2 > gap_threshold:
            # í° ê°­ ë°œê²¬ - ìƒˆ ê·¸ë£¹ ì‹œì‘
            groups.append(current_group)
            current_group = [sorted_items[i]]
        else:
            current_group.append(sorted_items[i])

    if current_group:
        groups.append(current_group)

    # ê° ê·¸ë£¹ì„ í…Œì´ë¸” ì˜ì—­ìœ¼ë¡œ ë³€í™˜
    tables = []
    for group in groups:
        if len(group) < 3:  # ìµœì†Œ 3ê°œ í…ìŠ¤íŠ¸ê°€ ìˆì–´ì•¼ í…Œì´ë¸”ë¡œ ê°„ì£¼
            continue

        # ê·¸ë£¹ì˜ ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
        x1 = min(item["box"][0] for item in group)
        y1 = min(item["box"][1] for item in group)
        x2 = max(item["box"][2] for item in group)
        y2 = max(item["box"][3] for item in group)

        # ë§ˆì§„ ì¶”ê°€
        margin = 10
        x1 = max(0, x1 - margin)
        y1 = max(0, y1 - margin)
        x2 = min(page_width, x2 + margin)
        y2 = min(page_height, y2 + margin)

        tables.append({
            "score": 0.9,
            "label": "table_estimated",
            "box": [x1, y1, x2, y2]
        })

    return tables


def estimate_column_boundaries_from_ocr(ocr_results: list, gap_threshold: int = 25) -> list:
    """
    OCR ê²°ê³¼ì˜ Xì¢Œí‘œë¥¼ ë¶„ì„í•˜ì—¬ ì—´ ê²½ê³„ ì¶”ì •
    ì…€ ë³‘í•©ì´ ìˆëŠ” í…Œì´ë¸”ì—ì„œ ìœ ìš©

    Args:
        ocr_results: OCR ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        gap_threshold: ì—´ êµ¬ë¶„ì„ ìœ„í•œ ìµœì†Œ X ê°­ (í”½ì…€)

    Returns:
        ì—´ ê²½ê³„ Xì¢Œí‘œ ë¦¬ìŠ¤íŠ¸ [x1, x2, x3, ...]
    """
    if not ocr_results:
        return []

    # ëª¨ë“  OCR í•­ëª©ì˜ X ì‹œì‘ ì¢Œí‘œ ìˆ˜ì§‘
    x_starts = []
    for item in ocr_results:
        x_starts.append(item["box"][0])

    if not x_starts:
        return []

    # X ì¢Œí‘œ ì •ë ¬
    x_starts = sorted(x_starts)

    # í´ëŸ¬ìŠ¤í„°ë§: ì¸ì ‘í•œ X ì¢Œí‘œ ê·¸ë£¹í™”
    clusters = []
    current_cluster = [x_starts[0]]

    for i in range(1, len(x_starts)):
        if x_starts[i] - x_starts[i-1] <= gap_threshold:
            current_cluster.append(x_starts[i])
        else:
            # ìƒˆ í´ëŸ¬ìŠ¤í„° ì‹œì‘
            clusters.append(current_cluster)
            current_cluster = [x_starts[i]]

    if current_cluster:
        clusters.append(current_cluster)

    # ê° í´ëŸ¬ìŠ¤í„°ì˜ ëŒ€í‘œê°’ (ìµœì†Œê°’) ë°˜í™˜
    boundaries = [min(cluster) for cluster in clusters]

    return boundaries


def ocr_to_table_structure(ocr_results: list, table_bbox: list,
                            y_tolerance: int = 15, x_gap_threshold: int = 30) -> list:
    """
    OCR ê²°ê³¼ë¥¼ í…Œì´ë¸” í–‰/ì—´ êµ¬ì¡°ë¡œ ë³€í™˜
    ê°œì„ : í—¤ë” í–‰(ì²« ë²ˆì§¸ í–‰)ì˜ ì—´ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì—´ ê²½ê³„ ì„¤ì •

    Args:
        ocr_results: í•„í„°ë§ëœ OCR ê²°ê³¼ (ìƒëŒ€ ì¢Œí‘œ)
        table_bbox: í…Œì´ë¸” ë°”ìš´ë”© ë°•ìŠ¤
        y_tolerance: ê°™ì€ í–‰ìœ¼ë¡œ ê°„ì£¼í•  Y ì˜¤ì°¨
        x_gap_threshold: ì—´ êµ¬ë¶„ì„ ìœ„í•œ X ê°­ ì„ê³„ê°’

    Returns:
        2D í…Œì´ë¸” ë°ì´í„° [[row1_col1, row1_col2, ...], [row2_col1, ...], ...]
    """
    if not ocr_results:
        return []

    # Y ì¢Œí‘œë¡œ ì •ë ¬ í›„ í–‰ ê·¸ë£¹í™”
    sorted_items = sorted(ocr_results, key=lambda x: (x["box"][1], x["box"][0]))

    rows = []
    current_row = []
    current_y = None

    for item in sorted_items:
        y = item["box"][1]

        if current_y is None:
            current_y = y
            current_row = [item]
        elif abs(y - current_y) <= y_tolerance:
            current_row.append(item)
        else:
            # ìƒˆ í–‰ ì‹œì‘ - í˜„ì¬ í–‰ì„ X ì¢Œí‘œë¡œ ì •ë ¬
            rows.append(sorted(current_row, key=lambda x: x["box"][0]))
            current_row = [item]
            current_y = y

    if current_row:
        rows.append(sorted(current_row, key=lambda x: x["box"][0]))

    if not rows:
        return []

    # ê°œì„ : í—¤ë” í–‰(ì²« ë²ˆì§¸ í–‰ ë˜ëŠ” ê°€ì¥ ë§ì€ ì—´ì„ ê°€ì§„ í–‰)ì„ ê¸°ì¤€ìœ¼ë¡œ ì—´ ê²½ê³„ ì„¤ì •
    # ê°€ì¥ ë§ì€ í•­ëª©ì„ ê°€ì§„ í–‰ì„ í—¤ë”ë¡œ ê°„ì£¼ (ë³´í†µ í—¤ë”ê°€ ê°€ì¥ ë§ì€ ì—´ì„ ê°€ì§)
    header_row_idx = 0
    max_items = len(rows[0])
    for i, row in enumerate(rows):
        if len(row) > max_items:
            max_items = len(row)
            header_row_idx = i

    header_row = rows[header_row_idx]

    # í—¤ë” í–‰ì˜ ê° í•­ëª© ìœ„ì¹˜ë¥¼ ì—´ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©
    column_positions = []
    for item in header_row:
        x1 = item["box"][0]
        x2 = item["box"][2]
        center_x = (x1 + x2) / 2
        column_positions.append({
            "x1": x1,
            "x2": x2,
            "center": center_x,
            "text": item["text"]
        })

    # ì—´ ê²½ê³„ ì„¤ì • (í—¤ë” ê¸°ë°˜)
    column_boundaries = []
    for i, col in enumerate(column_positions):
        # ì´ì „ ì—´ì˜ ëê³¼ í˜„ì¬ ì—´ì˜ ì‹œì‘ ì‚¬ì´ì˜ ì¤‘ê°„ì ì„ ê²½ê³„ë¡œ
        if i == 0:
            start = 0
        else:
            prev_end = column_positions[i-1]["x2"]
            curr_start = col["x1"]
            start = (prev_end + curr_start) / 2

        if i == len(column_positions) - 1:
            end = table_bbox[2] - table_bbox[0] + 100  # í…Œì´ë¸” ë„ˆë¹„ + ì—¬ìœ 
        else:
            curr_end = col["x2"]
            next_start = column_positions[i+1]["x1"]
            end = (curr_end + next_start) / 2

        column_boundaries.append((start, end, col["center"]))

    # ê° í–‰ì„ ì—´ì— ë§ì¶° ì •ë ¬ (í—¤ë” ê¸°ì¤€ ì—´ ê²½ê³„ ì‚¬ìš©)
    table_data = []
    for row in rows:
        row_data = assign_to_columns_by_header(row, column_boundaries)
        if any(cell.strip() for cell in row_data):  # ë¹ˆ í–‰ ì œì™¸
            table_data.append(row_data)

    return table_data


def assign_to_columns_by_header(row_items: list, column_boundaries: list) -> list:
    """
    í—¤ë” ê¸°ë°˜ ì—´ ê²½ê³„ë¥¼ ì‚¬ìš©í•˜ì—¬ í–‰ì˜ í•­ëª©ë“¤ì„ ì—´ì— í• ë‹¹

    Args:
        row_items: í–‰ì˜ OCR í•­ëª©ë“¤
        column_boundaries: ì—´ ê²½ê³„ ë¦¬ìŠ¤íŠ¸ [(start, end, center), ...]

    Returns:
        ì—´ì— ë§ì¶° ì •ë ¬ëœ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    if not column_boundaries:
        return [item["text"] for item in row_items]

    row_data = [""] * len(column_boundaries)

    for item in row_items:
        x1 = item["box"][0]
        x2 = item["box"][2]
        item_center = (x1 + x2) / 2
        text = item["text"]

        # í•­ëª©ì˜ ì¤‘ì‹¬ì´ ì–´ëŠ ì—´ ë²”ìœ„ì— ì†í•˜ëŠ”ì§€ í™•ì¸
        best_col = -1
        for col_idx, (start, end, center) in enumerate(column_boundaries):
            if start <= item_center <= end:
                best_col = col_idx
                break

        # ë²”ìœ„ ë‚´ì— ì—†ìœ¼ë©´ ê°€ì¥ ê°€ê¹Œìš´ ì—´ ì°¾ê¸°
        if best_col == -1:
            min_dist = float('inf')
            for col_idx, (start, end, center) in enumerate(column_boundaries):
                dist = abs(item_center - center)
                if dist < min_dist:
                    min_dist = dist
                    best_col = col_idx

        if best_col >= 0:
            if row_data[best_col]:
                row_data[best_col] += " " + text
            else:
                row_data[best_col] = text

    return row_data


def estimate_column_boundaries(x_positions: list, gap_threshold: int = 30) -> list:
    """
    X ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì—´ ê²½ê³„ ì¶”ì •

    Args:
        x_positions: X ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸
        gap_threshold: ì—´ êµ¬ë¶„ ê°­ ì„ê³„ê°’

    Returns:
        ì—´ ê²½ê³„ ë¦¬ìŠ¤íŠ¸ [(start, end), ...]
    """
    if not x_positions:
        return []

    sorted_x = sorted(set(x_positions))

    # í´ëŸ¬ìŠ¤í„°ë§
    clusters = []
    current_cluster = [sorted_x[0]]

    for i in range(1, len(sorted_x)):
        if sorted_x[i] - sorted_x[i-1] <= gap_threshold:
            current_cluster.append(sorted_x[i])
        else:
            clusters.append(current_cluster)
            current_cluster = [sorted_x[i]]

    if current_cluster:
        clusters.append(current_cluster)

    # ê° í´ëŸ¬ìŠ¤í„°ì˜ ê²½ê³„
    boundaries = []
    for cluster in clusters:
        start = min(cluster) - gap_threshold // 2
        end = max(cluster) + gap_threshold // 2
        boundaries.append((start, end))

    return boundaries


def assign_to_columns(row_items: list, column_boundaries: list) -> list:
    """
    í–‰ì˜ í•­ëª©ë“¤ì„ ì—´ì— í• ë‹¹

    Args:
        row_items: í–‰ì˜ OCR í•­ëª©ë“¤
        column_boundaries: ì—´ ê²½ê³„ ë¦¬ìŠ¤íŠ¸

    Returns:
        ì—´ì— ë§ì¶° ì •ë ¬ëœ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    if not column_boundaries:
        return [item["text"] for item in row_items]

    # ê° ì—´ì— í•´ë‹¹í•˜ëŠ” í…ìŠ¤íŠ¸ ì°¾ê¸°
    row_data = [""] * len(column_boundaries)

    for item in row_items:
        x = item["box"][0]
        text = item["text"]

        # ê°€ì¥ ê°€ê¹Œìš´ ì—´ ì°¾ê¸°
        best_col = 0
        min_dist = float('inf')

        for col_idx, (start, end) in enumerate(column_boundaries):
            col_center = (start + end) / 2
            dist = abs(x - col_center)
            if dist < min_dist:
                min_dist = dist
                best_col = col_idx

        # ì´ë¯¸ ê°’ì´ ìˆìœ¼ë©´ í•©ì¹˜ê¸°
        if row_data[best_col]:
            row_data[best_col] += " " + text
        else:
            row_data[best_col] = text

    return row_data


def extract_comet_tables(pdf_bytes: bytes, progress_callback=None) -> dict:
    """
    Comet ë°©ì‹ìœ¼ë¡œ PDFì—ì„œ í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ
    OCR ê²°ê³¼ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ í…Œì´ë¸” í˜•íƒœë¡œ ë°˜í™˜

    Args:
        pdf_bytes: PDF íŒŒì¼ ë°”ì´íŠ¸
        progress_callback: ì§„í–‰ìƒí™© ì½œë°±

    Returns:
        í…Œì´ë¸” ì¶”ì¶œ ê²°ê³¼ (ê¸°ì¡´ í˜•ì‹ê³¼ í˜¸í™˜)
    """
    # OCR ì¢Œí‘œ ì¶”ì¶œ
    comet_data = extract_ocr_with_coordinates(pdf_bytes, progress_callback)

    if "error" in comet_data:
        return {
            "tables": [],
            "error": comet_data["error"],
            "is_ai_extracted": True,
            "extraction_method": "comet"
        }

    result = {
        "tables": [],
        "pages": [],
        "comet_html": [],  # Comet HTML ì˜¤ë²„ë ˆì´
        "is_ai_extracted": True,
        "total_pages": comet_data["total_pages"],
        "extraction_method": "comet",
        "ocr_engine": comet_data.get("ocr_engine", "PaddleOCR")
    }

    for page_data in comet_data["pages"]:
        page_num = page_data["page"]
        ocr_results = page_data["ocr_results"]

        # Comet HTML ì˜¤ë²„ë ˆì´ ìƒì„±
        page_html = generate_comet_overlay_html(page_data, scale=0.8)
        result["comet_html"].append({
            "page": page_num,
            "html": page_html
        })

        # OCR ê²°ê³¼ë¥¼ í–‰/ì—´ êµ¬ì¡°ë¡œ ì •ë¦¬ (ê¸°ì¡´ í˜¸í™˜)
        if ocr_results:
            # Y ì¢Œí‘œë¡œ í–‰ ê·¸ë£¹í™”
            sorted_items = sorted(ocr_results, key=lambda x: (x["box"][1], x["box"][0]))

            rows = []
            current_row = []
            current_y = None
            y_tolerance = 15  # ê°™ì€ í–‰ìœ¼ë¡œ ê°„ì£¼í•  Y ì˜¤ì°¨

            for item in sorted_items:
                y = item["box"][1]

                if current_y is None:
                    current_y = y
                    current_row = [item]
                elif abs(y - current_y) <= y_tolerance:
                    current_row.append(item)
                else:
                    # ìƒˆ í–‰ ì‹œì‘
                    rows.append(sorted(current_row, key=lambda x: x["box"][0]))
                    current_row = [item]
                    current_y = y

            if current_row:
                rows.append(sorted(current_row, key=lambda x: x["box"][0]))

            # í…Œì´ë¸” ë°ì´í„° ìƒì„±
            table_data = []
            for row in rows:
                row_texts = [item["text"] for item in row]
                if any(row_texts):  # ë¹ˆ í–‰ ì œì™¸
                    table_data.append(row_texts)

            if table_data:
                result["tables"].append({
                    "page": page_num,
                    "table_index": 1,
                    "confidence": 0.99,  # OCR ê¸°ë°˜ì´ë¯€ë¡œ ë†’ì€ ì‹ ë¢°ë„
                    "data": table_data,
                    "row_count": len(table_data),
                    "col_count": max(len(row) for row in table_data) if table_data else 0,
                    "extraction_method": "comet_ocr"
                })

        # í˜ì´ì§€ë³„ ì›ë³¸ ë°ì´í„° ì €ì¥
        result["pages"].append({
            "page": page_num,
            "ocr_results": ocr_results,
            "image_base64": page_data["image_base64"],
            "width": page_data["width"],
            "height": page_data["height"]
        })

    return result


def extract_tables_auto(pdf_bytes: bytes, progress_callback=None, method: str = "auto") -> dict:
    """
    ìë™ìœ¼ë¡œ ìµœì ì˜ ë°©ë²•ìœ¼ë¡œ í…Œì´ë¸” ì¶”ì¶œ

    Args:
        pdf_bytes: PDF íŒŒì¼ ë°”ì´íŠ¸
        progress_callback: ì§„í–‰ìƒí™© ì½œë°±
        method: ì¶”ì¶œ ë°©ë²•
            - "auto": ìë™ ì„ íƒ (Comet > Table Transformer)
            - "comet": Comet ë°©ì‹ (OCR ì˜¤ë²„ë ˆì´) - ê¶Œì¥
            - "vlm": VLM(Granite3.2-vision) ì‚¬ìš©
            - "table_transformer": Table Transformer + OCR ì‚¬ìš©

    Returns:
        ì¶”ì¶œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if method == "auto":
        # Comet ë°©ì‹ ìš°ì„  (ê°€ì¥ ì •í™•)
        if PADDLEOCR_AVAILABLE:
            method = "comet"
        elif OLLAMA_AVAILABLE and check_ollama_model("granite3.2-vision"):
            method = "vlm"
        elif TABLE_TRANSFORMER_AVAILABLE:
            method = "table_transformer"
        else:
            return {
                "tables": [],
                "error": "ì‚¬ìš© ê°€ëŠ¥í•œ ì¶”ì¶œ ë°©ë²•ì´ ì—†ìŠµë‹ˆë‹¤. PaddleOCR, Ollama ë˜ëŠ” Table Transformerë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.",
                "is_ai_extracted": False
            }

    if method == "comet":
        return extract_comet_tables(pdf_bytes, progress_callback)
    elif method == "vlm":
        return extract_vlm_tables(pdf_bytes, progress_callback)
    else:
        return extract_smart_tables(pdf_bytes, progress_callback)


def extract_smart_unified(pdf_bytes: bytes, progress_callback=None,
                          separate_tables: bool = True) -> dict:
    """
    í†µí•© ìŠ¤ë§ˆíŠ¸ í…Œì´ë¸” ì¶”ì¶œ (ë©”ë‰´ í†µí•©ìš©)

    ìë™ìœ¼ë¡œ PDF íƒ€ì…ì„ ê°ì§€í•˜ê³  ìµœì ì˜ ë°©ë²•ìœ¼ë¡œ ì¶”ì¶œ:
    - í…ìŠ¤íŠ¸ PDF â†’ PyMuPDF ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ (100% ì •í™•ë„, OCR ìŠ¤í‚µ)
    - ìŠ¤ìº” PDF â†’ PaddleOCR
    - separate_tables=True â†’ Table Transformer + ê²©ìì„  ê°ì§€ë¡œ í…Œì´ë¸” ë¶„ë¦¬

    Args:
        pdf_bytes: PDF íŒŒì¼ ë°”ì´íŠ¸
        progress_callback: ì§„í–‰ìƒí™© ì½œë°± í•¨ìˆ˜
        separate_tables: Trueë©´ í…Œì´ë¸” ì˜ì—­ì„ ê°œë³„ ë¶„ë¦¬ (ê¸°ë³¸ê°’: True)

    Returns:
        í†µí•© ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        {
            "tables": [...],
            "pages": [...],
            "is_scanned": True/False,
            "extraction_method": "text_direct" / "comet_ocr" / "hybrid",
            "ocr_engine": "PyMuPDF (Direct Text)" / "PaddleOCR",
            ...
        }
    """
    # 1. PDF íƒ€ì… ê°ì§€
    scanned = is_scanned_pdf(pdf_bytes)

    if progress_callback:
        pdf_type = "ìŠ¤ìº” PDF" if scanned else "í…ìŠ¤íŠ¸ PDF"
        progress_callback(0, 1, f"ğŸ“„ {pdf_type} ê°ì§€ë¨...")

    # 2. í…ìŠ¤íŠ¸/ì¢Œí‘œ ì¶”ì¶œ (PDF íƒ€ì…ì— ë”°ë¼)
    if scanned:
        # ìŠ¤ìº” PDF â†’ PaddleOCR
        if not PADDLEOCR_AVAILABLE:
            return {
                "tables": [],
                "error": "ìŠ¤ìº” PDF ì²˜ë¦¬ë¥¼ ìœ„í•´ PaddleOCRì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "is_scanned": True,
                "is_ai_extracted": False
            }
        text_data = extract_ocr_with_coordinates(pdf_bytes, progress_callback)
        text_data["is_scanned"] = True
    else:
        # í…ìŠ¤íŠ¸ PDF â†’ PyMuPDF ì§ì ‘ ì¶”ì¶œ
        text_data = extract_text_with_coordinates(pdf_bytes, progress_callback)
        text_data["is_scanned"] = False

    if "error" in text_data:
        return text_data

    # 3. í…Œì´ë¸” ë¶„ë¦¬ ì—¬ë¶€ì— ë”°ë¥¸ ì²˜ë¦¬
    if separate_tables and TABLE_TRANSFORMER_AVAILABLE:
        # Table Transformer + ê²©ìì„  ê°ì§€ë¡œ í…Œì´ë¸” ë¶„ë¦¬
        return _extract_with_table_separation(pdf_bytes, text_data, progress_callback)
    else:
        # ë‹¨ìˆœ í˜ì´ì§€ë³„ ì¶”ì¶œ (ê¸°ì¡´ Comet ë°©ì‹)
        return _extract_page_tables(text_data, progress_callback)


def _extract_page_tables(text_data: dict, progress_callback=None) -> dict:
    """
    í˜ì´ì§€ë³„ í…Œì´ë¸” ì¶”ì¶œ (í…Œì´ë¸” ë¶„ë¦¬ ì—†ì´)
    ê¸°ì¡´ Comet ë°©ì‹ê³¼ ë™ì¼
    """
    result = {
        "tables": [],
        "pages": [],
        "comet_html": [],
        "is_ai_extracted": True,
        "is_scanned": text_data.get("is_scanned", True),
        "total_pages": text_data.get("total_pages", 0),
        "extraction_method": text_data.get("extraction_method", "comet"),
        "ocr_engine": text_data.get("ocr_engine", "Unknown")
    }

    for page_data in text_data.get("pages", []):
        page_num = page_data["page"]
        ocr_results = page_data.get("ocr_results", [])

        # Comet HTML ì˜¤ë²„ë ˆì´ ìƒì„±
        page_html = generate_comet_overlay_html(page_data, scale=0.8)
        result["comet_html"].append({
            "page": page_num,
            "html": page_html
        })

        # OCR ê²°ê³¼ë¥¼ í–‰/ì—´ êµ¬ì¡°ë¡œ ì •ë¦¬
        if ocr_results:
            sorted_items = sorted(ocr_results, key=lambda x: (x["box"][1], x["box"][0]))

            rows = []
            current_row = []
            current_y = None
            y_tolerance = 15

            for item in sorted_items:
                y = item["box"][1]
                if current_y is None:
                    current_y = y
                    current_row = [item]
                elif abs(y - current_y) <= y_tolerance:
                    current_row.append(item)
                else:
                    rows.append(sorted(current_row, key=lambda x: x["box"][0]))
                    current_row = [item]
                    current_y = y

            if current_row:
                rows.append(sorted(current_row, key=lambda x: x["box"][0]))

            table_data = []
            for row in rows:
                row_texts = [item["text"] for item in row]
                if any(row_texts):
                    table_data.append(row_texts)

            if table_data:
                result["tables"].append({
                    "page": page_num,
                    "table_index": 1,
                    "confidence": 0.99 if not result["is_scanned"] else 0.95,
                    "data": table_data,
                    "row_count": len(table_data),
                    "col_count": max(len(row) for row in table_data) if table_data else 0,
                    "extraction_method": result["extraction_method"]
                })

        result["pages"].append({
            "page": page_num,
            "ocr_results": ocr_results,
            "image_base64": page_data.get("image_base64", ""),
            "width": page_data.get("width", 0),
            "height": page_data.get("height", 0)
        })

    return result


def _extract_with_table_separation(pdf_bytes: bytes, text_data: dict,
                                    progress_callback=None) -> dict:
    """
    Table Transformer + ê²©ìì„  ê°ì§€ë¡œ í…Œì´ë¸” ê°œë³„ ë¶„ë¦¬ ì¶”ì¶œ
    ê¸°ì¡´ extract_comet_with_table_detection ë¡œì§ í™œìš©
    """
    # extract_comet_with_table_detection í•¨ìˆ˜ í™œìš©
    # ë‹¨, text_dataê°€ ì´ë¯¸ ìˆìœ¼ë¯€ë¡œ OCRì€ ì¬ì‚¬ìš©

    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    total_pages = len(doc)

    result = {
        "tables": [],
        "pages": [],
        "comet_html": [],
        "total_pages": total_pages,
        "total_tables": 0,
        "is_ai_extracted": True,
        "is_scanned": text_data.get("is_scanned", True),
        "is_hybrid": True,
        "extraction_method": "hybrid",
        "ocr_engine": text_data.get("ocr_engine", "PaddleOCR") + " + Table Transformer"
    }

    zoom = 2.0
    table_count = 0

    for page_num in range(total_pages):
        if progress_callback:
            progress_callback(page_num + 1, total_pages,
                              f"í˜ì´ì§€ {page_num + 1}/{total_pages} í…Œì´ë¸” ë¶„ë¦¬ ì¤‘...")

        # í˜ì´ì§€ ì´ë¯¸ì§€ ìƒì„±
        page = doc[page_num]
        mat = fitz.Matrix(zoom, zoom)
        pix = page.get_pixmap(matrix=mat)
        img_bytes = pix.tobytes("png")
        page_image = Image.open(io.BytesIO(img_bytes))

        # í•´ë‹¹ í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        page_text_data = None
        for pd in text_data.get("pages", []):
            if pd["page"] == page_num + 1:
                page_text_data = pd
                break

        # Table Transformerë¡œ í…Œì´ë¸” ì˜ì—­ ê°ì§€
        detected_tables = detect_tables(page_image, threshold=0.5)

        if detected_tables and page_text_data:
            # ê°ì§€ëœ í…Œì´ë¸”ë³„ë¡œ ì²˜ë¦¬
            for table_idx, table_info in enumerate(detected_tables):
                table_count += 1
                bbox = table_info["box"]
                confidence = table_info["score"]

                # bbox ì˜ì—­ ë‚´ì˜ OCR ê²°ê³¼ë§Œ í•„í„°ë§
                ocr_results = page_text_data.get("ocr_results", [])
                filtered_ocr = []
                for item in ocr_results:
                    item_box = item["box"]
                    # ì¤‘ì‹¬ì ì´ í…Œì´ë¸” bbox ì•ˆì— ìˆëŠ”ì§€ í™•ì¸
                    cx = (item_box[0] + item_box[2]) / 2
                    cy = (item_box[1] + item_box[3]) / 2
                    if bbox[0] <= cx <= bbox[2] and bbox[1] <= cy <= bbox[3]:
                        filtered_ocr.append(item)

                # í…Œì´ë¸” ì˜ì—­ í¬ë¡­
                table_image = page_image.crop(tuple(bbox))

                # ê²©ìì„  ê°ì§€
                grid_lines = detect_grid_lines(table_image,
                                               min_h_ratio=0.05, min_v_ratio=0.05)

                # ê²©ìì„  ê¸°ë°˜ ì…€ ìƒì„± (detect_grid_linesê°€ cellsë¥¼ ë°˜í™˜)
                cells = grid_lines.get("cells", [])

                # ì…€ì— OCR í…ìŠ¤íŠ¸ ë§¤í•‘
                if cells and filtered_ocr:
                    # bbox ì¢Œìƒë‹¨ ê¸°ì¤€ìœ¼ë¡œ ì¢Œí‘œ ë³€í™˜
                    offset_x, offset_y = bbox[0], bbox[1]
                    for item in filtered_ocr:
                        item["box"] = [
                            item["box"][0] - offset_x,
                            item["box"][1] - offset_y,
                            item["box"][2] - offset_x,
                            item["box"][3] - offset_y
                        ]

                    table_data = map_ocr_to_grid_cells(filtered_ocr, grid_lines)
                    # None ë°˜í™˜ ì‹œ í´ë°± (Codex ê¶Œì¥)
                    if table_data is None:
                        table_data = _group_ocr_to_rows(filtered_ocr, bbox)
                else:
                    # ê²©ìì„  ì—†ìœ¼ë©´ Y ì¢Œí‘œ ê¸°ë°˜ ê·¸ë£¹í™”
                    table_data = _group_ocr_to_rows(filtered_ocr, bbox)

                if table_data:
                    result["tables"].append({
                        "page": page_num + 1,
                        "table_index": table_idx + 1,
                        "table_name": f"í…Œì´ë¸” {table_idx + 1}",
                        "bbox": bbox,
                        "confidence": confidence,
                        "data": table_data,
                        "row_count": len(table_data),
                        "col_count": max(len(row) for row in table_data) if table_data else 0,
                        "extraction_method": "hybrid_table_detection"
                    })

        elif page_text_data:
            # í…Œì´ë¸”ì´ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ í˜ì´ì§€ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ í…Œì´ë¸”ë¡œ
            ocr_results = page_text_data.get("ocr_results", [])
            if ocr_results:
                table_data = _group_ocr_to_rows(ocr_results, None)
                if table_data:
                    table_count += 1
                    result["tables"].append({
                        "page": page_num + 1,
                        "table_index": 1,
                        "table_name": "ì „ì²´ í˜ì´ì§€",
                        "confidence": 0.8,
                        "data": table_data,
                        "row_count": len(table_data),
                        "col_count": max(len(row) for row in table_data) if table_data else 0,
                        "extraction_method": "page_ocr"
                    })

        # í˜ì´ì§€ ë°ì´í„° ì €ì¥
        if page_text_data:
            result["pages"].append({
                "page": page_num + 1,
                "ocr_results": page_text_data.get("ocr_results", []),
                "image_base64": page_text_data.get("image_base64", ""),
                "width": page_text_data.get("width", 0),
                "height": page_text_data.get("height", 0)
            })

    doc.close()
    result["total_tables"] = table_count
    return result


def _group_ocr_to_rows(ocr_results: list, bbox: list = None) -> list:
    """OCR ê²°ê³¼ë¥¼ Y ì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ í–‰ìœ¼ë¡œ ê·¸ë£¹í™”"""
    if not ocr_results:
        return []

    sorted_items = sorted(ocr_results, key=lambda x: (x["box"][1], x["box"][0]))

    rows = []
    current_row = []
    current_y = None
    y_tolerance = 15

    for item in sorted_items:
        y = item["box"][1]
        if current_y is None:
            current_y = y
            current_row = [item]
        elif abs(y - current_y) <= y_tolerance:
            current_row.append(item)
        else:
            rows.append(sorted(current_row, key=lambda x: x["box"][0]))
            current_row = [item]
            current_y = y

    if current_row:
        rows.append(sorted(current_row, key=lambda x: x["box"][0]))

    table_data = []
    for row in rows:
        row_texts = [item["text"] for item in row]
        if any(row_texts):
            table_data.append(row_texts)

    return table_data


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    import sys
    sys.stdout.reconfigure(encoding='utf-8')

    print("=" * 60)
    print("ìŠ¤ë§ˆíŠ¸ í…Œì´ë¸” ì¶”ì¶œê¸° v3 í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    print(f"\nì—”ì§„ ìƒíƒœ:")
    print(f"  Ollama VLM: {'ì‚¬ìš© ê°€ëŠ¥' if OLLAMA_AVAILABLE else 'ì‚¬ìš© ë¶ˆê°€'}")
    print(f"  Granite3.2-vision: {'ì„¤ì¹˜ë¨' if check_ollama_model('granite3.2-vision') else 'ë¯¸ì„¤ì¹˜'}")
    print(f"  PaddleOCR: {'ì‚¬ìš© ê°€ëŠ¥' if PADDLEOCR_AVAILABLE else 'ì‚¬ìš© ë¶ˆê°€'}")
    print(f"  Tesseract: {'ì‚¬ìš© ê°€ëŠ¥' if TESSERACT_AVAILABLE else 'ì‚¬ìš© ë¶ˆê°€'}")
    print(f"  Table Transformer: {'ì‚¬ìš© ê°€ëŠ¥' if TABLE_TRANSFORMER_AVAILABLE else 'ì‚¬ìš© ë¶ˆê°€'}")

    # í…ŒìŠ¤íŠ¸ PDF
    pdf_path = "e:/Antigravity/Black_Yak/ì œë¡œìŠ¤íŒŸ ë‹¤ìš´ìì¼“#1 ì˜¤ë” ë“±ë¡ ì‘ì§€ 1BYPAWU005-M-1.pdf"

    if os.path.exists(pdf_path):
        with open(pdf_path, "rb") as f:
            pdf_bytes = f.read()

        print(f"\nPDF: {pdf_path}")
        print(f"Is Scanned PDF: {is_scanned_pdf(pdf_bytes)}")

        def progress(page, total, msg):
            print(f"  [{page}/{total}] {msg}")

        # VLM í…ŒìŠ¤íŠ¸
        if OLLAMA_AVAILABLE and check_ollama_model("granite3.2-vision"):
            print("\n" + "=" * 60)
            print("VLM ì¶”ì¶œ í…ŒìŠ¤íŠ¸ (Granite3.2-vision)")
            print("=" * 60)
            result = extract_vlm_tables(pdf_bytes, progress_callback=progress)

            print(f"\nê²°ê³¼:")
            print(f"  ì¶”ì¶œ ë°©ë²•: {result.get('extraction_method', 'N/A')}")
            print(f"  ëª¨ë¸: {result.get('model', 'N/A')}")
            print(f"  ë°œê²¬ëœ í…Œì´ë¸” ìˆ˜: {len(result['tables'])}")

            for table in result["tables"]:
                print(f"\n  í˜ì´ì§€ {table['page']}, í…Œì´ë¸” {table['table_index']}:")
                print(f"    ì œëª©: {table.get('title', 'N/A')}")
                print(f"    í¬ê¸°: {table['row_count']} í–‰ x {table['col_count']} ì—´")
                print(f"    ë°ì´í„°:")
                for row in table["data"][:5]:
                    print(f"      {row}")

            # í˜ì´ì§€ë³„ í•„ë“œ ì •ë³´
            for page_data in result.get("pages", []):
                if page_data.get("fields"):
                    print(f"\n  í˜ì´ì§€ {page_data['page']} ì¶”ì¶œ í•„ë“œ:")
                    for key, value in page_data["fields"].items():
                        print(f"    {key}: {value}")

        # Table Transformer í…ŒìŠ¤íŠ¸ (ë¹„êµìš©)
        print("\n" + "=" * 60)
        print("Table Transformer ì¶”ì¶œ í…ŒìŠ¤íŠ¸ (ë¹„êµìš©)")
        print("=" * 60)
        result = extract_smart_tables(pdf_bytes, progress_callback=progress, use_paddle=True)

        print(f"\nê²°ê³¼:")
        print(f"  OCR ì—”ì§„: {result.get('ocr_engine', 'N/A')}")
        print(f"  ë°œê²¬ëœ í…Œì´ë¸” ìˆ˜: {len(result['tables'])}")

        for table in result["tables"][:2]:  # ì²˜ìŒ 2ê°œë§Œ
            print(f"\n  í˜ì´ì§€ {table['page']}, í…Œì´ë¸” {table['table_index']}:")
            print(f"    ì‹ ë¢°ë„: {table['confidence']}")
            print(f"    í¬ê¸°: {table['row_count']} í–‰ x {table['col_count']} ì—´")
            print(f"    ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 3í–‰):")
            for row in table["data"][:3]:
                print(f"      {row}")
    else:
        print(f"\nPDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
