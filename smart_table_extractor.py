"""
ìŠ¤ë§ˆíŠ¸ í…Œì´ë¸” ì¶”ì¶œê¸° v4
Perplexity Comet ë°©ì‹: ì›ë³¸ PDF ì´ë¯¸ì§€ ìœ„ì— OCR í…ìŠ¤íŠ¸ë¥¼ íˆ¬ëª… ì˜¤ë²„ë ˆì´ë¡œ ë°°ì¹˜
ì‚¬ìš©ìê°€ í…ìŠ¤íŠ¸ë¥¼ ì„ íƒ/ë³µì‚¬í•  ìˆ˜ ìˆê²Œ í•¨ (100% ì •í™•ë„)

v4 ë³€ê²½ì‚¬í•­:
- Comet ë°©ì‹ OCR ì˜¤ë²„ë ˆì´ ì‹œìŠ¤í…œ ì¶”ê°€
- PDF ì´ë¯¸ì§€ + OCR í…ìŠ¤íŠ¸ ì¢Œí‘œ ê¸°ë°˜ íˆ¬ëª… ì˜¤ë²„ë ˆì´
- HTML/CSSë¡œ í…ìŠ¤íŠ¸ ì„ íƒ ê°€ëŠ¥í•˜ê²Œ ë Œë”ë§

v3 ë³€ê²½ì‚¬í•­:
- Granite3.2-vision VLM ì¶”ê°€ (ë¬¸ì„œ ì´í•´ íŠ¹í™” ëª¨ë¸)
- Ollama ê¸°ë°˜ ë¡œì»¬ VLM ì¶”ì¶œ ëª¨ë“œ
- Table TransformerëŠ” í´ë°±ìœ¼ë¡œ ìœ ì§€

v2 ë³€ê²½ì‚¬í•­:
- PaddleOCR ì‚¬ìš© (Tesseract ëŒ€ë¹„ í•œê¸€ ì¸ì‹ë¥  í–¥ìƒ)
- PP-OCRv5 ëª¨ë¸ ì ìš©
"""

import fitz
from PIL import Image
import io
import os
import json
import re
import tempfile
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (PaddleOCR ì—°ê²° ì²´í¬ ìŠ¤í‚µ)
os.environ['DISABLE_MODEL_SOURCE_CHECK'] = 'True'

# Ollama VLM ì„¤ì •
OLLAMA_AVAILABLE = False
try:
    import ollama
    OLLAMA_AVAILABLE = True
except ImportError:
    ollama = None

# PaddleOCR ì„¤ì •
PADDLEOCR_AVAILABLE = False
_paddle_ocr = None

try:
    from paddleocr import PaddleOCR
    PADDLEOCR_AVAILABLE = True
except ImportError:
    PaddleOCR = None

# Tesseract OCR ì„¤ì • (í´ë°±ìš©)
TESSERACT_AVAILABLE = False
try:
    import pytesseract
    pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
    TESSDATA_DIR = str(Path(__file__).parent / "tessdata")
    os.environ['TESSDATA_PREFIX'] = TESSDATA_DIR
    TESSERACT_AVAILABLE = True
except ImportError:
    pytesseract = None

# OCR ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
OCR_AVAILABLE = PADDLEOCR_AVAILABLE or TESSERACT_AVAILABLE

# Table Transformer ì„¤ì •
TABLE_TRANSFORMER_AVAILABLE = False
try:
    import torch
    from transformers import AutoImageProcessor, TableTransformerForObjectDetection
    TABLE_TRANSFORMER_AVAILABLE = True
except ImportError:
    torch = None
    AutoImageProcessor = None
    TableTransformerForObjectDetection = None


# ëª¨ë¸ ìºì‹œ (í•œ ë²ˆë§Œ ë¡œë“œ)
_detection_model = None
_detection_processor = None
_structure_model = None
_structure_processor = None


def get_paddle_ocr():
    """PaddleOCR ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ì‹±ê¸€í†¤)"""
    global _paddle_ocr
    if _paddle_ocr is None and PADDLEOCR_AVAILABLE:
        _paddle_ocr = PaddleOCR(lang='korean')
    return _paddle_ocr


def load_detection_model():
    """í…Œì´ë¸” ê°ì§€ ëª¨ë¸ ë¡œë“œ (ìºì‹œ)"""
    global _detection_model, _detection_processor
    if _detection_model is None:
        _detection_processor = AutoImageProcessor.from_pretrained(
            "microsoft/table-transformer-detection"
        )
        _detection_model = TableTransformerForObjectDetection.from_pretrained(
            "microsoft/table-transformer-detection"
        )
    return _detection_processor, _detection_model


def load_structure_model():
    """í…Œì´ë¸” êµ¬ì¡° ì¸ì‹ ëª¨ë¸ ë¡œë“œ (ìºì‹œ)"""
    global _structure_model, _structure_processor
    if _structure_model is None:
        _structure_processor = AutoImageProcessor.from_pretrained(
            "microsoft/table-transformer-structure-recognition"
        )
        _structure_model = TableTransformerForObjectDetection.from_pretrained(
            "microsoft/table-transformer-structure-recognition"
        )
    return _structure_processor, _structure_model


def pdf_page_to_image(pdf_bytes: bytes, page_num: int = 0, zoom: float = 2.0) -> Image.Image:
    """PDF í˜ì´ì§€ë¥¼ PIL Imageë¡œ ë³€í™˜"""
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    page = doc[page_num]
    mat = fitz.Matrix(zoom, zoom)
    pix = page.get_pixmap(matrix=mat)
    img_bytes = pix.tobytes("png")
    img = Image.open(io.BytesIO(img_bytes))
    doc.close()
    return img


def detect_tables(image: Image.Image, threshold: float = 0.7) -> list:
    """ì´ë¯¸ì§€ì—ì„œ í…Œì´ë¸” ì˜ì—­ ê°ì§€"""
    if not TABLE_TRANSFORMER_AVAILABLE:
        return []

    processor, model = load_detection_model()
    inputs = processor(images=image, return_tensors="pt")

    with torch.no_grad():
        outputs = model(**inputs)

    target_sizes = torch.tensor([image.size[::-1]])
    results = processor.post_process_object_detection(
        outputs, threshold=threshold, target_sizes=target_sizes
    )[0]

    tables = []
    for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
        box_coords = [int(x) for x in box.tolist()]
        tables.append({
            "score": round(score.item(), 3),
            "label": model.config.id2label[label.item()],
            "box": box_coords  # [x1, y1, x2, y2]
        })

    return tables


def detect_table_structure(table_image: Image.Image, threshold: float = 0.5) -> dict:
    """í…Œì´ë¸” ì´ë¯¸ì§€ì—ì„œ ì…€/í–‰/ì—´ êµ¬ì¡° ê°ì§€"""
    if not TABLE_TRANSFORMER_AVAILABLE:
        return {"cells": [], "rows": [], "columns": []}

    processor, model = load_structure_model()
    inputs = processor(images=table_image, return_tensors="pt")

    with torch.no_grad():
        outputs = model(**inputs)

    target_sizes = torch.tensor([table_image.size[::-1]])
    results = processor.post_process_object_detection(
        outputs, threshold=threshold, target_sizes=target_sizes
    )[0]

    cells = []
    rows = []
    columns = []

    for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
        box_coords = [int(x) for x in box.tolist()]
        label_name = model.config.id2label[label.item()]

        item = {
            "score": round(score.item(), 3),
            "box": box_coords
        }

        if "cell" in label_name:
            cells.append(item)
        elif "row" in label_name:
            rows.append(item)
        elif "column" in label_name:
            columns.append(item)

    return {
        "cells": cells,
        "rows": rows,
        "columns": columns
    }


def ocr_cell_paddle(image: Image.Image, box: list) -> str:
    """PaddleOCRë¡œ ì…€ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    ocr = get_paddle_ocr()
    if ocr is None:
        return ""

    x1, y1, x2, y2 = box
    cell_img = image.crop((x1, y1, x2, y2))

    # PIL Imageë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    import tempfile
    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
        cell_img.save(tmp.name)
        tmp_path = tmp.name

    try:
        result = ocr.predict(tmp_path)
        os.unlink(tmp_path)

        if result:
            texts = []
            for res in result:
                if 'rec_texts' in res:
                    texts.extend(res['rec_texts'])
            return ' '.join(texts).strip()
    except Exception as e:
        if os.path.exists(tmp_path):
            os.unlink(tmp_path)
        return ""

    return ""


def ocr_cell_tesseract(image: Image.Image, box: list) -> str:
    """Tesseract OCRë¡œ ì…€ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í´ë°±)"""
    if not TESSERACT_AVAILABLE:
        return ""

    x1, y1, x2, y2 = box
    cell_img = image.crop((x1, y1, x2, y2))

    # OCR ì‹¤í–‰ (í•œê¸€+ì˜ì–´)
    text = pytesseract.image_to_string(cell_img, lang='kor+eng').strip()
    return text


def ocr_cell(image: Image.Image, box: list) -> str:
    """ì…€ ì´ë¯¸ì§€ì—ì„œ OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (PaddleOCR ìš°ì„ , Tesseract í´ë°±)"""
    if PADDLEOCR_AVAILABLE:
        return ocr_cell_paddle(image, box)
    elif TESSERACT_AVAILABLE:
        return ocr_cell_tesseract(image, box)
    return ""


def ocr_full_image_paddle(image: Image.Image) -> list:
    """PaddleOCRë¡œ ì „ì²´ ì´ë¯¸ì§€ OCR (ë” ë¹ ë¥¸ ë°©ì‹)"""
    ocr = get_paddle_ocr()
    if ocr is None:
        return []

    # PIL Imageë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    import tempfile
    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
        image.save(tmp.name)
        tmp_path = tmp.name

    try:
        result = ocr.predict(tmp_path)
        os.unlink(tmp_path)

        if result:
            ocr_results = []
            for res in result:
                if 'rec_texts' in res and 'rec_polys' in res:
                    texts = res['rec_texts']
                    polys = res['rec_polys']
                    scores = res.get('rec_scores', [1.0] * len(texts))

                    for text, poly, score in zip(texts, polys, scores):
                        # polyëŠ” 4ê°œì˜ ì  [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
                        if len(poly) >= 4:
                            x_coords = [p[0] for p in poly]
                            y_coords = [p[1] for p in poly]
                            # numpy int16 â†’ Python int ë³€í™˜ (JSON ì§ë ¬í™” í˜¸í™˜)
                            box = [int(min(x_coords)), int(min(y_coords)), int(max(x_coords)), int(max(y_coords))]
                            ocr_results.append({
                                "text": text,
                                "box": box,
                                "score": float(score) if hasattr(score, 'item') else score
                            })
            return ocr_results
    except Exception as e:
        if os.path.exists(tmp_path):
            os.unlink(tmp_path)

    return []


def organize_cells_to_table(cells: list, table_width: int, table_height: int) -> list:
    """ì…€ë“¤ì„ í–‰/ì—´ êµ¬ì¡°ë¡œ ì •ë¦¬í•˜ì—¬ 2D í…Œì´ë¸” ìƒì„±"""
    if not cells:
        return []

    # ì…€ë“¤ì„ y ì¢Œí‘œ(í–‰)ë¡œ ë¨¼ì € ì •ë ¬, ê°™ì€ í–‰ ë‚´ì—ì„œëŠ” x ì¢Œí‘œ(ì—´)ë¡œ ì •ë ¬
    sorted_cells = sorted(cells, key=lambda c: (c["box"][1], c["box"][0]))

    # í–‰ ê·¸ë£¹ ìƒì„± (y ì¢Œí‘œê°€ ë¹„ìŠ·í•œ ì…€ë“¤ì„ ê°™ì€ í–‰ìœ¼ë¡œ)
    rows = []
    current_row = []
    current_y = None
    y_tolerance = 20  # ê°™ì€ í–‰ìœ¼ë¡œ ê°„ì£¼í•  y ì˜¤ì°¨ ë²”ìœ„

    for cell in sorted_cells:
        y = cell["box"][1]

        if current_y is None:
            current_y = y
            current_row = [cell]
        elif abs(y - current_y) <= y_tolerance:
            current_row.append(cell)
        else:
            # ìƒˆë¡œìš´ í–‰ ì‹œì‘
            rows.append(sorted(current_row, key=lambda c: c["box"][0]))
            current_row = [cell]
            current_y = y

    if current_row:
        rows.append(sorted(current_row, key=lambda c: c["box"][0]))

    # í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì—¬ 2D ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    table_data = []
    for row in rows:
        row_data = [cell.get("text", "") for cell in row]
        table_data.append(row_data)

    return table_data


def extract_smart_tables(pdf_bytes: bytes, progress_callback=None, use_paddle=True) -> dict:
    """
    ìŠ¤ë§ˆíŠ¸ í…Œì´ë¸” ì¶”ì¶œ (Comet ë°©ì‹)
    1. PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    2. Table Transformerë¡œ í…Œì´ë¸” ì˜ì—­ ê°ì§€
    3. ê° í…Œì´ë¸”ì˜ ì…€ êµ¬ì¡° ì¸ì‹
    4. PaddleOCR/Tesseractë¡œ ê° ì…€ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    5. êµ¬ì¡°í™”ëœ í…Œì´ë¸” ë°ì´í„° ë°˜í™˜

    Args:
        pdf_bytes: PDF íŒŒì¼ ë°”ì´íŠ¸
        progress_callback: ì§„í–‰ìƒí™© ì½œë°± í•¨ìˆ˜ (page, total, message)
        use_paddle: PaddleOCR ì‚¬ìš© ì—¬ë¶€ (Falseë©´ Tesseract ì‚¬ìš©)
    """
    if not TABLE_TRANSFORMER_AVAILABLE:
        return {
            "tables": [],
            "error": "Table Transformerê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "is_ai_extracted": False
        }

    if not OCR_AVAILABLE:
        return {
            "tables": [],
            "error": "OCR(PaddleOCR ë˜ëŠ” Tesseract)ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "is_ai_extracted": False
        }

    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    total_pages = len(doc)

    # OCR ì—”ì§„ ì •ë³´
    ocr_engine = "PaddleOCR" if (use_paddle and PADDLEOCR_AVAILABLE) else "Tesseract"

    result = {
        "tables": [],
        "is_ai_extracted": True,
        "total_pages": total_pages,
        "ocr_engine": ocr_engine
    }

    for page_num in range(total_pages):
        if progress_callback:
            progress_callback(page_num + 1, total_pages, f"í˜ì´ì§€ {page_num + 1}/{total_pages} ì²˜ë¦¬ ì¤‘...")

        # PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        page = doc[page_num]
        mat = fitz.Matrix(2.0, 2.0)  # 2x í™•ëŒ€
        pix = page.get_pixmap(matrix=mat)
        img_bytes = pix.tobytes("png")
        page_image = Image.open(io.BytesIO(img_bytes))

        # í…Œì´ë¸” ì˜ì—­ ê°ì§€
        detected_tables = detect_tables(page_image, threshold=0.7)

        for table_idx, table_info in enumerate(detected_tables):
            if progress_callback:
                progress_callback(
                    page_num + 1, total_pages,
                    f"í˜ì´ì§€ {page_num + 1} - í…Œì´ë¸” {table_idx + 1} êµ¬ì¡° ë¶„ì„ ì¤‘..."
                )

            # í…Œì´ë¸” ì˜ì—­ í¬ë¡­
            x1, y1, x2, y2 = table_info["box"]
            table_image = page_image.crop((x1, y1, x2, y2))

            # ì…€ êµ¬ì¡° ì¸ì‹
            structure = detect_table_structure(table_image, threshold=0.5)
            cells = structure["cells"]

            if not cells:
                continue

            # ê° ì…€ì—ì„œ OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if progress_callback:
                progress_callback(
                    page_num + 1, total_pages,
                    f"í˜ì´ì§€ {page_num + 1} - í…Œì´ë¸” {table_idx + 1} OCR ì¤‘... ({ocr_engine})"
                )

            for cell in cells:
                if use_paddle and PADDLEOCR_AVAILABLE:
                    cell["text"] = ocr_cell_paddle(table_image, cell["box"])
                else:
                    cell["text"] = ocr_cell_tesseract(table_image, cell["box"])

            # ì…€ë“¤ì„ 2D í…Œì´ë¸” êµ¬ì¡°ë¡œ ì •ë¦¬
            table_data = organize_cells_to_table(
                cells,
                table_image.width,
                table_image.height
            )

            if table_data:
                result["tables"].append({
                    "page": page_num + 1,
                    "table_index": table_idx + 1,
                    "confidence": table_info["score"],
                    "data": table_data,
                    "cell_count": len(cells),
                    "row_count": len(table_data),
                    "col_count": max(len(row) for row in table_data) if table_data else 0
                })

    doc.close()
    return result


def is_scanned_pdf(pdf_bytes: bytes) -> bool:
    """PDFê°€ ìŠ¤ìº”(ì´ë¯¸ì§€ ê¸°ë°˜)ì¸ì§€ í™•ì¸"""
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")

    for page_num in range(min(3, len(doc))):  # ì²˜ìŒ 3í˜ì´ì§€ë§Œ í™•ì¸
        page = doc[page_num]
        text = page.get_text().strip()

        if len(text) > 50:  # í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ í…ìŠ¤íŠ¸ PDF
            doc.close()
            return False

    doc.close()
    return True


# ============================================================
# VLM (Vision Language Model) ê¸°ë°˜ í…Œì´ë¸” ì¶”ì¶œ - Comet ë°©ì‹
# ============================================================

def check_ollama_model(model_name: str = "granite3.2-vision") -> bool:
    """Ollamaì—ì„œ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    if not OLLAMA_AVAILABLE:
        return False
    try:
        result = ollama.list()
        # ollama.list()ëŠ” models ì†ì„±ì„ ê°€ì§„ ê°ì²´ ë°˜í™˜
        models_list = getattr(result, 'models', None)
        if models_list is None and isinstance(result, dict):
            models_list = result.get('models', [])
        if models_list is None:
            models_list = []

        model_names = []
        for m in models_list:
            # Model ê°ì²´ ë˜ëŠ” ë”•ì…”ë„ˆë¦¬ ì²˜ë¦¬
            name = getattr(m, 'model', None)
            if name is None and isinstance(m, dict):
                name = m.get('model')
            if name:
                model_names.append(name.split(':')[0])

        return model_name.split(':')[0] in model_names
    except Exception as e:
        print(f"Ollama ëª¨ë¸ í™•ì¸ ì˜¤ë¥˜: {e}")
        return False


def extract_table_with_vlm(image_path: str, model: str = "granite3.2-vision") -> dict:
    """
    VLMì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ
    Perplexity Comet ë°©ì‹: AIê°€ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ì§ì ‘ í…Œì´ë¸” ë‚´ìš©ì„ ì´í•´

    Args:
        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        model: ì‚¬ìš©í•  Ollama VLM ëª¨ë¸

    Returns:
        ì¶”ì¶œëœ í…Œì´ë¸” ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    if not OLLAMA_AVAILABLE:
        return {"error": "Ollamaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "raw_text": ""}

    # VLM í”„ë¡¬í”„íŠ¸ (ellipsis ... ì œê±°í•˜ì—¬ JSON íŒŒì‹± ì˜¤ë¥˜ ë°©ì§€)
    prompt = '''This is a garment manufacturing document (WORK SHEET).
Extract ALL text and data from this document image.

Focus on these key fields if present:
- STYLE NO / Style Number
- SEASON
- COLOR WAY (all color codes like BK, NA, SV and their names)
- GOODS KIND / Product type
- BRAND
- FACTORY
- ORDER NO
- DELIVERY DATE
- Any table data with rows and columns

Return the data as valid JSON. Example format:
{
    "fields": {
        "STYLE_NO": "ABC123",
        "SEASON": "2024FW",
        "COLOR_WAY": [{"code": "BK", "name": "BLACK"}, {"code": "NA", "name": "NAVY"}],
        "GOODS_KIND": "JACKET",
        "BRAND": "BRAND_NAME"
    },
    "tables": [
        {
            "title": "Size Chart",
            "headers": ["SIZE", "CHEST", "LENGTH"],
            "rows": [["S", "100", "65"], ["M", "105", "67"]]
        }
    ],
    "raw_text": "all visible text"
}

IMPORTANT:
- Return ONLY valid JSON, no ellipsis (...) or placeholder text
- Only include fields that are actually visible in the image
- If no tables found, use empty array: "tables": []'''

    try:
        response = ollama.chat(
            model=model,
            messages=[{
                'role': 'user',
                'content': prompt,
                'images': [image_path]
            }],
            options={'num_predict': 4000, 'temperature': 0.1}
        )

        content = response['message']['content']

        # JSON ì¶”ì¶œ ì‹œë„
        json_match = re.search(r'\{[\s\S]*\}', content)
        if json_match:
            json_str = json_match.group()

            # VLMì´ ellipsisë¥¼ í¬í•¨í–ˆì„ ê²½ìš° ì œê±° (JSON íŒŒì‹± ì˜¤ë¥˜ ë°©ì§€)
            # íŒ¨í„´: , ...] ë˜ëŠ” , ...]
            json_str = re.sub(r',\s*\.\.\.(\s*[\]\}])', r'\1', json_str)
            # íŒ¨í„´: [..., ...] -> [...] (ë°°ì—´ ëì˜ ellipsis)
            json_str = re.sub(r'\.\.\.\s*,?\s*(?=[\]\}])', '', json_str)

            try:
                data = json.loads(json_str)
                data['raw_response'] = content
                return data
            except json.JSONDecodeError as e:
                # ë””ë²„ê·¸ìš©: íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì €ì¥
                return {
                    "raw_text": content,
                    "fields": {},
                    "tables": [],
                    "parse_error": str(e),
                    "json_attempted": json_str[:500]
                }

        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        return {
            "raw_text": content,
            "fields": {},
            "tables": []
        }

    except Exception as e:
        return {
            "error": str(e),
            "raw_text": ""
        }


def extract_vlm_tables(pdf_bytes: bytes, progress_callback=None, model: str = "granite3.2-vision") -> dict:
    """
    VLM(Vision Language Model)ì„ ì‚¬ìš©í•˜ì—¬ PDFì—ì„œ í…Œì´ë¸” ì¶”ì¶œ
    Perplexity Comet ë°©ì‹: AIê°€ ë¬¸ì„œë¥¼ ë³´ê³  ì§ì ‘ ì´í•´í•˜ì—¬ ë°ì´í„° ì¶”ì¶œ

    Args:
        pdf_bytes: PDF íŒŒì¼ ë°”ì´íŠ¸
        progress_callback: ì§„í–‰ìƒí™© ì½œë°± í•¨ìˆ˜ (page, total, message)
        model: ì‚¬ìš©í•  VLM ëª¨ë¸ (ê¸°ë³¸: granite3.2-vision)

    Returns:
        ì¶”ì¶œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if not OLLAMA_AVAILABLE:
        return {
            "tables": [],
            "error": "Ollamaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install ollama' ì‹¤í–‰ í•„ìš”",
            "is_ai_extracted": False,
            "extraction_method": "vlm"
        }

    if not check_ollama_model(model):
        return {
            "tables": [],
            "error": f"ëª¨ë¸ '{model}'ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'ollama pull {model}' ì‹¤í–‰ í•„ìš”",
            "is_ai_extracted": False,
            "extraction_method": "vlm"
        }

    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    total_pages = len(doc)

    result = {
        "tables": [],
        "pages": [],
        "is_ai_extracted": True,
        "total_pages": total_pages,
        "extraction_method": "vlm",
        "model": model
    }

    for page_num in range(total_pages):
        if progress_callback:
            progress_callback(page_num + 1, total_pages, f"í˜ì´ì§€ {page_num + 1}/{total_pages} VLM ë¶„ì„ ì¤‘...")

        # PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        page = doc[page_num]
        mat = fitz.Matrix(2.0, 2.0)  # 2x í™•ëŒ€ë¡œ ë” ì„ ëª…í•˜ê²Œ
        pix = page.get_pixmap(matrix=mat)

        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (Windows í˜¸í™˜)
        tmp_path = os.path.join(tempfile.gettempdir(), f"vlm_page_{page_num}.png")
        pix.save(tmp_path)

        try:
            # VLMìœ¼ë¡œ ì¶”ì¶œ
            vlm_result = extract_table_with_vlm(tmp_path, model)

            # ê²°ê³¼ ì €ì¥
            page_data = {
                "page": page_num + 1,
                "fields": vlm_result.get("fields", {}),
                "tables": vlm_result.get("tables", []),
                "raw_text": vlm_result.get("raw_text", "")
            }

            if "error" in vlm_result:
                page_data["error"] = vlm_result["error"]

            result["pages"].append(page_data)

            # í…Œì´ë¸” ë°ì´í„°ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            for table_idx, table in enumerate(vlm_result.get("tables", [])):
                table_data = []

                # í—¤ë”ê°€ ìˆìœ¼ë©´ ì¶”ê°€
                if table.get("headers"):
                    table_data.append(table["headers"])

                # í–‰ ë°ì´í„° ì¶”ê°€
                for row in table.get("rows", []):
                    table_data.append(row)

                if table_data:
                    result["tables"].append({
                        "page": page_num + 1,
                        "table_index": table_idx + 1,
                        "confidence": 0.95,  # VLMì€ ì‹ ë¢°ë„ë¥¼ ì§ì ‘ ì œê³µí•˜ì§€ ì•ŠìŒ
                        "data": table_data,
                        "title": table.get("title", ""),
                        "row_count": len(table_data),
                        "col_count": max(len(row) for row in table_data) if table_data else 0
                    })

            # í•„ë“œ ë°ì´í„°ë„ í…Œì´ë¸”ë¡œ ë³€í™˜ (í‚¤-ê°’ ìŒ)
            fields = vlm_result.get("fields", {})
            if fields:
                field_table = []
                for key, value in fields.items():
                    if isinstance(value, list):
                        # COLOR_WAY ë“± ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ì²˜ë¦¬
                        for item in value:
                            if isinstance(item, dict):
                                field_table.append([key, f"{item.get('code', '')} - {item.get('name', '')}"])
                            else:
                                field_table.append([key, str(item)])
                    else:
                        field_table.append([key, str(value)])

                if field_table:
                    result["tables"].insert(0, {
                        "page": page_num + 1,
                        "table_index": 0,
                        "confidence": 0.95,
                        "data": [["í•„ë“œ", "ê°’"]] + field_table,
                        "title": "ë¬¸ì„œ í•„ë“œ",
                        "row_count": len(field_table) + 1,
                        "col_count": 2
                    })

        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)

    doc.close()
    return result


# ============================================================
# í†µí•© ì¶”ì¶œ í•¨ìˆ˜
# ============================================================

# ============================================================
# Comet ë°©ì‹ OCR ì˜¤ë²„ë ˆì´ ì‹œìŠ¤í…œ
# PDF ì›ë³¸ ì´ë¯¸ì§€ + íˆ¬ëª… OCR í…ìŠ¤íŠ¸ ë ˆì´ì–´ = ì„ íƒ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸
# ============================================================

import base64


def extract_ocr_with_coordinates(pdf_bytes: bytes, progress_callback=None, zoom: float = 2.0) -> dict:
    """
    Comet ë°©ì‹: PDF í˜ì´ì§€ë³„ë¡œ ì›ë³¸ ì´ë¯¸ì§€ + OCR í…ìŠ¤íŠ¸ ì¢Œí‘œ ì¶”ì¶œ

    Args:
        pdf_bytes: PDF íŒŒì¼ ë°”ì´íŠ¸
        progress_callback: ì§„í–‰ìƒí™© ì½œë°± í•¨ìˆ˜ (page, total, message)
        zoom: ì´ë¯¸ì§€ í™•ëŒ€ ë°°ìœ¨ (ê¸°ë³¸ 2.0)

    Returns:
        {
            "pages": [
                {
                    "page": 1,
                    "image_base64": "...",  # PNG ì´ë¯¸ì§€ base64
                    "width": 1200,
                    "height": 1600,
                    "ocr_results": [
                        {"text": "í…ìŠ¤íŠ¸", "box": [x1, y1, x2, y2], "score": 0.99},
                        ...
                    ]
                },
                ...
            ],
            "total_pages": 6,
            "extraction_method": "comet"
        }
    """
    if not PADDLEOCR_AVAILABLE:
        return {
            "pages": [],
            "error": "PaddleOCRê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "extraction_method": "comet"
        }

    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    total_pages = len(doc)

    result = {
        "pages": [],
        "total_pages": total_pages,
        "extraction_method": "comet",
        "ocr_engine": "PaddleOCR PP-OCRv5"
    }

    for page_num in range(total_pages):
        if progress_callback:
            progress_callback(page_num + 1, total_pages, f"í˜ì´ì§€ {page_num + 1}/{total_pages} OCR ì²˜ë¦¬ ì¤‘...")

        # PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        page = doc[page_num]
        mat = fitz.Matrix(zoom, zoom)
        pix = page.get_pixmap(matrix=mat)
        img_bytes = pix.tobytes("png")

        # ì´ë¯¸ì§€ë¥¼ PIL Imageë¡œ ë³€í™˜
        img = Image.open(io.BytesIO(img_bytes))

        # PaddleOCRë¡œ í…ìŠ¤íŠ¸ + ì¢Œí‘œ ì¶”ì¶œ
        ocr_results = ocr_full_image_paddle(img)

        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        img_base64 = base64.b64encode(img_bytes).decode('utf-8')

        page_data = {
            "page": page_num + 1,
            "image_base64": img_base64,
            "width": img.width,
            "height": img.height,
            "ocr_results": ocr_results
        }

        result["pages"].append(page_data)

    doc.close()
    return result


def generate_comet_overlay_html(page_data: dict, scale: float = 1.0) -> str:
    """
    Comet ë°©ì‹ HTML ì˜¤ë²„ë ˆì´ ìƒì„±
    ì›ë³¸ ì´ë¯¸ì§€ ìœ„ì— íˆ¬ëª…í•œ ì„ íƒ ê°€ëŠ¥ í…ìŠ¤íŠ¸ ë ˆì´ì–´ ë°°ì¹˜

    Args:
        page_data: extract_ocr_with_coordinatesì˜ í˜ì´ì§€ ë°ì´í„°
        scale: í‘œì‹œ ìŠ¤ì¼€ì¼ (ê¸°ë³¸ 1.0)

    Returns:
        HTML ë¬¸ìì—´ (ì´ë¯¸ì§€ + íˆ¬ëª… í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´)
    """
    img_base64 = page_data["image_base64"]
    width = page_data["width"]
    height = page_data["height"]
    ocr_results = page_data["ocr_results"]
    page_num = page_data["page"]

    # ìŠ¤ì¼€ì¼ ì ìš©
    display_width = int(width * scale)
    display_height = int(height * scale)

    # í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ìš”ì†Œ ìƒì„±
    text_elements = []
    for item in ocr_results:
        text = item["text"]
        box = item["box"]  # [x1, y1, x2, y2]

        # ì¢Œí‘œ ìŠ¤ì¼€ì¼ ì ìš©
        x1 = int(box[0] * scale)
        y1 = int(box[1] * scale)
        x2 = int(box[2] * scale)
        y2 = int(box[3] * scale)

        box_width = x2 - x1
        box_height = y2 - y1

        # í°íŠ¸ í¬ê¸° ê³„ì‚° (ë°•ìŠ¤ ë†’ì´ ê¸°ì¤€)
        font_size = max(8, int(box_height * 0.8))

        # HTML íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
        escaped_text = text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;").replace('"', "&quot;")

        text_elements.append(f'''
            <span style="
                position: absolute;
                left: {x1}px;
                top: {y1}px;
                width: {box_width}px;
                height: {box_height}px;
                font-size: {font_size}px;
                line-height: {box_height}px;
                color: transparent;
                background: transparent;
                cursor: text;
                user-select: text;
                -webkit-user-select: text;
                overflow: hidden;
                white-space: nowrap;
            " data-text="{escaped_text}">{escaped_text}</span>
        ''')

    # ì „ì²´ HTML ìƒì„±
    html = f'''
    <div class="comet-page-container" style="
        position: relative;
        width: {display_width}px;
        height: {display_height}px;
        margin: 10px auto;
        border: 1px solid #ddd;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    ">
        <!-- ì›ë³¸ ì´ë¯¸ì§€ (ë°°ê²½) -->
        <img src="data:image/png;base64,{img_base64}"
             style="
                 position: absolute;
                 top: 0;
                 left: 0;
                 width: {display_width}px;
                 height: {display_height}px;
                 pointer-events: none;
             "
             alt="í˜ì´ì§€ {page_num}"
        />

        <!-- OCR í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ (íˆ¬ëª…, ì„ íƒ ê°€ëŠ¥) -->
        <div class="comet-text-layer" style="
            position: absolute;
            top: 0;
            left: 0;
            width: {display_width}px;
            height: {display_height}px;
            z-index: 10;
        ">
            {''.join(text_elements)}
        </div>
    </div>
    '''

    return html


def generate_comet_full_html(comet_data: dict, scale: float = 0.8) -> str:
    """
    ì „ì²´ PDFì— ëŒ€í•œ Comet HTML ìƒì„± (ëª¨ë“  í˜ì´ì§€)

    Args:
        comet_data: extract_ocr_with_coordinatesì˜ ì „ì²´ ê²°ê³¼
        scale: í‘œì‹œ ìŠ¤ì¼€ì¼ (ê¸°ë³¸ 0.8 = 80%)

    Returns:
        ì „ì²´ HTML ë¬¸ìì—´
    """
    pages = comet_data.get("pages", [])
    total_pages = comet_data.get("total_pages", len(pages))

    page_htmls = []
    for page_data in pages:
        page_html = generate_comet_overlay_html(page_data, scale)
        page_num = page_data["page"]

        page_htmls.append(f'''
            <div class="comet-page-wrapper" style="margin-bottom: 20px;">
                <h3 style="text-align: center; color: #333; margin: 10px 0;">
                    í˜ì´ì§€ {page_num} / {total_pages}
                </h3>
                {page_html}
            </div>
        ''')

    # ì „ì²´ HTML ë¬¸ì„œ
    full_html = f'''
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <title>Comet OCR ì˜¤ë²„ë ˆì´</title>
        <style>
            body {{
                font-family: 'Malgun Gothic', sans-serif;
                background-color: #f5f5f5;
                padding: 20px;
                margin: 0;
            }}
            .comet-header {{
                text-align: center;
                padding: 20px;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                border-radius: 8px;
                margin-bottom: 20px;
            }}
            .comet-info {{
                text-align: center;
                color: #666;
                margin-bottom: 20px;
            }}
            .comet-page-wrapper {{
                background: white;
                border-radius: 8px;
                padding: 15px;
                margin-bottom: 20px;
            }}
            /* í…ìŠ¤íŠ¸ ì„ íƒ ì‹œ í•˜ì´ë¼ì´íŠ¸ */
            .comet-text-layer span::selection {{
                background: rgba(0, 120, 215, 0.3);
                color: transparent;
            }}
        </style>
    </head>
    <body>
        <div class="comet-header">
            <h1>ğŸ“„ Comet OCR ì˜¤ë²„ë ˆì´ ë·°ì–´</h1>
            <p>í…ìŠ¤íŠ¸ë¥¼ ë“œë˜ê·¸í•˜ì—¬ ì„ íƒ â†’ Ctrl+Cë¡œ ë³µì‚¬</p>
        </div>

        <div class="comet-info">
            <p>ì´ {total_pages} í˜ì´ì§€ | OCR ì—”ì§„: PaddleOCR PP-OCRv5</p>
        </div>

        <div class="comet-pages">
            {''.join(page_htmls)}
        </div>
    </body>
    </html>
    '''

    return full_html


# ============================================================
# Comet + Table Transformer í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹
# Table Transformerë¡œ í…Œì´ë¸” ì˜ì—­ ê°ì§€ â†’ ê° ì˜ì—­ë³„ Comet OCR
# ============================================================

def extract_comet_with_table_detection(pdf_bytes: bytes, progress_callback=None,
                                        detection_threshold: float = 0.5) -> dict:
    """
    Comet + Table Transformer í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹
    1. Table Transformerë¡œ í…Œì´ë¸” ì˜ì—­(bbox) ê°ì§€
    2. ê° í…Œì´ë¸” ì˜ì—­ì— ëŒ€í•´ Comet OCR ì ìš©
    3. í…Œì´ë¸”ë³„ë¡œ êµ¬ì¡°í™”ëœ ë°ì´í„° ë°˜í™˜

    Args:
        pdf_bytes: PDF íŒŒì¼ ë°”ì´íŠ¸
        progress_callback: ì§„í–‰ìƒí™© ì½œë°± í•¨ìˆ˜
        detection_threshold: í…Œì´ë¸” ê°ì§€ ì„ê³„ê°’ (ê¸°ë³¸ 0.5)

    Returns:
        {
            "tables": [
                {
                    "page": 1,
                    "table_index": 1,
                    "table_name": "COLOR/SIZE QTY",  # ê°ì§€ëœ í…Œì´ë¸” ì œëª©
                    "bbox": [x1, y1, x2, y2],
                    "confidence": 0.95,
                    "data": [[...], [...], ...],
                    "row_count": 10,
                    "col_count": 5,
                    "ocr_results": [...]  # ì›ë³¸ OCR ë°ì´í„°
                },
                ...
            ],
            "pages": [...],
            "comet_html": [...],
            "total_tables": 5,
            "extraction_method": "comet_hybrid"
        }
    """
    if not PADDLEOCR_AVAILABLE:
        return {
            "tables": [],
            "error": "PaddleOCRê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "extraction_method": "comet_hybrid"
        }

    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    total_pages = len(doc)

    result = {
        "tables": [],
        "pages": [],
        "comet_html": [],
        "total_pages": total_pages,
        "total_tables": 0,
        "is_ai_extracted": True,
        "extraction_method": "comet_hybrid",
        "ocr_engine": "PaddleOCR PP-OCRv5",
        "table_detector": "Table Transformer" if TABLE_TRANSFORMER_AVAILABLE else "Y-coordinate clustering"
    }

    table_index_global = 0

    for page_num in range(total_pages):
        if progress_callback:
            progress_callback(page_num + 1, total_pages, f"í˜ì´ì§€ {page_num + 1}/{total_pages} ì²˜ë¦¬ ì¤‘...")

        # PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        page = doc[page_num]
        zoom = 2.0
        mat = fitz.Matrix(zoom, zoom)
        pix = page.get_pixmap(matrix=mat)
        img_bytes = pix.tobytes("png")
        img = Image.open(io.BytesIO(img_bytes))

        # ì „ì²´ í˜ì´ì§€ OCR ìˆ˜í–‰
        if progress_callback:
            progress_callback(page_num + 1, total_pages, f"í˜ì´ì§€ {page_num + 1} OCR ì²˜ë¦¬ ì¤‘...")

        page_ocr_results = ocr_full_image_paddle(img)

        # ì´ë¯¸ì§€ base64 ì¸ì½”ë”©
        img_base64 = base64.b64encode(img_bytes).decode('utf-8')

        # í˜ì´ì§€ ë°ì´í„° ì €ì¥
        page_data = {
            "page": page_num + 1,
            "image_base64": img_base64,
            "width": img.width,
            "height": img.height,
            "ocr_results": page_ocr_results
        }
        result["pages"].append(page_data)

        # Comet HTML ìƒì„±
        page_html = generate_comet_overlay_html(page_data, scale=0.8)
        result["comet_html"].append({
            "page": page_num + 1,
            "html": page_html
        })

        # í…Œì´ë¸” ì˜ì—­ ê°ì§€
        if progress_callback:
            progress_callback(page_num + 1, total_pages, f"í˜ì´ì§€ {page_num + 1} í…Œì´ë¸” ì˜ì—­ ê°ì§€ ì¤‘...")

        if TABLE_TRANSFORMER_AVAILABLE:
            # Table Transformerë¡œ í…Œì´ë¸” ì˜ì—­ ê°ì§€
            detected_tables = detect_tables(img, threshold=detection_threshold)
        else:
            # Table Transformer ì—†ìœ¼ë©´ ì „ì²´ í˜ì´ì§€ë¥¼ í•˜ë‚˜ì˜ í…Œì´ë¸”ë¡œ ì²˜ë¦¬
            detected_tables = [{
                "score": 0.99,
                "label": "table",
                "box": [0, 0, img.width, img.height]
            }]

        if not detected_tables:
            # í…Œì´ë¸”ì´ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ Y ì¢Œí‘œ í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ í…Œì´ë¸” ì˜ì—­ ì¶”ì •
            detected_tables = estimate_table_regions_from_ocr(page_ocr_results, img.width, img.height)

        # ê° í…Œì´ë¸” ì˜ì—­ë³„ë¡œ ì²˜ë¦¬
        for table_idx, table_info in enumerate(detected_tables):
            table_index_global += 1
            table_box = table_info["box"]  # [x1, y1, x2, y2]
            table_score = table_info.get("score", 0.99)

            # í…Œì´ë¸” ì˜ì—­ ë‚´ì˜ OCR ê²°ê³¼ë§Œ í•„í„°ë§
            table_ocr = filter_ocr_by_bbox(page_ocr_results, table_box)

            if not table_ocr:
                continue

            # í…Œì´ë¸” ì œëª© ì¶”ì • (í…Œì´ë¸” ì˜ì—­ ìœ„ìª½ í…ìŠ¤íŠ¸)
            table_name = estimate_table_name(page_ocr_results, table_box)

            # OCR ê²°ê³¼ë¥¼ í–‰/ì—´ êµ¬ì¡°ë¡œ ë³€í™˜
            table_data = ocr_to_table_structure(table_ocr, table_box)

            if table_data:
                result["tables"].append({
                    "page": page_num + 1,
                    "table_index": table_idx + 1,
                    "table_index_global": table_index_global,
                    "table_name": table_name,
                    "bbox": table_box,
                    "confidence": float(table_score),
                    "data": table_data,
                    "row_count": len(table_data),
                    "col_count": max(len(row) for row in table_data) if table_data else 0,
                    "ocr_results": table_ocr,
                    "extraction_method": "comet_hybrid"
                })

    doc.close()
    result["total_tables"] = len(result["tables"])

    return result


def filter_ocr_by_bbox(ocr_results: list, bbox: list, margin: int = 5) -> list:
    """
    ë°”ìš´ë”© ë°•ìŠ¤ ë‚´ì˜ OCR ê²°ê³¼ë§Œ í•„í„°ë§

    Args:
        ocr_results: OCR ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        bbox: [x1, y1, x2, y2] í…Œì´ë¸” ì˜ì—­
        margin: ë§ˆì§„ (í”½ì…€)

    Returns:
        í•„í„°ë§ëœ OCR ê²°ê³¼
    """
    x1, y1, x2, y2 = bbox
    filtered = []

    for item in ocr_results:
        box = item["box"]
        # OCR ë°•ìŠ¤ì˜ ì¤‘ì‹¬ì ì´ í…Œì´ë¸” ì˜ì—­ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
        center_x = (box[0] + box[2]) / 2
        center_y = (box[1] + box[3]) / 2

        if (x1 - margin <= center_x <= x2 + margin and
            y1 - margin <= center_y <= y2 + margin):
            # ìƒëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
            filtered.append({
                "text": item["text"],
                "box": [
                    item["box"][0] - x1,  # ìƒëŒ€ x1
                    item["box"][1] - y1,  # ìƒëŒ€ y1
                    item["box"][2] - x1,  # ìƒëŒ€ x2
                    item["box"][3] - y1   # ìƒëŒ€ y2
                ],
                "box_absolute": item["box"],  # ì ˆëŒ€ ì¢Œí‘œ ìœ ì§€
                "score": item.get("score", 1.0)
            })

    return filtered


def estimate_table_name(ocr_results: list, table_bbox: list, search_height: int = 60) -> str:
    """
    í…Œì´ë¸” ì˜ì—­ ìœ„ìª½ì—ì„œ í…Œì´ë¸” ì œëª© ì¶”ì •

    Args:
        ocr_results: í˜ì´ì§€ ì „ì²´ OCR ê²°ê³¼
        table_bbox: í…Œì´ë¸” ë°”ìš´ë”© ë°•ìŠ¤ [x1, y1, x2, y2]
        search_height: í…Œì´ë¸” ìœ„ìª½ ê²€ìƒ‰ ë†’ì´ (í”½ì…€)

    Returns:
        ì¶”ì •ëœ í…Œì´ë¸” ì œëª©
    """
    x1, y1, x2, y2 = table_bbox

    # í…Œì´ë¸” ìœ„ìª½ ì˜ì—­ì—ì„œ í…ìŠ¤íŠ¸ ì°¾ê¸°
    candidates = []
    for item in ocr_results:
        box = item["box"]
        text_center_y = (box[1] + box[3]) / 2
        text_center_x = (box[0] + box[2]) / 2

        # í…Œì´ë¸” ìœ„ìª½ search_height í”½ì…€ ë‚´ì— ìˆê³ , x ë²”ìœ„ê°€ ê²¹ì¹˜ëŠ” í…ìŠ¤íŠ¸
        if (y1 - search_height <= text_center_y < y1 and
            x1 <= text_center_x <= x2):
            candidates.append({
                "text": item["text"],
                "y": box[1]
            })

    if candidates:
        # ê°€ì¥ ì•„ë˜ìª½(í…Œì´ë¸”ì— ê°€ê¹Œìš´) í…ìŠ¤íŠ¸ ì„ íƒ
        candidates.sort(key=lambda x: x["y"], reverse=True)
        return candidates[0]["text"]

    return ""


def estimate_table_regions_from_ocr(ocr_results: list, page_width: int, page_height: int,
                                     gap_threshold: int = 50) -> list:
    """
    OCR ê²°ê³¼ì˜ Y ì¢Œí‘œ ë¶„í¬ë¥¼ ë¶„ì„í•˜ì—¬ í…Œì´ë¸” ì˜ì—­ ì¶”ì •
    í° Y ê°­ì´ ìˆìœ¼ë©´ í…Œì´ë¸” êµ¬ë¶„ìœ¼ë¡œ íŒë‹¨

    Args:
        ocr_results: OCR ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        page_width: í˜ì´ì§€ ë„ˆë¹„
        page_height: í˜ì´ì§€ ë†’ì´
        gap_threshold: í…Œì´ë¸” êµ¬ë¶„ ê°­ ì„ê³„ê°’ (í”½ì…€)

    Returns:
        ì¶”ì •ëœ í…Œì´ë¸” ì˜ì—­ ë¦¬ìŠ¤íŠ¸
    """
    if not ocr_results:
        return []

    # Y ì¢Œí‘œë¡œ ì •ë ¬
    sorted_items = sorted(ocr_results, key=lambda x: x["box"][1])

    # í…Œì´ë¸” ì˜ì—­ ê·¸ë£¹í™”
    groups = []
    current_group = [sorted_items[0]]

    for i in range(1, len(sorted_items)):
        prev_y2 = current_group[-1]["box"][3]  # ì´ì „ í•­ëª©ì˜ y2
        curr_y1 = sorted_items[i]["box"][1]     # í˜„ì¬ í•­ëª©ì˜ y1

        if curr_y1 - prev_y2 > gap_threshold:
            # í° ê°­ ë°œê²¬ - ìƒˆ ê·¸ë£¹ ì‹œì‘
            groups.append(current_group)
            current_group = [sorted_items[i]]
        else:
            current_group.append(sorted_items[i])

    if current_group:
        groups.append(current_group)

    # ê° ê·¸ë£¹ì„ í…Œì´ë¸” ì˜ì—­ìœ¼ë¡œ ë³€í™˜
    tables = []
    for group in groups:
        if len(group) < 3:  # ìµœì†Œ 3ê°œ í…ìŠ¤íŠ¸ê°€ ìˆì–´ì•¼ í…Œì´ë¸”ë¡œ ê°„ì£¼
            continue

        # ê·¸ë£¹ì˜ ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
        x1 = min(item["box"][0] for item in group)
        y1 = min(item["box"][1] for item in group)
        x2 = max(item["box"][2] for item in group)
        y2 = max(item["box"][3] for item in group)

        # ë§ˆì§„ ì¶”ê°€
        margin = 10
        x1 = max(0, x1 - margin)
        y1 = max(0, y1 - margin)
        x2 = min(page_width, x2 + margin)
        y2 = min(page_height, y2 + margin)

        tables.append({
            "score": 0.9,
            "label": "table_estimated",
            "box": [x1, y1, x2, y2]
        })

    return tables


def ocr_to_table_structure(ocr_results: list, table_bbox: list,
                            y_tolerance: int = 15, x_gap_threshold: int = 30) -> list:
    """
    OCR ê²°ê³¼ë¥¼ í…Œì´ë¸” í–‰/ì—´ êµ¬ì¡°ë¡œ ë³€í™˜

    Args:
        ocr_results: í•„í„°ë§ëœ OCR ê²°ê³¼ (ìƒëŒ€ ì¢Œí‘œ)
        table_bbox: í…Œì´ë¸” ë°”ìš´ë”© ë°•ìŠ¤
        y_tolerance: ê°™ì€ í–‰ìœ¼ë¡œ ê°„ì£¼í•  Y ì˜¤ì°¨
        x_gap_threshold: ì—´ êµ¬ë¶„ì„ ìœ„í•œ X ê°­ ì„ê³„ê°’

    Returns:
        2D í…Œì´ë¸” ë°ì´í„° [[row1_col1, row1_col2, ...], [row2_col1, ...], ...]
    """
    if not ocr_results:
        return []

    # Y ì¢Œí‘œë¡œ ì •ë ¬ í›„ í–‰ ê·¸ë£¹í™”
    sorted_items = sorted(ocr_results, key=lambda x: (x["box"][1], x["box"][0]))

    rows = []
    current_row = []
    current_y = None

    for item in sorted_items:
        y = item["box"][1]

        if current_y is None:
            current_y = y
            current_row = [item]
        elif abs(y - current_y) <= y_tolerance:
            current_row.append(item)
        else:
            # ìƒˆ í–‰ ì‹œì‘ - í˜„ì¬ í–‰ì„ X ì¢Œí‘œë¡œ ì •ë ¬
            rows.append(sorted(current_row, key=lambda x: x["box"][0]))
            current_row = [item]
            current_y = y

    if current_row:
        rows.append(sorted(current_row, key=lambda x: x["box"][0]))

    # ì—´ ìœ„ì¹˜ ì¶”ì • (X ì¢Œí‘œ í´ëŸ¬ìŠ¤í„°ë§)
    all_x_positions = []
    for row in rows:
        for item in row:
            all_x_positions.append(item["box"][0])

    if not all_x_positions:
        return []

    # X ì¢Œí‘œ í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ì—´ ê²½ê³„ ì°¾ê¸°
    column_boundaries = estimate_column_boundaries(all_x_positions, x_gap_threshold)

    # ê° í–‰ì„ ì—´ì— ë§ì¶° ì •ë ¬
    table_data = []
    for row in rows:
        row_data = assign_to_columns(row, column_boundaries)
        if any(cell.strip() for cell in row_data):  # ë¹ˆ í–‰ ì œì™¸
            table_data.append(row_data)

    return table_data


def estimate_column_boundaries(x_positions: list, gap_threshold: int = 30) -> list:
    """
    X ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì—´ ê²½ê³„ ì¶”ì •

    Args:
        x_positions: X ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸
        gap_threshold: ì—´ êµ¬ë¶„ ê°­ ì„ê³„ê°’

    Returns:
        ì—´ ê²½ê³„ ë¦¬ìŠ¤íŠ¸ [(start, end), ...]
    """
    if not x_positions:
        return []

    sorted_x = sorted(set(x_positions))

    # í´ëŸ¬ìŠ¤í„°ë§
    clusters = []
    current_cluster = [sorted_x[0]]

    for i in range(1, len(sorted_x)):
        if sorted_x[i] - sorted_x[i-1] <= gap_threshold:
            current_cluster.append(sorted_x[i])
        else:
            clusters.append(current_cluster)
            current_cluster = [sorted_x[i]]

    if current_cluster:
        clusters.append(current_cluster)

    # ê° í´ëŸ¬ìŠ¤í„°ì˜ ê²½ê³„
    boundaries = []
    for cluster in clusters:
        start = min(cluster) - gap_threshold // 2
        end = max(cluster) + gap_threshold // 2
        boundaries.append((start, end))

    return boundaries


def assign_to_columns(row_items: list, column_boundaries: list) -> list:
    """
    í–‰ì˜ í•­ëª©ë“¤ì„ ì—´ì— í• ë‹¹

    Args:
        row_items: í–‰ì˜ OCR í•­ëª©ë“¤
        column_boundaries: ì—´ ê²½ê³„ ë¦¬ìŠ¤íŠ¸

    Returns:
        ì—´ì— ë§ì¶° ì •ë ¬ëœ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    if not column_boundaries:
        return [item["text"] for item in row_items]

    # ê° ì—´ì— í•´ë‹¹í•˜ëŠ” í…ìŠ¤íŠ¸ ì°¾ê¸°
    row_data = [""] * len(column_boundaries)

    for item in row_items:
        x = item["box"][0]
        text = item["text"]

        # ê°€ì¥ ê°€ê¹Œìš´ ì—´ ì°¾ê¸°
        best_col = 0
        min_dist = float('inf')

        for col_idx, (start, end) in enumerate(column_boundaries):
            col_center = (start + end) / 2
            dist = abs(x - col_center)
            if dist < min_dist:
                min_dist = dist
                best_col = col_idx

        # ì´ë¯¸ ê°’ì´ ìˆìœ¼ë©´ í•©ì¹˜ê¸°
        if row_data[best_col]:
            row_data[best_col] += " " + text
        else:
            row_data[best_col] = text

    return row_data


def extract_comet_tables(pdf_bytes: bytes, progress_callback=None) -> dict:
    """
    Comet ë°©ì‹ìœ¼ë¡œ PDFì—ì„œ í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ
    OCR ê²°ê³¼ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ í…Œì´ë¸” í˜•íƒœë¡œ ë°˜í™˜

    Args:
        pdf_bytes: PDF íŒŒì¼ ë°”ì´íŠ¸
        progress_callback: ì§„í–‰ìƒí™© ì½œë°±

    Returns:
        í…Œì´ë¸” ì¶”ì¶œ ê²°ê³¼ (ê¸°ì¡´ í˜•ì‹ê³¼ í˜¸í™˜)
    """
    # OCR ì¢Œí‘œ ì¶”ì¶œ
    comet_data = extract_ocr_with_coordinates(pdf_bytes, progress_callback)

    if "error" in comet_data:
        return {
            "tables": [],
            "error": comet_data["error"],
            "is_ai_extracted": True,
            "extraction_method": "comet"
        }

    result = {
        "tables": [],
        "pages": [],
        "comet_html": [],  # Comet HTML ì˜¤ë²„ë ˆì´
        "is_ai_extracted": True,
        "total_pages": comet_data["total_pages"],
        "extraction_method": "comet",
        "ocr_engine": comet_data.get("ocr_engine", "PaddleOCR")
    }

    for page_data in comet_data["pages"]:
        page_num = page_data["page"]
        ocr_results = page_data["ocr_results"]

        # Comet HTML ì˜¤ë²„ë ˆì´ ìƒì„±
        page_html = generate_comet_overlay_html(page_data, scale=0.8)
        result["comet_html"].append({
            "page": page_num,
            "html": page_html
        })

        # OCR ê²°ê³¼ë¥¼ í–‰/ì—´ êµ¬ì¡°ë¡œ ì •ë¦¬ (ê¸°ì¡´ í˜¸í™˜)
        if ocr_results:
            # Y ì¢Œí‘œë¡œ í–‰ ê·¸ë£¹í™”
            sorted_items = sorted(ocr_results, key=lambda x: (x["box"][1], x["box"][0]))

            rows = []
            current_row = []
            current_y = None
            y_tolerance = 15  # ê°™ì€ í–‰ìœ¼ë¡œ ê°„ì£¼í•  Y ì˜¤ì°¨

            for item in sorted_items:
                y = item["box"][1]

                if current_y is None:
                    current_y = y
                    current_row = [item]
                elif abs(y - current_y) <= y_tolerance:
                    current_row.append(item)
                else:
                    # ìƒˆ í–‰ ì‹œì‘
                    rows.append(sorted(current_row, key=lambda x: x["box"][0]))
                    current_row = [item]
                    current_y = y

            if current_row:
                rows.append(sorted(current_row, key=lambda x: x["box"][0]))

            # í…Œì´ë¸” ë°ì´í„° ìƒì„±
            table_data = []
            for row in rows:
                row_texts = [item["text"] for item in row]
                if any(row_texts):  # ë¹ˆ í–‰ ì œì™¸
                    table_data.append(row_texts)

            if table_data:
                result["tables"].append({
                    "page": page_num,
                    "table_index": 1,
                    "confidence": 0.99,  # OCR ê¸°ë°˜ì´ë¯€ë¡œ ë†’ì€ ì‹ ë¢°ë„
                    "data": table_data,
                    "row_count": len(table_data),
                    "col_count": max(len(row) for row in table_data) if table_data else 0,
                    "extraction_method": "comet_ocr"
                })

        # í˜ì´ì§€ë³„ ì›ë³¸ ë°ì´í„° ì €ì¥
        result["pages"].append({
            "page": page_num,
            "ocr_results": ocr_results,
            "image_base64": page_data["image_base64"],
            "width": page_data["width"],
            "height": page_data["height"]
        })

    return result


def extract_tables_auto(pdf_bytes: bytes, progress_callback=None, method: str = "auto") -> dict:
    """
    ìë™ìœ¼ë¡œ ìµœì ì˜ ë°©ë²•ìœ¼ë¡œ í…Œì´ë¸” ì¶”ì¶œ

    Args:
        pdf_bytes: PDF íŒŒì¼ ë°”ì´íŠ¸
        progress_callback: ì§„í–‰ìƒí™© ì½œë°±
        method: ì¶”ì¶œ ë°©ë²•
            - "auto": ìë™ ì„ íƒ (Comet > Table Transformer)
            - "comet": Comet ë°©ì‹ (OCR ì˜¤ë²„ë ˆì´) - ê¶Œì¥
            - "vlm": VLM(Granite3.2-vision) ì‚¬ìš©
            - "table_transformer": Table Transformer + OCR ì‚¬ìš©

    Returns:
        ì¶”ì¶œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if method == "auto":
        # Comet ë°©ì‹ ìš°ì„  (ê°€ì¥ ì •í™•)
        if PADDLEOCR_AVAILABLE:
            method = "comet"
        elif OLLAMA_AVAILABLE and check_ollama_model("granite3.2-vision"):
            method = "vlm"
        elif TABLE_TRANSFORMER_AVAILABLE:
            method = "table_transformer"
        else:
            return {
                "tables": [],
                "error": "ì‚¬ìš© ê°€ëŠ¥í•œ ì¶”ì¶œ ë°©ë²•ì´ ì—†ìŠµë‹ˆë‹¤. PaddleOCR, Ollama ë˜ëŠ” Table Transformerë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.",
                "is_ai_extracted": False
            }

    if method == "comet":
        return extract_comet_tables(pdf_bytes, progress_callback)
    elif method == "vlm":
        return extract_vlm_tables(pdf_bytes, progress_callback)
    else:
        return extract_smart_tables(pdf_bytes, progress_callback)


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    import sys
    sys.stdout.reconfigure(encoding='utf-8')

    print("=" * 60)
    print("ìŠ¤ë§ˆíŠ¸ í…Œì´ë¸” ì¶”ì¶œê¸° v3 í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    print(f"\nì—”ì§„ ìƒíƒœ:")
    print(f"  Ollama VLM: {'ì‚¬ìš© ê°€ëŠ¥' if OLLAMA_AVAILABLE else 'ì‚¬ìš© ë¶ˆê°€'}")
    print(f"  Granite3.2-vision: {'ì„¤ì¹˜ë¨' if check_ollama_model('granite3.2-vision') else 'ë¯¸ì„¤ì¹˜'}")
    print(f"  PaddleOCR: {'ì‚¬ìš© ê°€ëŠ¥' if PADDLEOCR_AVAILABLE else 'ì‚¬ìš© ë¶ˆê°€'}")
    print(f"  Tesseract: {'ì‚¬ìš© ê°€ëŠ¥' if TESSERACT_AVAILABLE else 'ì‚¬ìš© ë¶ˆê°€'}")
    print(f"  Table Transformer: {'ì‚¬ìš© ê°€ëŠ¥' if TABLE_TRANSFORMER_AVAILABLE else 'ì‚¬ìš© ë¶ˆê°€'}")

    # í…ŒìŠ¤íŠ¸ PDF
    pdf_path = "e:/Antigravity/Black_Yak/ì œë¡œìŠ¤íŒŸ ë‹¤ìš´ìì¼“#1 ì˜¤ë” ë“±ë¡ ì‘ì§€ 1BYPAWU005-M-1.pdf"

    if os.path.exists(pdf_path):
        with open(pdf_path, "rb") as f:
            pdf_bytes = f.read()

        print(f"\nPDF: {pdf_path}")
        print(f"Is Scanned PDF: {is_scanned_pdf(pdf_bytes)}")

        def progress(page, total, msg):
            print(f"  [{page}/{total}] {msg}")

        # VLM í…ŒìŠ¤íŠ¸
        if OLLAMA_AVAILABLE and check_ollama_model("granite3.2-vision"):
            print("\n" + "=" * 60)
            print("VLM ì¶”ì¶œ í…ŒìŠ¤íŠ¸ (Granite3.2-vision)")
            print("=" * 60)
            result = extract_vlm_tables(pdf_bytes, progress_callback=progress)

            print(f"\nê²°ê³¼:")
            print(f"  ì¶”ì¶œ ë°©ë²•: {result.get('extraction_method', 'N/A')}")
            print(f"  ëª¨ë¸: {result.get('model', 'N/A')}")
            print(f"  ë°œê²¬ëœ í…Œì´ë¸” ìˆ˜: {len(result['tables'])}")

            for table in result["tables"]:
                print(f"\n  í˜ì´ì§€ {table['page']}, í…Œì´ë¸” {table['table_index']}:")
                print(f"    ì œëª©: {table.get('title', 'N/A')}")
                print(f"    í¬ê¸°: {table['row_count']} í–‰ x {table['col_count']} ì—´")
                print(f"    ë°ì´í„°:")
                for row in table["data"][:5]:
                    print(f"      {row}")

            # í˜ì´ì§€ë³„ í•„ë“œ ì •ë³´
            for page_data in result.get("pages", []):
                if page_data.get("fields"):
                    print(f"\n  í˜ì´ì§€ {page_data['page']} ì¶”ì¶œ í•„ë“œ:")
                    for key, value in page_data["fields"].items():
                        print(f"    {key}: {value}")

        # Table Transformer í…ŒìŠ¤íŠ¸ (ë¹„êµìš©)
        print("\n" + "=" * 60)
        print("Table Transformer ì¶”ì¶œ í…ŒìŠ¤íŠ¸ (ë¹„êµìš©)")
        print("=" * 60)
        result = extract_smart_tables(pdf_bytes, progress_callback=progress, use_paddle=True)

        print(f"\nê²°ê³¼:")
        print(f"  OCR ì—”ì§„: {result.get('ocr_engine', 'N/A')}")
        print(f"  ë°œê²¬ëœ í…Œì´ë¸” ìˆ˜: {len(result['tables'])}")

        for table in result["tables"][:2]:  # ì²˜ìŒ 2ê°œë§Œ
            print(f"\n  í˜ì´ì§€ {table['page']}, í…Œì´ë¸” {table['table_index']}:")
            print(f"    ì‹ ë¢°ë„: {table['confidence']}")
            print(f"    í¬ê¸°: {table['row_count']} í–‰ x {table['col_count']} ì—´")
            print(f"    ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 3í–‰):")
            for row in table["data"][:3]:
                print(f"      {row}")
    else:
        print(f"\nPDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
